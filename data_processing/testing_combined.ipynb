{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImageProcessor import ImageProcessor\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global initialization\n",
    "global_detector = dlib.get_frontal_face_detector()\n",
    "global_predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "global_sr_model = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "global_sr_model.readModel(\"EDSR_x4.pb\")\n",
    "global_sr_model.setModel(\"edsr\", 4)\n",
    "ImageProcessor = ImageProcessor(global_detector, global_predictor, global_sr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_eyes(frame, global_sr_model, global_detector, global_predictor):\n",
    "    \"\"\"\n",
    "    \n",
    "    Detects and combines the eye regions from the frame using the extract_eye_region method.\n",
    "    Args:\n",
    "        frame: The input image frame.\n",
    "        landmarks: Facial landmarks detected in the frame.\n",
    "        global_sr_model: Super-resolution model.\n",
    "        global_detector: Face detector.\n",
    "        global_predictor: Landmark predictor.\n",
    "    Returns:\n",
    "        The combined eye regions, or None if not detected.\n",
    "    \"\"\"\n",
    "    # Enhance image resolution\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = global_detector(gray)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = global_predictor(gray, face)\n",
    "\n",
    "        # Extract the coordinates for each eye using dlib's facial landmark indices\n",
    "        left_eye_points = range(36, 42)\n",
    "        right_eye_points = range(42, 48)\n",
    "\n",
    "        # Extract each eye region using the extract_eye_region method\n",
    "        left_eye_region, _ = ImageProcessor.extract_eye_region(frame, landmarks, left_eye_points)\n",
    "        right_eye_region, _ = ImageProcessor.extract_eye_region(frame, landmarks, right_eye_points)\n",
    "\n",
    "\n",
    "\n",
    "        left_eye_super_res = ImageProcessor.enhance_image_resolution(left_eye_region, global_sr_model)\n",
    "        right_eye_super_res = ImageProcessor.enhance_image_resolution(right_eye_region, global_sr_model)\n",
    "\n",
    "        # Resize each eye region to the target size\n",
    "        target_size = (40, 48)  # Assuming you want to resize both eyes to this size\n",
    "        left_eye_resized = cv2.resize(left_eye_super_res, target_size)\n",
    "\n",
    "        right_eye_resized = cv2.resize(right_eye_super_res, target_size)\n",
    "\n",
    "        # Combine the eye regions\n",
    "        combined_eyes = np.hstack((left_eye_resized, right_eye_resized))\n",
    "        return combined_eyes\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "local_base_dir = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirs = glob(os.path.join(local_base_dir, '*/'))\n",
    "\n",
    "results = []\n",
    "\n",
    "for subdir in subdirs:\n",
    "    print(f\"Processing images in {subdir}\")\n",
    "    metadata_file_path = os.path.join(subdir, 'metadata.json')\n",
    "    csv_files = glob(os.path.join(subdir, '*.csv'))\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        dataset = pd.read_csv(csv_file, header=None)\n",
    "        # Update here: Remove extra parentheses to correctly unpack arguments\n",
    "        data_rows = [(tuple(row), metadata_file_path, local_base_dir) for index, row in dataset.iterrows()]\n",
    "\n",
    "        for data_row in data_rows:\n",
    "            # Update here: Unpack the arguments\n",
    "            frame, metadata_file_path, local_base_dir = data_row\n",
    "            combined_eyes = get_combined_eyes(frame, global_sr_model, global_detector, global_predictor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.10_eye_gaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
