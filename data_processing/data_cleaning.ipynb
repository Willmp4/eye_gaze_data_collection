{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "MIN_HEIGHT = 100\n",
    "MIN_WIDTH = 100\n",
    "MIN_BRIGHTNESS = 50\n",
    "\n",
    "\n",
    "def check_image_quality(image_path):\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Image not found or could not be loaded: {image_path}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "        if image.shape[0] < MIN_HEIGHT or image.shape[1] < MIN_WIDTH:\n",
    "            return False\n",
    "\n",
    "        # Example: check if the image is too dar\n",
    "        if np.mean(image) < MIN_BRIGHTNESS:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking image quality: {e}\")\n",
    "        return False\n",
    "\n",
    "# Usage\n",
    "is_good_quality = check_image_quality('data/William/images/William_04f57bf9-74b4-4269-adcc-6d7096345f86.png')\n",
    "is_good_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_eye_region(image, eye_box):\n",
    "    \"\"\"\n",
    "    Check if the eye region defined by the bounding box is valid.\n",
    "    Args:\n",
    "        image: The image in which the eye region is located.\n",
    "        eye_box: The bounding box of the eye region in the format [x, y, width, height].\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the eye region is valid, False otherwise.\n",
    "    \"\"\"\n",
    "    x, y, width, height = eye_box\n",
    "    if x < 0 or y < 0 or width <= 0 or height <= 0:\n",
    "        return False\n",
    "    if x + width > image.shape[1] or y + height > image.shape[0]:\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_perfect_user(participant_eye_data, perfect_user_eye_data, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Compare the participant's eye data with the perfect user's eye data.\n",
    "    Args:\n",
    "        participant_eye_data (list): The eye box and pupil data for the participant.\n",
    "        perfect_user_eye_data (list): The eye box and pupil data for the perfect user.\n",
    "        threshold (float): The acceptable threshold for deviation.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the participant data is within the threshold of the perfect user data.\n",
    "    \"\"\"\n",
    "    # Calculate deviation for each data point and check against the threshold\n",
    "    for p_data, pu_data in zip(participant_eye_data, perfect_user_eye_data):\n",
    "        if abs(p_data - pu_data) > threshold * abs(pu_data):\n",
    "            return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_key_from_filename(filename):\n",
    "    # This is where you extract the matching part of the filename.\n",
    "    # It's an example, you'll need to define how to extract the matching key.\n",
    "    return filename.split('_')[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def process_participant_data(participant_data_path, perfect_user_data, participant_image_folder):\n",
    "    with open(participant_data_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(',')\n",
    "            if len(parts) < 15:\n",
    "                print(\"Invalid data format.\")\n",
    "                continue\n",
    "\n",
    "            image_name = parts[0]\n",
    "            image_path = os.path.join(participant_image_folder, image_name)\n",
    "            key = extract_key_from_filename(image_name)\n",
    "            perfect_data = perfect_user_data.get(key)\n",
    "\n",
    "            if not perfect_data:\n",
    "                print(f\"No matching perfect user data for image: {image_name}\")\n",
    "                continue\n",
    "\n",
    "            # Assuming the first part is the image filename\n",
    "            participant_eye_box_pupil_data = list(map(float, parts[3:15]))\n",
    "\n",
    "            # Load and check image\n",
    "            if not check_image_quality(image_path):\n",
    "                print(f\"Image failed quality check: {image_path}\")\n",
    "                continue\n",
    "\n",
    "            # Extract eye box data\n",
    "            left_eye_box = list(map(int, parts[5:9]))\n",
    "            right_eye_box = list(map(int, parts[11:15]))\n",
    "\n",
    "            # Apply eye region check\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None or not check_eye_region(image, left_eye_box) or not check_eye_region(image, right_eye_box):\n",
    "                print(f\"Eye region check failed for image: {image_path}\")\n",
    "                continue\n",
    "\n",
    "            # Compare with perfect user data\n",
    "            if not compare_with_perfect_user(participant_eye_box_pupil_data, perfect_data, threshold=0.1):\n",
    "                print(f\"Data deviates from 'perfect user' for image: {image_path}\")\n",
    "                continue\n",
    "\n",
    "            output_path = os.path.join(participant_image_folder, f\"processed_{os.path.basename(image_path)}\")\n",
    "            # Save processed data or image\n",
    "            # This part of the code depends on what \"processed\" means in your context\n",
    "            # You need to define how you want to save the processed data or image\n",
    "            print(f\"Data is good and processed image saved to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_user_data(user_data_path):\n",
    "    user_data = {}\n",
    "\n",
    "    try:\n",
    "        with open(user_data_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split(',')\n",
    "                if len(parts) < 15:\n",
    "                    continue\n",
    "\n",
    "                # Assuming the first part is the image filename\n",
    "                image_name = parts[0]\n",
    "                eye_box_pupil_data = list(map(float, parts[3:15]))\n",
    "                \n",
    "                # Use a part of the image filename as the key, for example, the timestamp\n",
    "                key = extract_key_from_filename(image_name)\n",
    "                user_data[key] = eye_box_pupil_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading user data: {e}\")\n",
    "\n",
    "    return user_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3b89e44e-f63a-4327-8f7f-2ac6b078cb52.png': [262.0, 199.0, 255.0, 196.0, 22.0, 8.0, 323.0, 203.0, 312.0, 200.0, 22.0, 8.0], '642e7551-3240-4add-b7b4-fd240704519c.png': [261.0, 205.0, 250.0, 203.0, 23.0, 8.0, 323.0, 208.0, 309.0, 205.0, 22.0, 8.0], 'a1e7f7f7-0a0b-4d4e-86b1-a64ec5139ff4.png': [262.0, 209.0, 252.0, 205.0, 23.0, 9.0, 322.0, 210.0, 311.0, 207.0, 22.0, 9.0], '084ef3e3-bffb-48d5-adf6-4e074c13bd7b.png': [261.0, 207.0, 251.0, 205.0, 23.0, 8.0, 320.0, 212.0, 310.0, 208.0, 22.0, 9.0], '92344c06-ea60-44ed-aec1-9f26ec9985a6.png': [261.0, 213.0, 250.0, 209.0, 23.0, 9.0, 324.0, 214.0, 309.0, 211.0, 24.0, 8.0], '1102f111-6bda-4325-99c0-0653ff379be7.png': [253.0, 213.0, 243.0, 210.0, 24.0, 9.0, 315.0, 214.0, 305.0, 212.0, 23.0, 8.0], 'd6ecbcc0-dd9b-4f2b-8304-9b16fd7df2cf.png': [228.0, 201.0, 219.0, 199.0, 21.0, 7.0, 290.0, 204.0, 275.0, 201.0, 24.0, 8.0], '08daa18b-ac91-4c85-967c-364cd702ce76.png': [227.0, 204.0, 218.0, 201.0, 23.0, 8.0, 287.0, 207.0, 277.0, 204.0, 24.0, 8.0], '0dd631c6-0a46-4945-9489-aa0eb649dc2c.png': [220.0, 212.0, 209.0, 208.0, 24.0, 9.0, 282.0, 212.0, 269.0, 209.0, 25.0, 8.0], '17b5526e-e211-43f6-b5c9-f2a96aa8013e.png': [218.0, 214.0, 208.0, 210.0, 23.0, 9.0, 280.0, 214.0, 268.0, 211.0, 25.0, 9.0], '1c2380bf-e080-4363-aced-3a70ce297792.png': [223.0, 214.0, 209.0, 208.0, 26.0, 12.0, 281.0, 215.0, 272.0, 210.0, 27.0, 11.0], 'c9577ba1-796b-499d-8172-4a948923c2b8.png': [222.0, 216.0, 210.0, 210.0, 25.0, 12.0, 282.0, 217.0, 271.0, 212.0, 26.0, 11.0], 'f5a6f7a3-fa59-4d10-a4d1-3e69c6dc9148.png': [221.0, 217.0, 209.0, 212.0, 26.0, 11.0, 289.0, 217.0, 272.0, 212.0, 26.0, 12.0], '976ce9d8-dc77-493f-8f6f-d6f3a94c0cde.png': [230.0, 220.0, 214.0, 215.0, 24.0, 10.0, 291.0, 220.0, 274.0, 216.0, 26.0, 10.0], 'c05b4c62-afa2-45ab-b01d-7b5ad4dcfb5d.png': [226.0, 219.0, 217.0, 215.0, 24.0, 9.0, 291.0, 218.0, 278.0, 215.0, 25.0, 9.0], 'ea22f26b-415c-4bad-9049-69059722924b.png': [245.0, 214.0, 236.0, 212.0, 22.0, 7.0, 304.0, 216.0, 295.0, 213.0, 23.0, 8.0], 'aa716bb5-bf33-4964-bb3d-3ee64f163944.png': [250.0, 210.0, 236.0, 208.0, 22.0, 7.0, 307.0, 212.0, 294.0, 210.0, 22.0, 7.0], 'd3296439-7793-4316-91f1-ebaef5eb6a4e.png': [245.0, 209.0, 235.0, 207.0, 22.0, 7.0, 303.0, 211.0, 293.0, 208.0, 23.0, 8.0], '2646a395-4912-4276-ad59-15aa97982fef.png': [253.0, 204.0, 242.0, 201.0, 22.0, 8.0, 311.0, 207.0, 301.0, 204.0, 23.0, 8.0], '42ddec04-9c45-4ea7-b5cc-da529794dc33.png': [250.0, 206.0, 239.0, 204.0, 23.0, 8.0, 308.0, 209.0, 299.0, 206.0, 23.0, 8.0], 'e355d76b-d071-4379-959b-dfa7109a297d.png': [246.0, 207.0, 236.0, 205.0, 24.0, 7.0, 310.0, 208.0, 295.0, 206.0, 24.0, 7.0], 'cb80f8a0-6065-4484-b3fd-5a5ab8ddb7dc.png': [242.0, 205.0, 233.0, 202.0, 24.0, 8.0, 310.0, 208.0, 294.0, 205.0, 24.0, 8.0], '0b99605a-729f-47b5-87cd-8ab409883a89.png': [242.0, 205.0, 232.0, 200.0, 24.0, 11.0, 309.0, 208.0, 292.0, 204.0, 25.0, 10.0], '04f57bf9-74b4-4269-adcc-6d7096345f86.png': [240.0, 204.0, 229.0, 199.0, 25.0, 11.0, 304.0, 206.0, 290.0, 201.0, 26.0, 11.0], '56b64898-dfed-40ac-9fea-8cc43cca037f.png': [238.0, 204.0, 225.0, 198.0, 26.0, 12.0, 300.0, 205.0, 289.0, 199.0, 27.0, 12.0], '96c6400a-0677-4b2b-af6f-5577fb7e1422.png': [236.0, 204.0, 222.0, 198.0, 26.0, 12.0, 297.0, 205.0, 285.0, 199.0, 27.0, 12.0], 'c9c47393-0224-4e16-9210-228fa0e5211c.png': [234.0, 205.0, 221.0, 201.0, 25.0, 10.0, 293.0, 208.0, 283.0, 204.0, 25.0, 10.0], '25e6e872-8e34-435d-96a3-35684f17a4c2.png': [231.0, 208.0, 220.0, 205.0, 23.0, 8.0, 289.0, 209.0, 280.0, 206.0, 24.0, 8.0], '2c4bd664-fcf9-437f-8f3d-9dec427d255b.png': [227.0, 210.0, 218.0, 207.0, 23.0, 8.0, 292.0, 210.0, 277.0, 207.0, 24.0, 8.0], 'fbf5eaf8-a0bb-4a29-a888-57567b515e4e.png': [213.0, 218.0, 201.0, 214.0, 25.0, 10.0, 276.0, 216.0, 263.0, 212.0, 26.0, 10.0], 'e5e2fa0e-664b-4fb5-a679-439d1e35b3cb.png': [221.0, 219.0, 203.0, 213.0, 27.0, 12.0, 277.0, 215.0, 267.0, 209.0, 28.0, 13.0], 'ed30f2f0-9729-460a-a5e4-c5a43ae5b92d.png': [216.0, 219.0, 204.0, 213.0, 26.0, 13.0, 278.0, 217.0, 268.0, 211.0, 27.0, 13.0], 'c870d708-6f5f-4759-bb7e-1b0732545581.png': [229.0, 216.0, 217.0, 211.0, 26.0, 11.0, 293.0, 218.0, 280.0, 211.0, 27.0, 11.0], '7bfcfd1d-62fa-4c8e-a7d6-145f3eda7c71.png': [239.0, 216.0, 229.0, 214.0, 23.0, 7.0, 298.0, 219.0, 289.0, 216.0, 24.0, 8.0], 'e8139c37-af13-464c-95b6-4e89d7ab00a2.png': [267.0, 214.0, 258.0, 211.0, 23.0, 8.0, 325.0, 220.0, 316.0, 216.0, 23.0, 9.0], '4f48631e-d2c8-4f58-9184-ec358a14a958.png': [269.0, 213.0, 260.0, 210.0, 23.0, 8.0, 328.0, 219.0, 318.0, 215.0, 21.0, 9.0]}\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m image_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/Hossein/images/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/Hossein/data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mprocess_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperfect_user_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[97], line 5\u001b[0m, in \u001b[0;36mprocess_dataset\u001b[0;34m(csv_file, image_folder, perfect_user_data)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(csv_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[0;32m----> 5\u001b[0m         \u001b[43mprocess_participant_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperfect_user_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[89], line 5\u001b[0m, in \u001b[0;36mprocess_participant_data\u001b[0;34m(participant_data_path, perfect_user_data, participant_image_folder)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_participant_data\u001b[39m(participant_data_path, perfect_user_data, participant_image_folder):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(participant_data_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 5\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m      6\u001b[0m             parts \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parts) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m15\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/python/3.10.13/lib/python3.10/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to process the entire dataset\n",
    "def process_dataset(csv_file, image_folder, perfect_user_data):\n",
    "    with open(csv_file, 'r') as file:\n",
    "        for line in file:\n",
    "            process_participant_data(line.strip().split(',')[0], perfect_user_data, image_folder)  # strip the line to remove newline characters\n",
    "\n",
    "# Load perfect user data\n",
    "perfect_user_data = load_user_data('data/William/data.csv') \n",
    "print(perfect_user_data)\n",
    "\n",
    "# Now process the participant's dataset\n",
    "image_folder = './data/Hossein/images/'\n",
    "csv_file = './data/Hossein/data.csv'\n",
    "process_dataset(csv_file, image_folder, perfect_user_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data_processing)",
   "language": "python",
   "name": "data_processing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
