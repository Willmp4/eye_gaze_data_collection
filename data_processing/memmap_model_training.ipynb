{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "num_samples = 217636\n",
    "x_shape = (100, 200, 3)\n",
    "y_shape = (8,)\n",
    "\n",
    "x_dtype = 'float32'  # Determine the appropriate dtype\n",
    "y_dtype = 'float32'  # Determine the appropriate dtype\n",
    "\n",
    "# x_memmap = np.memmap('x_dataset_head_pos.memmap', dtype=x_dtype, mode='w+', shape=(num_samples,) + x_shape)\n",
    "# y_memmap = np.memmap('y_dataset_head_pos.memmap', dtype=y_dtype, mode='w+', shape=(num_samples,) + y_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "def process_and_combine_pkl_files_to_memmap(directory_path, x_memmap, y_memmap):\n",
    "    current_index = 0\n",
    "    \n",
    "    for file_path in glob.glob(directory_path + '/*.pkl'):\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        with open(file_path, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "            \n",
    "        if isinstance(data, dict) and 'X' in data and 'Y' in data:\n",
    "            X_data = data['X']\n",
    "            Y_data = data['Y']\n",
    "            \n",
    "            # Flatten Y_data\n",
    "            flattened_Y_data = []\n",
    "            for y in Y_data:\n",
    "                # Make sure to handle both cases where y[0] could be a list or a numpy array\n",
    "                gaze_data = np.array(y[0], dtype=np.float32) if isinstance(y[0], list) else y[0].astype(np.float32)\n",
    "                head_pose_data = y[1].astype(np.float32)\n",
    "                flattened_y = np.concatenate([gaze_data, head_pose_data])\n",
    "                flattened_Y_data.append(flattened_y)\n",
    "                \n",
    "            Y_data = np.array(flattened_Y_data, dtype=np.float32)\n",
    "        \n",
    "        else:\n",
    "            Y_numeric = []  # Initialize an empty list to hold the processed Y data\n",
    "            for y in data[1]:\n",
    "                numeric_values = y[:2] + y[3:]  # Adjusted to exclude index 3\n",
    "                Y_numeric.append([float(val) for val in numeric_values])  # Convert to float\n",
    "            \n",
    "            Y_data = np.array(Y_numeric, dtype=np.float32)  # Convert the list to a numpy array of type float32\n",
    "            X_data = np.array(data[0], dtype=np.float32)  # Ensure X_data is also properly formatted\n",
    "\n",
    "        num_samples_in_file = len(X_data)\n",
    "        x_batch = np.array(X_data, dtype=x_memmap.dtype).reshape((num_samples_in_file,) + x_shape)\n",
    "        \n",
    "        # No need to reshape Y_data as it is already in the correct shape after flattening\n",
    "        y_batch = Y_data  # It should already be in the correct shape\n",
    "        \n",
    "        # Ensure we do not exceed the allocated memmap size\n",
    "        if current_index + num_samples_in_file > len(x_memmap):\n",
    "            raise ValueError(\"The dataset is larger than expected.\")\n",
    "        \n",
    "        # Write directly to the memmap files\n",
    "        x_memmap[current_index:current_index + num_samples_in_file] = x_batch\n",
    "        y_memmap[current_index:current_index + num_samples_in_file] = y_batch\n",
    "        \n",
    "        current_index += num_samples_in_file\n",
    "        x_memmap.flush()\n",
    "        y_memmap.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = './process_MPIIGaze/batches_head_pos/' \n",
    "process_and_combine_pkl_files_to_memmap(directory_path, x_memmap, y_memmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def augment_image(image):\n",
    "    # Random rotation between -5 and 5 degrees\n",
    "    rows, cols = image.shape[0], image.shape[1]\n",
    "    rotation_angle = np.random.uniform(-3, 3)\n",
    "    M_rot = cv2.getRotationMatrix2D((cols / 2, rows / 2), rotation_angle, 1)\n",
    "    \n",
    "    # Random shift between -2% to 2% of the image size\n",
    "    max_shift = max(rows, cols) * 0.02\n",
    "    dx = np.random.uniform(-max_shift, max_shift)\n",
    "    dy = np.random.uniform(-max_shift, max_shift)\n",
    "    M_shift = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "    \n",
    "    # Apply the transformations\n",
    "    dst = cv2.warpAffine(image, M_rot, (cols, rows))\n",
    "    dst = cv2.warpAffine(dst, M_shift, (cols, rows))\n",
    "\n",
    "    brightness_factor = np.random.uniform(0.8, 1.2)\n",
    "    dst = dst * brightness_factor\n",
    "    dst = np.clip(dst, 0, 255).astype(image.dtype) * brightness_factor\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memmap_batch_generator(x_memmap_path, y_memmap_path, batch_size, indices, shuffle=True, augment=False):\n",
    "    x_memmap = np.memmap(x_memmap_path, dtype=x_dtype, mode='r', shape=(num_samples,) + x_shape)\n",
    "    y_memmap = np.memmap(y_memmap_path, dtype=y_dtype, mode='r', shape=(num_samples,) + y_shape)\n",
    "    \n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "        \n",
    "        for start_idx in range(0, len(indices), batch_size):\n",
    "            end_idx = min(start_idx + batch_size, len(indices))\n",
    "            batch_indices = indices[start_idx:end_idx]\n",
    "            \n",
    "            x_batch = x_memmap[batch_indices]\n",
    "            if augment:\n",
    "                # Apply augmentation to each image in the batch\n",
    "                x_batch = np.array([augment_image(image) for image in x_batch])\n",
    "            \n",
    "            gaze_data = y_memmap[batch_indices, :2]  # Assuming the first 2 values are for gaze\n",
    "            pose_data = y_memmap[batch_indices, 2:]  # The next 6 values for head pose\n",
    "            \n",
    "            # Yielding a batch of data with the correct format for multi-output\n",
    "            yield x_batch, {'gaze_output': gaze_data, 'pose_output': pose_data}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the memmap files\n",
    "x_memmap_path = 'x_dataset_head_pos.memmap'\n",
    "y_memmap_path = 'y_dataset_head_pos.memmap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import VGG16\n",
    "\n",
    "# Load VGG16 without the top classification layers\n",
    "vgg_base = VGG16(include_top=False, weights='imagenet', input_shape=(100, 200, 3))\n",
    "\n",
    "# Flatten the output of the convolutional base\n",
    "flat1 = Flatten()(vgg_base.output)\n",
    "\n",
    "# Common dense layers, now directly following the VGG16 output\n",
    "dense1 = Dense(4096, activation='relu', kernel_regularizer=l2(0.001), kernel_initializer='he_uniform')(flat1)\n",
    "dropout1 = Dropout(0.5)(dense1)\n",
    "\n",
    "# Gaze prediction branch (remains unchanged)\n",
    "gaze_dense = Dense(4096, activation='relu', kernel_initializer='he_uniform')(dropout1)\n",
    "gaze_dropout = Dropout(0.5)(gaze_dense)\n",
    "gaze_output = Dense(2, activation='sigmoid', name='gaze_output')(gaze_dropout)\n",
    "\n",
    "# Head pose estimation branch (remains unchanged)\n",
    "pose_dense = Dense(4096, activation='relu', kernel_initializer='he_uniform')(dropout1)\n",
    "pose_dropout = Dropout(0.5)(pose_dense)\n",
    "pose_output = Dense(6, activation='sigmoid', name='pose_output')(pose_dropout)\n",
    "\n",
    "# Final model now has only one input, which is the VGG16 input\n",
    "model = Model(inputs=vgg_base.input, outputs=[gaze_output, pose_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.00005), loss='mse', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('eye_gaze_v31_{epoch:02d}.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
    "\n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5780/5780 [==============================] - 1485s 255ms/step - loss: 0.2884 - gaze_output_loss: 0.0160 - pose_output_loss: 0.0047 - gaze_output_mae: 0.0849 - pose_output_mae: 0.0449 - val_loss: 0.0108 - val_gaze_output_loss: 0.0062 - val_pose_output_loss: 0.0033 - val_gaze_output_mae: 0.0526 - val_pose_output_mae: 0.0366\n",
      "Epoch 2/100\n",
      "5780/5780 [==============================] - 1486s 256ms/step - loss: 0.0098 - gaze_output_loss: 0.0060 - pose_output_loss: 0.0031 - gaze_output_mae: 0.0528 - pose_output_mae: 0.0355 - val_loss: 0.0089 - val_gaze_output_loss: 0.0056 - val_pose_output_loss: 0.0029 - val_gaze_output_mae: 0.0484 - val_pose_output_mae: 0.0337\n",
      "Epoch 3/100\n",
      "5780/5780 [==============================] - 1463s 253ms/step - loss: 0.0080 - gaze_output_loss: 0.0048 - pose_output_loss: 0.0027 - gaze_output_mae: 0.0471 - pose_output_mae: 0.0331 - val_loss: 0.0075 - val_gaze_output_loss: 0.0045 - val_pose_output_loss: 0.0026 - val_gaze_output_mae: 0.0420 - val_pose_output_mae: 0.0311\n",
      "Epoch 4/100\n",
      "5780/5780 [==============================] - 1485s 257ms/step - loss: 0.0069 - gaze_output_loss: 0.0041 - pose_output_loss: 0.0025 - gaze_output_mae: 0.0432 - pose_output_mae: 0.0314 - val_loss: 0.0075 - val_gaze_output_loss: 0.0046 - val_pose_output_loss: 0.0025 - val_gaze_output_mae: 0.0432 - val_pose_output_mae: 0.0320\n",
      "Epoch 5/100\n",
      "5780/5780 [==============================] - 1424s 246ms/step - loss: 0.0061 - gaze_output_loss: 0.0035 - pose_output_loss: 0.0023 - gaze_output_mae: 0.0400 - pose_output_mae: 0.0301 - val_loss: 0.0068 - val_gaze_output_loss: 0.0043 - val_pose_output_loss: 0.0021 - val_gaze_output_mae: 0.0416 - val_pose_output_mae: 0.0283\n",
      "Epoch 6/100\n",
      "5780/5780 [==============================] - 1416s 245ms/step - loss: 0.0055 - gaze_output_loss: 0.0031 - pose_output_loss: 0.0021 - gaze_output_mae: 0.0379 - pose_output_mae: 0.0288 - val_loss: 0.0066 - val_gaze_output_loss: 0.0042 - val_pose_output_loss: 0.0021 - val_gaze_output_mae: 0.0407 - val_pose_output_mae: 0.0279\n",
      "Epoch 7/100\n",
      "5780/5780 [==============================] - 1415s 245ms/step - loss: 0.0050 - gaze_output_loss: 0.0028 - pose_output_loss: 0.0019 - gaze_output_mae: 0.0358 - pose_output_mae: 0.0278 - val_loss: 0.0061 - val_gaze_output_loss: 0.0038 - val_pose_output_loss: 0.0020 - val_gaze_output_mae: 0.0367 - val_pose_output_mae: 0.0275\n",
      "Epoch 8/100\n",
      "5780/5780 [==============================] - 1406s 243ms/step - loss: 0.0046 - gaze_output_loss: 0.0025 - pose_output_loss: 0.0018 - gaze_output_mae: 0.0340 - pose_output_mae: 0.0268 - val_loss: 0.0061 - val_gaze_output_loss: 0.0040 - val_pose_output_loss: 0.0018 - val_gaze_output_mae: 0.0387 - val_pose_output_mae: 0.0255\n",
      "Epoch 9/100\n",
      "5780/5780 [==============================] - 1408s 244ms/step - loss: 0.0042 - gaze_output_loss: 0.0023 - pose_output_loss: 0.0017 - gaze_output_mae: 0.0325 - pose_output_mae: 0.0259 - val_loss: 0.0060 - val_gaze_output_loss: 0.0039 - val_pose_output_loss: 0.0019 - val_gaze_output_mae: 0.0377 - val_pose_output_mae: 0.0266\n",
      "Epoch 10/100\n",
      "5780/5780 [==============================] - 1403s 243ms/step - loss: 0.0039 - gaze_output_loss: 0.0021 - pose_output_loss: 0.0015 - gaze_output_mae: 0.0312 - pose_output_mae: 0.0251 - val_loss: 0.0057 - val_gaze_output_loss: 0.0037 - val_pose_output_loss: 0.0018 - val_gaze_output_mae: 0.0368 - val_pose_output_mae: 0.0246\n",
      "Epoch 11/100\n",
      "5780/5780 [==============================] - 1398s 242ms/step - loss: 0.0036 - gaze_output_loss: 0.0019 - pose_output_loss: 0.0014 - gaze_output_mae: 0.0301 - pose_output_mae: 0.0243 - val_loss: 0.0056 - val_gaze_output_loss: 0.0036 - val_pose_output_loss: 0.0017 - val_gaze_output_mae: 0.0354 - val_pose_output_mae: 0.0242\n",
      "Epoch 12/100\n",
      "5780/5780 [==============================] - 1394s 241ms/step - loss: 0.0033 - gaze_output_loss: 0.0018 - pose_output_loss: 0.0013 - gaze_output_mae: 0.0290 - pose_output_mae: 0.0236 - val_loss: 0.0056 - val_gaze_output_loss: 0.0037 - val_pose_output_loss: 0.0017 - val_gaze_output_mae: 0.0358 - val_pose_output_mae: 0.0237\n",
      "Epoch 13/100\n",
      "5780/5780 [==============================] - 1394s 241ms/step - loss: 0.0031 - gaze_output_loss: 0.0016 - pose_output_loss: 0.0012 - gaze_output_mae: 0.0280 - pose_output_mae: 0.0229 - val_loss: 0.0055 - val_gaze_output_loss: 0.0036 - val_pose_output_loss: 0.0016 - val_gaze_output_mae: 0.0351 - val_pose_output_mae: 0.0232\n",
      "Epoch 14/100\n",
      "5780/5780 [==============================] - 1394s 241ms/step - loss: 0.0029 - gaze_output_loss: 0.0015 - pose_output_loss: 0.0012 - gaze_output_mae: 0.0271 - pose_output_mae: 0.0223 - val_loss: 0.0054 - val_gaze_output_loss: 0.0036 - val_pose_output_loss: 0.0016 - val_gaze_output_mae: 0.0348 - val_pose_output_mae: 0.0230\n",
      "Epoch 15/100\n",
      "5780/5780 [==============================] - 1384s 240ms/step - loss: 0.0027 - gaze_output_loss: 0.0014 - pose_output_loss: 0.0011 - gaze_output_mae: 0.0263 - pose_output_mae: 0.0217 - val_loss: 0.0053 - val_gaze_output_loss: 0.0035 - val_pose_output_loss: 0.0016 - val_gaze_output_mae: 0.0338 - val_pose_output_mae: 0.0232\n",
      "Epoch 16/100\n",
      "5780/5780 [==============================] - 1389s 240ms/step - loss: 0.0026 - gaze_output_loss: 0.0013 - pose_output_loss: 0.0010 - gaze_output_mae: 0.0256 - pose_output_mae: 0.0211 - val_loss: 0.0053 - val_gaze_output_loss: 0.0035 - val_pose_output_loss: 0.0016 - val_gaze_output_mae: 0.0345 - val_pose_output_mae: 0.0227\n",
      "Epoch 17/100\n",
      "5780/5780 [==============================] - 1379s 239ms/step - loss: 0.0024 - gaze_output_loss: 0.0013 - pose_output_loss: 9.3835e-04 - gaze_output_mae: 0.0249 - pose_output_mae: 0.0206 - val_loss: 0.0054 - val_gaze_output_loss: 0.0036 - val_pose_output_loss: 0.0016 - val_gaze_output_mae: 0.0360 - val_pose_output_mae: 0.0218\n",
      "Epoch 18/100\n",
      "5780/5780 [==============================] - 1379s 239ms/step - loss: 0.0023 - gaze_output_loss: 0.0012 - pose_output_loss: 8.8145e-04 - gaze_output_mae: 0.0242 - pose_output_mae: 0.0201 - val_loss: 0.0054 - val_gaze_output_loss: 0.0037 - val_pose_output_loss: 0.0016 - val_gaze_output_mae: 0.0363 - val_pose_output_mae: 0.0222\n",
      "Epoch 19/100\n",
      "5780/5780 [==============================] - 1381s 239ms/step - loss: 0.0022 - gaze_output_loss: 0.0011 - pose_output_loss: 8.2762e-04 - gaze_output_mae: 0.0236 - pose_output_mae: 0.0196 - val_loss: 0.0054 - val_gaze_output_loss: 0.0036 - val_pose_output_loss: 0.0016 - val_gaze_output_mae: 0.0347 - val_pose_output_mae: 0.0225\n",
      "Epoch 20/100\n",
      "5780/5780 [==============================] - 1382s 239ms/step - loss: 0.0021 - gaze_output_loss: 0.0011 - pose_output_loss: 7.7389e-04 - gaze_output_mae: 0.0232 - pose_output_mae: 0.0192 - val_loss: 0.0053 - val_gaze_output_loss: 0.0035 - val_pose_output_loss: 0.0016 - val_gaze_output_mae: 0.0342 - val_pose_output_mae: 0.0221\n",
      "Epoch 21/100\n",
      "5780/5780 [==============================] - 1373s 238ms/step - loss: 0.0020 - gaze_output_loss: 0.0010 - pose_output_loss: 7.3091e-04 - gaze_output_mae: 0.0227 - pose_output_mae: 0.0188 - val_loss: 0.0052 - val_gaze_output_loss: 0.0035 - val_pose_output_loss: 0.0016 - val_gaze_output_mae: 0.0340 - val_pose_output_mae: 0.0217\n",
      "Epoch 22/100\n",
      "5780/5780 [==============================] - 1367s 236ms/step - loss: 0.0019 - gaze_output_loss: 0.0010 - pose_output_loss: 6.8693e-04 - gaze_output_mae: 0.0223 - pose_output_mae: 0.0183 - val_loss: 0.0052 - val_gaze_output_loss: 0.0034 - val_pose_output_loss: 0.0016 - val_gaze_output_mae: 0.0335 - val_pose_output_mae: 0.0217\n",
      "Epoch 23/100\n",
      "5780/5780 [==============================] - 1371s 237ms/step - loss: 0.0018 - gaze_output_loss: 9.7202e-04 - pose_output_loss: 6.5409e-04 - gaze_output_mae: 0.0219 - pose_output_mae: 0.0180 - val_loss: 0.0051 - val_gaze_output_loss: 0.0034 - val_pose_output_loss: 0.0015 - val_gaze_output_mae: 0.0336 - val_pose_output_mae: 0.0213\n",
      "Epoch 24/100\n",
      "5780/5780 [==============================] - 1377s 238ms/step - loss: 0.0017 - gaze_output_loss: 9.2693e-04 - pose_output_loss: 6.2664e-04 - gaze_output_mae: 0.0215 - pose_output_mae: 0.0177 - val_loss: 0.0051 - val_gaze_output_loss: 0.0034 - val_pose_output_loss: 0.0016 - val_gaze_output_mae: 0.0331 - val_pose_output_mae: 0.0220\n",
      "Epoch 25/100\n",
      "5780/5780 [==============================] - 1387s 240ms/step - loss: 0.0017 - gaze_output_loss: 9.0348e-04 - pose_output_loss: 5.9483e-04 - gaze_output_mae: 0.0212 - pose_output_mae: 0.0173 - val_loss: 0.0051 - val_gaze_output_loss: 0.0034 - val_pose_output_loss: 0.0015 - val_gaze_output_mae: 0.0336 - val_pose_output_mae: 0.0211\n",
      "Epoch 26/100\n",
      "5780/5780 [==============================] - 1375s 238ms/step - loss: 0.0016 - gaze_output_loss: 8.8633e-04 - pose_output_loss: 5.7267e-04 - gaze_output_mae: 0.0210 - pose_output_mae: 0.0171 - val_loss: 0.0052 - val_gaze_output_loss: 0.0034 - val_pose_output_loss: 0.0016 - val_gaze_output_mae: 0.0336 - val_pose_output_mae: 0.0218\n",
      "Epoch 27/100\n",
      "5780/5780 [==============================] - 1367s 237ms/step - loss: 0.0016 - gaze_output_loss: 8.5846e-04 - pose_output_loss: 5.5360e-04 - gaze_output_mae: 0.0206 - pose_output_mae: 0.0168 - val_loss: 0.0052 - val_gaze_output_loss: 0.0035 - val_pose_output_loss: 0.0015 - val_gaze_output_mae: 0.0352 - val_pose_output_mae: 0.0210\n",
      "Epoch 28/100\n",
      "5780/5780 [==============================] - 1367s 236ms/step - loss: 0.0015 - gaze_output_loss: 8.3139e-04 - pose_output_loss: 5.3516e-04 - gaze_output_mae: 0.0203 - pose_output_mae: 0.0166 - val_loss: 0.0050 - val_gaze_output_loss: 0.0033 - val_pose_output_loss: 0.0015 - val_gaze_output_mae: 0.0324 - val_pose_output_mae: 0.0207\n",
      "Epoch 29/100\n",
      "5780/5780 [==============================] - 1415s 245ms/step - loss: 0.0015 - gaze_output_loss: 8.1521e-04 - pose_output_loss: 5.1503e-04 - gaze_output_mae: 0.0201 - pose_output_mae: 0.0163 - val_loss: 0.0050 - val_gaze_output_loss: 0.0034 - val_pose_output_loss: 0.0015 - val_gaze_output_mae: 0.0334 - val_pose_output_mae: 0.0207\n",
      "Epoch 30/100\n",
      "   7/5780 [..............................] - ETA: 27:19 - loss: 0.0014 - gaze_output_loss: 7.2564e-04 - pose_output_loss: 4.7655e-04 - gaze_output_mae: 0.0209 - pose_output_mae: 0.0163"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m validation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(val_indices) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "indices = np.arange(num_samples)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Split indices into training and validation sets\n",
    "train_indices = indices[:int(0.85 * num_samples)]  # 85% for training\n",
    "val_indices = indices[int(0.85 * num_samples):]  # 15% for validation\n",
    "\n",
    "# Instantiate the generators\n",
    "train_generator = memmap_batch_generator(x_memmap_path, y_memmap_path, batch_size, train_indices, shuffle=True)\n",
    "validation_generator = memmap_batch_generator(x_memmap_path, y_memmap_path, batch_size, val_indices, shuffle=False)\n",
    "\n",
    "\n",
    "# Calculate steps\n",
    "steps_per_epoch = len(train_indices) // batch_size\n",
    "validation_steps = len(val_indices) // batch_size\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x=train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save('eye_gaze_v30.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_9_tf_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
