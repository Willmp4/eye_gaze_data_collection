{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import dlib\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eye_region(frame, eye_coords, target_size=(40, 48)):\n",
    "    \"\"\"\n",
    "    Preprocesses the eye region for the CNN model.\n",
    "    Args:\n",
    "        frame: The input image frame (in BGR format).\n",
    "        eye_coords: Coordinates of the eye region.\n",
    "        target_size: The target size for each eye region.\n",
    "    Returns:\n",
    "        The preprocessed eye region.\n",
    "    \"\"\"\n",
    "    x_min = min(x for x, y in eye_coords)\n",
    "    x_max = max(x for x, y in eye_coords)\n",
    "    y_min = min(y for x, y in eye_coords)\n",
    "    y_max = max(y for x, y in eye_coords)\n",
    "\n",
    "    # Cropping the eye region based on the extremities of the landmarks\n",
    "    cropped_eye = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    # Resizing the cropped eye region to the target size\n",
    "    resized_eye = cv2.resize(cropped_eye, target_size)\n",
    "\n",
    "    return resized_eye.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_eyes(frame):\n",
    "    \"\"\"\n",
    "    Detects and combines the eye regions from the frame.\n",
    "    Args:\n",
    "        frame: The input image frame.\n",
    "    Returns:\n",
    "        The combined eye regions, or None if not detected.\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "\n",
    "        # Extract the coordinates for each eye\n",
    "        left_eye = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(36, 42)]\n",
    "        right_eye = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(42, 48)]\n",
    "\n",
    "        # Preprocess each eye region\n",
    "        left_eye_region = preprocess_eye_region(frame, left_eye)\n",
    "\n",
    "        right_eye_region = preprocess_eye_region(frame, right_eye)\n",
    "\n",
    "        # Combine the eyes side by side\n",
    "        combined_eyes = np.hstack([left_eye_region, right_eye_region])\n",
    "\n",
    "        # Ensure the combined eyes image has the correct shape\n",
    "        if combined_eyes.shape[1] != 80:\n",
    "            raise ValueError(\"Combined eyes region does not match the expected width.\")\n",
    "        return combined_eyes\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_head_pose(head_pose_data, rotation_scale=180, translation_max_displacement=None):\n",
    "    \"\"\"\n",
    "    Normalizes the head pose data.\n",
    "    Args:\n",
    "        head_pose_data: List containing the head pose data (rotation and translation vectors).\n",
    "        rotation_scale: Maximum value for the rotation vector components (180 for degrees, np.pi for radians).\n",
    "        translation_max_displacement: A tuple (max_x, max_y, max_z) representing the maximum displacement in each axis. If None, standard deviation normalization will be used.\n",
    "\n",
    "    Returns:\n",
    "        Normalized head pose data.\n",
    "    \"\"\"\n",
    "    # Normalize rotation vectors\n",
    "    normalized_rotation = np.array(head_pose_data[:3]) / rotation_scale\n",
    "\n",
    "    # Normalize translation vectors\n",
    "    if translation_max_displacement:\n",
    "        max_x, max_y, max_z = translation_max_displacement\n",
    "        normalized_translation = np.array(head_pose_data[3:]) / np.array([max_x, max_y, max_z])\n",
    "    else:\n",
    "        # Standard deviation normalization\n",
    "        translation_vector = np.array(head_pose_data[3:])\n",
    "        std_dev = np.std(translation_vector)\n",
    "        mean_val = np.mean(translation_vector)\n",
    "        normalized_translation = (translation_vector - mean_val) / std_dev\n",
    "\n",
    "    return np.concatenate([normalized_rotation, normalized_translation]).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "# Assuming normalize_head_pose and get_combined_eyes are defined as before\n",
    "def get_screen_size(metadata_file_path):\n",
    "    with open(metadata_file_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "        # Check if 'screenData' is a key in the metadata\n",
    "        if 'screenData' in metadata:\n",
    "            metadata = metadata['screenData']\n",
    "        # Otherwise, assume the metadata is already at the top level\n",
    "\n",
    "        screen_width = metadata.get('screenWidth')\n",
    "        screen_height = metadata.get('screenHeight')\n",
    "\n",
    "        if screen_width is None or screen_height is None:\n",
    "            raise ValueError(\"Screen size not found in metadata\")\n",
    "\n",
    "        return screen_width, screen_height\n",
    "\n",
    "def parse_head_pose_data(row):\n",
    "    # Split the strings and convert to float\n",
    "    rotation_str, translation_str = row['head_pose'], row['head_translation']\n",
    "    rotation = [float(x) for x in rotation_str.strip('\"').split(',')]\n",
    "    translation = [float(x) for x in translation_str.strip('\"').split(',')]\n",
    "    return rotation + translation  # Combine into a single list\n",
    "\n",
    "def prepare_dataset(base_dir):\n",
    "    X, Y = [], []\n",
    "    processed_files = set()\n",
    "    column_names = ['image_path', 'cursor_x', 'cursor_y', 'left_pup', 'eye_y1', 'eye_x2', 'eye_y2', 'eye_x3', 'eye_y3', 'eye_x4', 'eye_y4', 'eye_x5', 'eye_y5', 'eye_x6', 'eye_y6', 'head_pose', 'head_translation']\n",
    "\n",
    "    for subdir in glob(os.path.join(base_dir, '*/')):\n",
    "        print(f\"Processing directory: {subdir}\")\n",
    "        metadata_file_path = os.path.join(subdir, 'metadata.json')\n",
    "        screen_width, screen_height = get_screen_size(metadata_file_path)\n",
    "        print(f\"Screen size: {screen_width}x{screen_height}\")\n",
    "\n",
    "        # Find any CSV files in the directory\n",
    "        csv_files = glob(os.path.join(subdir, '*.csv'))\n",
    "        #skip calibration files\n",
    "        # csv_files = [f for f in csv_files if 'calibration' not in f]\n",
    "\n",
    "        for data_file_path in csv_files:\n",
    "            if data_file_path in processed_files:\n",
    "                # Skip this file since it has already been processed\n",
    "                continue\n",
    "            processed_files.add(data_file_path)  # Mark this file as processed\n",
    "\n",
    "            print(f\"Processing data CSV file: {data_file_path}\")\n",
    "            data = pd.read_csv(data_file_path, header=None, names=column_names)\n",
    "\n",
    "            if not csv_files:\n",
    "                print(f\"No data CSV file found in directory: {subdir}\")\n",
    "                continue\n",
    "            # Find any directory that contains image files (assuming JPEG for example)\n",
    "            img_folders = [d for d in os.listdir(subdir) if os.path.isdir(os.path.join(subdir, d)) and glob(os.path.join(subdir, d, '*.png'))]\n",
    "            if not img_folders:\n",
    "                print(f\"No image folder found that contains images in directory: {subdir}\")\n",
    "                continue\n",
    "            data = pd.read_csv(data_file_path, header=None, names=column_names)\n",
    "            # print how many columns \n",
    "            print(data.shape)\n",
    "\n",
    "            for index, row in data.iterrows():\n",
    "                # Directly use the image path from the dataframe\n",
    "                img_path = os.path.join(row['image_path'])\n",
    "                cursor_x, cursor_y = row['cursor_x'], row['cursor_y']\n",
    "                eye_box_pupil_data = row[3:15].tolist()\n",
    "                head_pose_data = parse_head_pose_data(row)\n",
    "\n",
    "                normalized_eye_box_pupil_data = [float(coord) / screen_width if i % 2 == 0 else float(coord) / screen_height for i, coord in enumerate(eye_box_pupil_data)]\n",
    "                normalized_head_pose_data = normalize_head_pose(head_pose_data)\n",
    "\n",
    "                # Load the image\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    print(f\"Image not found: {img_path}\")\n",
    "                    continue\n",
    "\n",
    "                combined_eyes = get_combined_eyes(img)\n",
    "\n",
    "                # Append to datasets\n",
    "                Y.append([cursor_x / screen_width, cursor_y / screen_height] + normalized_eye_box_pupil_data + normalized_head_pose_data)\n",
    "                X.append(combined_eyes)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing directory: ./data\\eloise\\\n",
      "Screen size: 1440x900\n",
      "Processing data CSV file: ./data\\eloise\\calibration_data.csv\n",
      "(56, 17)\n",
      "Processing directory: ./data\\Hossein\\\n",
      "Screen size: 1536x864\n",
      "Processing data CSV file: ./data\\Hossein\\calibration_data.csv\n",
      "(53, 17)\n",
      "Processing data CSV file: ./data\\Hossein\\data.csv\n",
      "(19, 17)\n",
      "Processing directory: ./data\\koala\\\n",
      "Screen size: 1536x864\n",
      "Processing data CSV file: ./data\\koala\\calibration_data.csv\n",
      "(9, 17)\n",
      "Processing data CSV file: ./data\\koala\\eye_gaze_data.csv\n",
      "(2, 17)\n",
      "Processing directory: ./data\\melissa\\\n",
      "Screen size: 1710x1112\n",
      "Processing data CSV file: ./data\\melissa\\calibration_data.csv\n",
      "(49, 17)\n",
      "Processing data CSV file: ./data\\melissa\\data.csv\n",
      "(74, 17)\n",
      "Processing directory: ./data\\Naia\\\n",
      "Screen size: 1440x900\n",
      "Processing data CSV file: ./data\\Naia\\calibration_data.csv\n",
      "(53, 17)\n",
      "Processing data CSV file: ./data\\Naia\\eye_gaze_data.csv\n",
      "(90, 17)\n",
      "Processing directory: ./data\\PerfectUser\\\n",
      "Screen size: 1536x864\n",
      "Processing data CSV file: ./data\\PerfectUser\\calibration_data.csv\n",
      "(53, 17)\n",
      "Processing data CSV file: ./data\\PerfectUser\\eye_gaze_data.csv\n",
      "(4, 17)\n",
      "Processing directory: ./data\\Shaq\\\n",
      "Screen size: 1280x720\n",
      "Processing data CSV file: ./data\\Shaq\\calibration_data.csv\n",
      "(53, 17)\n",
      "Processing data CSV file: ./data\\Shaq\\data.csv\n",
      "(29, 17)\n",
      "Processing directory: ./data\\Will\\\n",
      "Screen size: 1707x960\n",
      "Processing data CSV file: ./data\\Will\\calibration_data.csv\n",
      "(173, 17)\n",
      "Processing data CSV file: ./data\\Will\\eye_gaze_data.csv\n",
      "(358, 17)\n",
      "Processing directory: ./data\\William\\\n",
      "Screen size: 1707x960\n",
      "Processing data CSV file: ./data\\William\\calibration_data.csv\n",
      "(210, 17)\n",
      "Processing data CSV file: ./data\\William\\eye_gaze_data.csv\n",
      "(568, 17)\n",
      "Processing directory: ./data\\WilliamOld\\\n",
      "Screen size: 2560x1440\n",
      "Processing data CSV file: ./data\\WilliamOld\\data1.csv\n",
      "(1810, 17)\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "base_dir = './data'\n",
    "X, Y = prepare_dataset(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_filtered = [img for img in X if img is not None and isinstance(img, np.ndarray)]\n",
    "Y_filtered = [Y[i] for i in range(len(Y)) if X[i] is not None and isinstance(X[i], np.ndarray)]\n",
    "\n",
    "X_filtered = np.array(X_filtered)\n",
    "\n",
    "Y_filtered = np.array(Y_filtered)\n",
    "Y_filtered = Y_filtered[:, :14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3663, 3663)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_filtered), len(Y_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_filtered, Y_filtered, test_size=0.2, random_state=42)\n",
    "#Val data\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense, MaxPool2D\n",
    "from keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 80, 3)), \n",
    "    MaxPool2D(),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(14) \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[MeanSquaredError(), MeanAbsoluteError()])\n",
    "model.fit(X_train, Y_train, epochs=100, validation_split=0.1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "147/147 [==============================] - 9s 54ms/step - loss: 1.3619 - mean_squared_error: 1.2308 - mean_absolute_error: 0.8173 - val_loss: 0.3067 - val_mean_squared_error: 0.1757 - val_mean_absolute_error: 0.3129\n",
      "Epoch 2/100\n",
      "147/147 [==============================] - 8s 56ms/step - loss: 0.4491 - mean_squared_error: 0.3182 - mean_absolute_error: 0.4180 - val_loss: 0.4776 - val_mean_squared_error: 0.3469 - val_mean_absolute_error: 0.4616\n",
      "Epoch 3/100\n",
      "147/147 [==============================] - 9s 59ms/step - loss: 0.2950 - mean_squared_error: 0.1643 - mean_absolute_error: 0.2886 - val_loss: 0.4031 - val_mean_squared_error: 0.2725 - val_mean_absolute_error: 0.3998\n",
      "Epoch 4/100\n",
      "147/147 [==============================] - 9s 59ms/step - loss: 0.2552 - mean_squared_error: 0.1248 - mean_absolute_error: 0.2469 - val_loss: 0.2723 - val_mean_squared_error: 0.1420 - val_mean_absolute_error: 0.2757\n",
      "Epoch 5/100\n",
      "147/147 [==============================] - 9s 59ms/step - loss: 0.2280 - mean_squared_error: 0.0979 - mean_absolute_error: 0.2160 - val_loss: 0.2279 - val_mean_squared_error: 0.0979 - val_mean_absolute_error: 0.2188\n",
      "Epoch 6/100\n",
      "147/147 [==============================] - 9s 59ms/step - loss: 0.2201 - mean_squared_error: 0.0903 - mean_absolute_error: 0.2065 - val_loss: 0.2170 - val_mean_squared_error: 0.0873 - val_mean_absolute_error: 0.2020\n",
      "Epoch 7/100\n",
      "147/147 [==============================] - 9s 59ms/step - loss: 0.2160 - mean_squared_error: 0.0865 - mean_absolute_error: 0.1995 - val_loss: 0.2128 - val_mean_squared_error: 0.0834 - val_mean_absolute_error: 0.1954\n",
      "Epoch 8/100\n",
      "147/147 [==============================] - 9s 59ms/step - loss: 0.2108 - mean_squared_error: 0.0815 - mean_absolute_error: 0.1930 - val_loss: 0.2101 - val_mean_squared_error: 0.0810 - val_mean_absolute_error: 0.1916\n",
      "Epoch 9/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.2063 - mean_squared_error: 0.0773 - mean_absolute_error: 0.1877 - val_loss: 0.2068 - val_mean_squared_error: 0.0780 - val_mean_absolute_error: 0.1871\n",
      "Epoch 10/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.2038 - mean_squared_error: 0.0752 - mean_absolute_error: 0.1840 - val_loss: 0.2047 - val_mean_squared_error: 0.0762 - val_mean_absolute_error: 0.1842\n",
      "Epoch 11/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.2034 - mean_squared_error: 0.0751 - mean_absolute_error: 0.1833 - val_loss: 0.2030 - val_mean_squared_error: 0.0748 - val_mean_absolute_error: 0.1826\n",
      "Epoch 12/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1997 - mean_squared_error: 0.0716 - mean_absolute_error: 0.1791 - val_loss: 0.2010 - val_mean_squared_error: 0.0732 - val_mean_absolute_error: 0.1796\n",
      "Epoch 13/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1984 - mean_squared_error: 0.0706 - mean_absolute_error: 0.1770 - val_loss: 0.1999 - val_mean_squared_error: 0.0723 - val_mean_absolute_error: 0.1780\n",
      "Epoch 14/100\n",
      "147/147 [==============================] - 9s 60ms/step - loss: 0.1983 - mean_squared_error: 0.0709 - mean_absolute_error: 0.1769 - val_loss: 0.1985 - val_mean_squared_error: 0.0713 - val_mean_absolute_error: 0.1765\n",
      "Epoch 15/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1966 - mean_squared_error: 0.0696 - mean_absolute_error: 0.1749 - val_loss: 0.1964 - val_mean_squared_error: 0.0695 - val_mean_absolute_error: 0.1736\n",
      "Epoch 16/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1946 - mean_squared_error: 0.0679 - mean_absolute_error: 0.1726 - val_loss: 0.1953 - val_mean_squared_error: 0.0687 - val_mean_absolute_error: 0.1727\n",
      "Epoch 17/100\n",
      "147/147 [==============================] - 9s 60ms/step - loss: 0.1951 - mean_squared_error: 0.0687 - mean_absolute_error: 0.1727 - val_loss: 0.1943 - val_mean_squared_error: 0.0680 - val_mean_absolute_error: 0.1716\n",
      "Epoch 18/100\n",
      "147/147 [==============================] - 9s 60ms/step - loss: 0.1932 - mean_squared_error: 0.0672 - mean_absolute_error: 0.1703 - val_loss: 0.1930 - val_mean_squared_error: 0.0671 - val_mean_absolute_error: 0.1706\n",
      "Epoch 19/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1929 - mean_squared_error: 0.0671 - mean_absolute_error: 0.1701 - val_loss: 0.1919 - val_mean_squared_error: 0.0663 - val_mean_absolute_error: 0.1682\n",
      "Epoch 20/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1919 - mean_squared_error: 0.0666 - mean_absolute_error: 0.1696 - val_loss: 0.1914 - val_mean_squared_error: 0.0662 - val_mean_absolute_error: 0.1684\n",
      "Epoch 21/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1910 - mean_squared_error: 0.0660 - mean_absolute_error: 0.1687 - val_loss: 0.1906 - val_mean_squared_error: 0.0658 - val_mean_absolute_error: 0.1673\n",
      "Epoch 22/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1904 - mean_squared_error: 0.0657 - mean_absolute_error: 0.1675 - val_loss: 0.1895 - val_mean_squared_error: 0.0650 - val_mean_absolute_error: 0.1668\n",
      "Epoch 23/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1892 - mean_squared_error: 0.0649 - mean_absolute_error: 0.1662 - val_loss: 0.1891 - val_mean_squared_error: 0.0650 - val_mean_absolute_error: 0.1662\n",
      "Epoch 24/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1888 - mean_squared_error: 0.0649 - mean_absolute_error: 0.1661 - val_loss: 0.1878 - val_mean_squared_error: 0.0641 - val_mean_absolute_error: 0.1648\n",
      "Epoch 25/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1878 - mean_squared_error: 0.0642 - mean_absolute_error: 0.1650 - val_loss: 0.1871 - val_mean_squared_error: 0.0638 - val_mean_absolute_error: 0.1647\n",
      "Epoch 26/100\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 0.1868 - mean_squared_error: 0.0636 - mean_absolute_error: 0.1644 - val_loss: 0.1860 - val_mean_squared_error: 0.0631 - val_mean_absolute_error: 0.1638\n",
      "Epoch 27/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1863 - mean_squared_error: 0.0636 - mean_absolute_error: 0.1642 - val_loss: 0.1849 - val_mean_squared_error: 0.0624 - val_mean_absolute_error: 0.1630\n",
      "Epoch 28/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1854 - mean_squared_error: 0.0630 - mean_absolute_error: 0.1633 - val_loss: 0.1835 - val_mean_squared_error: 0.0613 - val_mean_absolute_error: 0.1600\n",
      "Epoch 29/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1843 - mean_squared_error: 0.0624 - mean_absolute_error: 0.1619 - val_loss: 0.1829 - val_mean_squared_error: 0.0612 - val_mean_absolute_error: 0.1594\n",
      "Epoch 30/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1842 - mean_squared_error: 0.0627 - mean_absolute_error: 0.1619 - val_loss: 0.1822 - val_mean_squared_error: 0.0608 - val_mean_absolute_error: 0.1588\n",
      "Epoch 31/100\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 0.1835 - mean_squared_error: 0.0624 - mean_absolute_error: 0.1611 - val_loss: 0.1814 - val_mean_squared_error: 0.0605 - val_mean_absolute_error: 0.1581\n",
      "Epoch 32/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1830 - mean_squared_error: 0.0624 - mean_absolute_error: 0.1608 - val_loss: 0.1807 - val_mean_squared_error: 0.0603 - val_mean_absolute_error: 0.1583\n",
      "Epoch 33/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1818 - mean_squared_error: 0.0616 - mean_absolute_error: 0.1600 - val_loss: 0.1798 - val_mean_squared_error: 0.0598 - val_mean_absolute_error: 0.1570\n",
      "Epoch 34/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1810 - mean_squared_error: 0.0612 - mean_absolute_error: 0.1589 - val_loss: 0.1790 - val_mean_squared_error: 0.0594 - val_mean_absolute_error: 0.1564\n",
      "Epoch 35/100\n",
      "147/147 [==============================] - 9s 60ms/step - loss: 0.1810 - mean_squared_error: 0.0616 - mean_absolute_error: 0.1593 - val_loss: 0.1780 - val_mean_squared_error: 0.0589 - val_mean_absolute_error: 0.1557\n",
      "Epoch 36/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1798 - mean_squared_error: 0.0609 - mean_absolute_error: 0.1585 - val_loss: 0.1775 - val_mean_squared_error: 0.0588 - val_mean_absolute_error: 0.1546\n",
      "Epoch 37/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1790 - mean_squared_error: 0.0606 - mean_absolute_error: 0.1579 - val_loss: 0.1762 - val_mean_squared_error: 0.0580 - val_mean_absolute_error: 0.1531\n",
      "Epoch 38/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1783 - mean_squared_error: 0.0604 - mean_absolute_error: 0.1576 - val_loss: 0.1752 - val_mean_squared_error: 0.0575 - val_mean_absolute_error: 0.1523\n",
      "Epoch 39/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1774 - mean_squared_error: 0.0600 - mean_absolute_error: 0.1565 - val_loss: 0.1746 - val_mean_squared_error: 0.0574 - val_mean_absolute_error: 0.1529\n",
      "Epoch 40/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1770 - mean_squared_error: 0.0600 - mean_absolute_error: 0.1566 - val_loss: 0.1740 - val_mean_squared_error: 0.0573 - val_mean_absolute_error: 0.1529\n",
      "Epoch 41/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1759 - mean_squared_error: 0.0594 - mean_absolute_error: 0.1559 - val_loss: 0.1730 - val_mean_squared_error: 0.0568 - val_mean_absolute_error: 0.1514\n",
      "Epoch 42/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1754 - mean_squared_error: 0.0594 - mean_absolute_error: 0.1552 - val_loss: 0.1725 - val_mean_squared_error: 0.0568 - val_mean_absolute_error: 0.1507\n",
      "Epoch 43/100\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 0.1747 - mean_squared_error: 0.0593 - mean_absolute_error: 0.1549 - val_loss: 0.1710 - val_mean_squared_error: 0.0558 - val_mean_absolute_error: 0.1503\n",
      "Epoch 44/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1735 - mean_squared_error: 0.0586 - mean_absolute_error: 0.1544 - val_loss: 0.1693 - val_mean_squared_error: 0.0547 - val_mean_absolute_error: 0.1503\n",
      "Epoch 45/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1731 - mean_squared_error: 0.0587 - mean_absolute_error: 0.1541 - val_loss: 0.1692 - val_mean_squared_error: 0.0552 - val_mean_absolute_error: 0.1484\n",
      "Epoch 46/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1722 - mean_squared_error: 0.0584 - mean_absolute_error: 0.1535 - val_loss: 0.1686 - val_mean_squared_error: 0.0551 - val_mean_absolute_error: 0.1481\n",
      "Epoch 47/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1712 - mean_squared_error: 0.0579 - mean_absolute_error: 0.1526 - val_loss: 0.1675 - val_mean_squared_error: 0.0546 - val_mean_absolute_error: 0.1475\n",
      "Epoch 48/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1702 - mean_squared_error: 0.0575 - mean_absolute_error: 0.1524 - val_loss: 0.1669 - val_mean_squared_error: 0.0545 - val_mean_absolute_error: 0.1472\n",
      "Epoch 49/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1696 - mean_squared_error: 0.0576 - mean_absolute_error: 0.1514 - val_loss: 0.1661 - val_mean_squared_error: 0.0543 - val_mean_absolute_error: 0.1463\n",
      "Epoch 50/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1689 - mean_squared_error: 0.0574 - mean_absolute_error: 0.1516 - val_loss: 0.1653 - val_mean_squared_error: 0.0541 - val_mean_absolute_error: 0.1462\n",
      "Epoch 51/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1684 - mean_squared_error: 0.0574 - mean_absolute_error: 0.1510 - val_loss: 0.1640 - val_mean_squared_error: 0.0534 - val_mean_absolute_error: 0.1466\n",
      "Epoch 52/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1670 - mean_squared_error: 0.0567 - mean_absolute_error: 0.1504 - val_loss: 0.1628 - val_mean_squared_error: 0.0528 - val_mean_absolute_error: 0.1440\n",
      "Epoch 53/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1659 - mean_squared_error: 0.0562 - mean_absolute_error: 0.1491 - val_loss: 0.1620 - val_mean_squared_error: 0.0526 - val_mean_absolute_error: 0.1435\n",
      "Epoch 54/100\n",
      "147/147 [==============================] - 10s 65ms/step - loss: 0.1657 - mean_squared_error: 0.0566 - mean_absolute_error: 0.1497 - val_loss: 0.1608 - val_mean_squared_error: 0.0521 - val_mean_absolute_error: 0.1446\n",
      "Epoch 55/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1650 - mean_squared_error: 0.0565 - mean_absolute_error: 0.1496 - val_loss: 0.1601 - val_mean_squared_error: 0.0520 - val_mean_absolute_error: 0.1429\n",
      "Epoch 56/100\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 0.1636 - mean_squared_error: 0.0558 - mean_absolute_error: 0.1482 - val_loss: 0.1594 - val_mean_squared_error: 0.0520 - val_mean_absolute_error: 0.1425\n",
      "Epoch 57/100\n",
      "147/147 [==============================] - 10s 65ms/step - loss: 0.1634 - mean_squared_error: 0.0563 - mean_absolute_error: 0.1491 - val_loss: 0.1591 - val_mean_squared_error: 0.0523 - val_mean_absolute_error: 0.1441\n",
      "Epoch 58/100\n",
      "147/147 [==============================] - 10s 71ms/step - loss: 0.1621 - mean_squared_error: 0.0557 - mean_absolute_error: 0.1475 - val_loss: 0.1576 - val_mean_squared_error: 0.0515 - val_mean_absolute_error: 0.1436\n",
      "Epoch 59/100\n",
      "147/147 [==============================] - 10s 70ms/step - loss: 0.1611 - mean_squared_error: 0.0553 - mean_absolute_error: 0.1478 - val_loss: 0.1567 - val_mean_squared_error: 0.0512 - val_mean_absolute_error: 0.1431\n",
      "Epoch 60/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1601 - mean_squared_error: 0.0550 - mean_absolute_error: 0.1468 - val_loss: 0.1554 - val_mean_squared_error: 0.0507 - val_mean_absolute_error: 0.1419\n",
      "Epoch 61/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1595 - mean_squared_error: 0.0551 - mean_absolute_error: 0.1469 - val_loss: 0.1550 - val_mean_squared_error: 0.0510 - val_mean_absolute_error: 0.1390\n",
      "Epoch 62/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1585 - mean_squared_error: 0.0548 - mean_absolute_error: 0.1460 - val_loss: 0.1538 - val_mean_squared_error: 0.0505 - val_mean_absolute_error: 0.1374\n",
      "Epoch 63/100\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.1572 - mean_squared_error: 0.0542 - mean_absolute_error: 0.1448 - val_loss: 0.1519 - val_mean_squared_error: 0.0493 - val_mean_absolute_error: 0.1363\n",
      "Epoch 64/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1563 - mean_squared_error: 0.0541 - mean_absolute_error: 0.1451 - val_loss: 0.1522 - val_mean_squared_error: 0.0504 - val_mean_absolute_error: 0.1370\n",
      "Epoch 65/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1554 - mean_squared_error: 0.0539 - mean_absolute_error: 0.1438 - val_loss: 0.1505 - val_mean_squared_error: 0.0494 - val_mean_absolute_error: 0.1371\n",
      "Epoch 66/100\n",
      "147/147 [==============================] - 10s 65ms/step - loss: 0.1547 - mean_squared_error: 0.0540 - mean_absolute_error: 0.1446 - val_loss: 0.1501 - val_mean_squared_error: 0.0498 - val_mean_absolute_error: 0.1366\n",
      "Epoch 67/100\n",
      "147/147 [==============================] - 10s 65ms/step - loss: 0.1534 - mean_squared_error: 0.0534 - mean_absolute_error: 0.1435 - val_loss: 0.1484 - val_mean_squared_error: 0.0488 - val_mean_absolute_error: 0.1354\n",
      "Epoch 68/100\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 0.1517 - mean_squared_error: 0.0525 - mean_absolute_error: 0.1421 - val_loss: 0.1469 - val_mean_squared_error: 0.0480 - val_mean_absolute_error: 0.1365\n",
      "Epoch 69/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1518 - mean_squared_error: 0.0534 - mean_absolute_error: 0.1435 - val_loss: 0.1462 - val_mean_squared_error: 0.0482 - val_mean_absolute_error: 0.1344\n",
      "Epoch 70/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1501 - mean_squared_error: 0.0525 - mean_absolute_error: 0.1423 - val_loss: 0.1449 - val_mean_squared_error: 0.0476 - val_mean_absolute_error: 0.1332\n",
      "Epoch 71/100\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 0.1495 - mean_squared_error: 0.0527 - mean_absolute_error: 0.1425 - val_loss: 0.1434 - val_mean_squared_error: 0.0469 - val_mean_absolute_error: 0.1315\n",
      "Epoch 72/100\n",
      "147/147 [==============================] - 10s 65ms/step - loss: 0.1487 - mean_squared_error: 0.0527 - mean_absolute_error: 0.1419 - val_loss: 0.1423 - val_mean_squared_error: 0.0466 - val_mean_absolute_error: 0.1309\n",
      "Epoch 73/100\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 0.1478 - mean_squared_error: 0.0525 - mean_absolute_error: 0.1413 - val_loss: 0.1419 - val_mean_squared_error: 0.0471 - val_mean_absolute_error: 0.1311\n",
      "Epoch 74/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1461 - mean_squared_error: 0.0516 - mean_absolute_error: 0.1394 - val_loss: 0.1399 - val_mean_squared_error: 0.0459 - val_mean_absolute_error: 0.1295\n",
      "Epoch 75/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1455 - mean_squared_error: 0.0519 - mean_absolute_error: 0.1405 - val_loss: 0.1400 - val_mean_squared_error: 0.0468 - val_mean_absolute_error: 0.1289\n",
      "Epoch 76/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1443 - mean_squared_error: 0.0515 - mean_absolute_error: 0.1393 - val_loss: 0.1392 - val_mean_squared_error: 0.0468 - val_mean_absolute_error: 0.1299\n",
      "Epoch 77/100\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 0.1435 - mean_squared_error: 0.0515 - mean_absolute_error: 0.1388 - val_loss: 0.1381 - val_mean_squared_error: 0.0465 - val_mean_absolute_error: 0.1297\n",
      "Epoch 78/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1426 - mean_squared_error: 0.0514 - mean_absolute_error: 0.1396 - val_loss: 0.1368 - val_mean_squared_error: 0.0461 - val_mean_absolute_error: 0.1282\n",
      "Epoch 79/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1412 - mean_squared_error: 0.0509 - mean_absolute_error: 0.1384 - val_loss: 0.1356 - val_mean_squared_error: 0.0457 - val_mean_absolute_error: 0.1275\n",
      "Epoch 80/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1401 - mean_squared_error: 0.0507 - mean_absolute_error: 0.1379 - val_loss: 0.1344 - val_mean_squared_error: 0.0454 - val_mean_absolute_error: 0.1272\n",
      "Epoch 81/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1390 - mean_squared_error: 0.0504 - mean_absolute_error: 0.1371 - val_loss: 0.1336 - val_mean_squared_error: 0.0454 - val_mean_absolute_error: 0.1269\n",
      "Epoch 82/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1384 - mean_squared_error: 0.0506 - mean_absolute_error: 0.1376 - val_loss: 0.1324 - val_mean_squared_error: 0.0450 - val_mean_absolute_error: 0.1266\n",
      "Epoch 83/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1366 - mean_squared_error: 0.0496 - mean_absolute_error: 0.1360 - val_loss: 0.1313 - val_mean_squared_error: 0.0447 - val_mean_absolute_error: 0.1257\n",
      "Epoch 84/100\n",
      "147/147 [==============================] - 10s 65ms/step - loss: 0.1359 - mean_squared_error: 0.0498 - mean_absolute_error: 0.1361 - val_loss: 0.1305 - val_mean_squared_error: 0.0448 - val_mean_absolute_error: 0.1263\n",
      "Epoch 85/100\n",
      "147/147 [==============================] - 10s 66ms/step - loss: 0.1353 - mean_squared_error: 0.0500 - mean_absolute_error: 0.1362 - val_loss: 0.1296 - val_mean_squared_error: 0.0448 - val_mean_absolute_error: 0.1267\n",
      "Epoch 86/100\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 0.1341 - mean_squared_error: 0.0497 - mean_absolute_error: 0.1354 - val_loss: 0.1283 - val_mean_squared_error: 0.0443 - val_mean_absolute_error: 0.1273\n",
      "Epoch 87/100\n",
      "147/147 [==============================] - 9s 62ms/step - loss: 0.1324 - mean_squared_error: 0.0488 - mean_absolute_error: 0.1335 - val_loss: 0.1270 - val_mean_squared_error: 0.0438 - val_mean_absolute_error: 0.1238\n",
      "Epoch 88/100\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 0.1320 - mean_squared_error: 0.0493 - mean_absolute_error: 0.1345 - val_loss: 0.1266 - val_mean_squared_error: 0.0443 - val_mean_absolute_error: 0.1245\n",
      "Epoch 89/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1308 - mean_squared_error: 0.0489 - mean_absolute_error: 0.1341 - val_loss: 0.1256 - val_mean_squared_error: 0.0441 - val_mean_absolute_error: 0.1240\n",
      "Epoch 90/100\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 0.1298 - mean_squared_error: 0.0487 - mean_absolute_error: 0.1337 - val_loss: 0.1252 - val_mean_squared_error: 0.0446 - val_mean_absolute_error: 0.1234\n",
      "Epoch 91/100\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 0.1284 - mean_squared_error: 0.0482 - mean_absolute_error: 0.1323 - val_loss: 0.1230 - val_mean_squared_error: 0.0432 - val_mean_absolute_error: 0.1224\n",
      "Epoch 92/100\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 0.1278 - mean_squared_error: 0.0484 - mean_absolute_error: 0.1329 - val_loss: 0.1220 - val_mean_squared_error: 0.0430 - val_mean_absolute_error: 0.1217\n",
      "Epoch 93/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1266 - mean_squared_error: 0.0480 - mean_absolute_error: 0.1320 - val_loss: 0.1213 - val_mean_squared_error: 0.0432 - val_mean_absolute_error: 0.1226\n",
      "Epoch 94/100\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 0.1261 - mean_squared_error: 0.0483 - mean_absolute_error: 0.1324 - val_loss: 0.1201 - val_mean_squared_error: 0.0428 - val_mean_absolute_error: 0.1238\n",
      "Epoch 95/100\n",
      "147/147 [==============================] - 10s 70ms/step - loss: 0.1246 - mean_squared_error: 0.0477 - mean_absolute_error: 0.1312 - val_loss: 0.1194 - val_mean_squared_error: 0.0429 - val_mean_absolute_error: 0.1222\n",
      "Epoch 96/100\n",
      "147/147 [==============================] - 10s 67ms/step - loss: 0.1238 - mean_squared_error: 0.0477 - mean_absolute_error: 0.1317 - val_loss: 0.1176 - val_mean_squared_error: 0.0419 - val_mean_absolute_error: 0.1200\n",
      "Epoch 97/100\n",
      "147/147 [==============================] - 10s 70ms/step - loss: 0.1226 - mean_squared_error: 0.0473 - mean_absolute_error: 0.1305 - val_loss: 0.1165 - val_mean_squared_error: 0.0416 - val_mean_absolute_error: 0.1211\n",
      "Epoch 98/100\n",
      "147/147 [==============================] - 10s 65ms/step - loss: 0.1220 - mean_squared_error: 0.0475 - mean_absolute_error: 0.1310 - val_loss: 0.1159 - val_mean_squared_error: 0.0419 - val_mean_absolute_error: 0.1199\n",
      "Epoch 99/100\n",
      "147/147 [==============================] - 9s 64ms/step - loss: 0.1207 - mean_squared_error: 0.0471 - mean_absolute_error: 0.1298 - val_loss: 0.1150 - val_mean_squared_error: 0.0417 - val_mean_absolute_error: 0.1191\n",
      "Epoch 100/100\n",
      "147/147 [==============================] - 9s 63ms/step - loss: 0.1198 - mean_squared_error: 0.0469 - mean_absolute_error: 0.1294 - val_loss: 0.1140 - val_mean_squared_error: 0.0416 - val_mean_absolute_error: 0.1195\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    # rotation_range=20,\n",
    "    # width_shift_range=0.1,\n",
    "    # height_shift_range=0.1,\n",
    "    # shear_range=0.2,\n",
    "    # zoom_range=[0.9, 1.1],\n",
    "    # horizontal_flip=True,\n",
    "    # fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Assuming you have your training data in train_data and train_labels\n",
    "train_generator = train_datagen.flow(X_train, Y_train, batch_size=32)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Adding L2 Regularization to Convolutional Layers\n",
    "l2_reg = 0.001\n",
    "\n",
    "# First Conv Block\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 80, 3), kernel_regularizer=l2(l2_reg)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Second Conv Block\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "# Flatten and Dense Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(14, activation='linear', kernel_regularizer=l2(l2_reg)))  # Adjust the number of outputs as needed\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.00005), loss='mse', metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,  # Adjust number of epochs\n",
    "    validation_data=(X_val, Y_val),  # Assuming validation data is available\n",
    "    callbacks=[early_stopping],\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers with dropout\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 80, 3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.25))  # Dropout layer after pooling\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.25))  # Another dropout layer\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.4))  # Higher dropout rate for deeper layers\n",
    "\n",
    "# Flatten the output from convolutional layers before passing it to the dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add dense layers with dropout\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout layer before the output layer\n",
    "model.add(Dense(14, activation='sigmoid'))  # Adjust the number of outputs as needed\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "model.fit(X_train, Y_train, epochs=100, validation_split=0.1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 21ms/step - loss: 0.1125 - mean_squared_error: 0.0401 - mean_absolute_error: 0.1196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11253387480974197, 0.040079690515995026, 0.11956485360860825]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate the model\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('./models/eye_gaze_v10_3800v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 21ms/step\n",
      "271.3668443262577 476.54571533203125\n",
      "187.4236822128296 101.24508619308472\n",
      "187.4236822128296 101.24508619308472\n",
      "202.92123220860958 107.37052202224731\n",
      "293.6021462082863 416.01139068603516\n",
      "709.4157844781876 874.8624229431152\n",
      "187.4236822128296 101.24508619308472\n",
      "187.4236822128296 101.24508619308472\n",
      "187.4236822128296 101.24508619308472\n",
      "164.96108695864677 417.72010803222656\n",
      "192.84839630126953 399.74870681762695\n",
      "187.4236822128296 101.24508619308472\n",
      "175.69090574979782 266.54797554016113\n",
      "187.4236822128296 101.24508619308472\n",
      "187.4236822128296 101.24508619308472\n",
      "187.4236822128296 101.24508619308472\n",
      "187.4236822128296 101.24508619308472\n",
      "235.55190861225128 316.4210343360901\n",
      "187.4236822128296 101.24508619308472\n",
      "187.4236822128296 101.24508619308472\n",
      "187.4236822128296 101.24508619308472\n",
      "329.230323061347 735.2469635009766\n",
      "215.2321930974722 225.5738639831543\n",
      "187.4236822128296 101.24508619308472\n",
      "199.13626052439213 153.61074328422546\n",
      "196.58742360770702 142.21516370773315\n",
      "187.4236822128296 101.24508619308472\n",
      "159.01719350367785 501.463565826416\n",
      "268.8796877861023 465.4259204864502\n",
      "266.71769581735134 455.75992584228516\n",
      "187.4236822128296 101.24508619308472\n",
      "252.88910940289497 393.9338493347168\n",
      "187.4236822128296 101.24508619308472\n",
      "344.53244656324387 803.661060333252\n",
      "239.62336629629135 758.9801788330078\n",
      "271.0472673177719 475.1169776916504\n",
      "187.4236822128296 101.24508619308472\n",
      "235.2182738482952 314.9294900894165\n",
      "187.4236822128296 101.24508619308472\n",
      "434.47546660900116 509.94483947753906\n",
      "187.4236822128296 101.24508619308472\n",
      "187.4236822128296 101.24508619308472\n",
      "187.4236822128296 101.24508619308472\n",
      "187.4236822128296 101.24508619308472\n",
      "187.4236822128296 101.24508619308472\n",
      "219.96894590556622 246.75138473510742\n",
      "215.67218899726868 227.54106044769287\n",
      "187.4236822128296 101.24508619308472\n",
      "187.4236822128296 101.24508619308472\n"
     ]
    }
   ],
   "source": [
    "#plot predicted vs actual on test data on a canvas using opencv \n",
    "\n",
    "import cv2\n",
    "import numpy as np \n",
    "predictions = model.predict(X_test)\n",
    "screen_width, screen_height = 2650, 1440\n",
    "canvas = np.zeros((screen_height, screen_width, 3), dtype=np.uint8)\n",
    "cv2.namedWindow('Gaze Tracking on Canvas', cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('Gaze Tracking on Canvas', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "# plot the first 10 images one by one\n",
    "for i in range(1,50):\n",
    "    # get the predicted x,y coordinates\n",
    "    x, y = predictions[i][0] * screen_width, predictions[i][1] * screen_height\n",
    "    print(x,y)\n",
    "    # get the actual x,y coordinates\n",
    "    x_actual, y_actual = Y_test[i][0] * screen_width, Y_test[i][1] * screen_height\n",
    "    # plot the predicted x,y coordinates\n",
    "    cv2.circle(canvas, (int(x), int(y)), 10, (0, 0, 255), -1)\n",
    "    # plot the actual x,y coordinates\n",
    "    cv2.circle(canvas, (int(x_actual), int(y_actual)), 10, (0, 255, 0), -1)\n",
    "    # show the canvas\n",
    "    cv2.imshow('Gaze Tracking on Canvas', canvas)\n",
    "    cv2.waitKey(0)\n",
    "    # clear the canvas\n",
    "    canvas = np.zeros((screen_height, screen_width, 3), dtype=np.uint8)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/eye_gaze_v11_3600v2_linear.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.10_eye_gaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
