{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_processed_data(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        X, Y = pickle.load(file)\n",
    "    return X, Y\n",
    "X1, Y1 = load_processed_data('./pickel_files/all_data_200_100.pkl')\n",
    "X1 = np.array(X1)\n",
    "Y1 = np.array(Y1)\n",
    "Y1 = Y1[:, :2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming combined_data is your combined dictionary with 'X' and 'Y' keys\n",
    "combined_data = {'X': [], 'Y': []}\n",
    "combined_data['X'].extend(X1)\n",
    "combined_data['Y'].extend(Y1)\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "def process_and_combine_pkl_files(directory_path):\n",
    "    \n",
    "    # Step 1: Find all .pkl files in the specified directory\n",
    "    for file_path in glob.glob(directory_path + '/*.pkl'):\n",
    "        with open(file_path, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "        \n",
    "        # Step 2: Append the data to combined_data if both 'X' and 'Y' are present\n",
    "        if 'X' in data and 'Y' in data:\n",
    "            combined_data['X'].extend(data['X'])\n",
    "            combined_data['Y'].extend(data['Y'])\n",
    "    \n",
    "\n",
    "    \n",
    "    # Step 4: Convert lists to NumPy arrays\n",
    "    X_filtered = np.array(combined_data['X'])\n",
    "    Y_filtered = np.array(combined_data['Y'])\n",
    "    \n",
    "    # Further processing of Y (if needed)\n",
    "    if Y_filtered.shape[1] > 2:\n",
    "        Y_filtered = Y_filtered[:, :2]\n",
    "\n",
    "    # Convert X to float 16\n",
    "    X_filtered = X_filtered.astype(np.float16)\n",
    "    \n",
    "    # Convert Y to float 16 \n",
    "    Y_filtered = Y_filtered.astype(np.float16)\n",
    "    \n",
    "    return X_filtered, Y_filtered\n",
    "\n",
    "# Example usage\n",
    "directory_path = './process_MPIIGaze'  # Adjust this path as necessary\n",
    "X_filtered, Y_filtered = process_and_combine_pkl_files(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save X and Y\n",
    "with open('60K', 'wb') as file:\n",
    "    pickle.dump([X_filtered, Y_filtered], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load X and Y\n",
    "with open('60K', 'rb') as file:\n",
    "    X_filtered, Y_filtered = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def batch_generator(X, Y, batch_size=32, shuffle=True):\n",
    "    \"\"\"\n",
    "    A generator that yields batches of data indefinitely, with optional shuffling.\n",
    "    \"\"\"\n",
    "    num_samples = len(X)\n",
    "    while True:  # Loop indefinitely\n",
    "        if shuffle:\n",
    "            indices = np.arange(num_samples)\n",
    "            np.random.shuffle(indices)\n",
    "            X = X[indices]\n",
    "            Y = Y[indices]\n",
    "\n",
    "        for start_idx in range(0, num_samples, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, num_samples)\n",
    "            yield X[start_idx:end_idx], Y[start_idx:end_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Dropout, Flatten\n",
    "from keras.regularizers import l2\n",
    "# Maxpooling\n",
    "from keras.layers import MaxPooling2D\n",
    "#BatchNormalization\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "# Your model definition\n",
    "model = Sequential([\n",
    "    Conv2D(32, (7, 7), activation='relu', input_shape=(100, 200, 3), kernel_regularizer=l2(0.001)),\n",
    "    \n",
    "    \n",
    "    Conv2D(64, (7, 7), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.15),\n",
    "\n",
    "\n",
    "    Conv2D(128, (5, 5), activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.15),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "\n",
    "    Conv2D(256, (5, 5), activation='relu'),\n",
    "\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.00005), loss='mse', metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, Y, test_size=0.2, val_size=0.2):\n",
    "    \"\"\"\n",
    "    Splits data into training, validation, and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - X, Y: The features and labels.\n",
    "    - test_size: Fraction of the dataset to be used as the test set.\n",
    "    - val_size: Fraction of the dataset (after removing the test set) to be used as the validation set.\n",
    "    \n",
    "    Returns:\n",
    "    - X_train, Y_train: Training set.\n",
    "    - X_val, Y_val: Validation set.\n",
    "    - X_test, Y_test: Test set.\n",
    "    \"\"\"\n",
    "    # Shuffle the dataset\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    X = X[indices]\n",
    "    Y = Y[indices]\n",
    "    \n",
    "    # Calculate split indices\n",
    "    test_split_idx = int(len(X) * (1 - test_size))\n",
    "    val_split_idx = int(test_split_idx * (1 - val_size))\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_val, X_test = X[:val_split_idx], X[val_split_idx:test_split_idx], X[test_split_idx:]\n",
    "    Y_train, Y_val, Y_test = Y[:val_split_idx], Y[val_split_idx:test_split_idx], Y[test_split_idx:]\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test\n",
    "\n",
    "# Apply the function to your data\n",
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = split_data(X_filtered, Y_filtered, test_size=0.2, val_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "num_train_samples = int(len(X_filtered) * 0.6)  # Assuming 60% of data is for training\n",
    "num_val_samples = int(len(X_filtered) * 0.2)  # Assuming 20% of data is for validation\n",
    "\n",
    "steps_per_epoch = num_train_samples // batch_size\n",
    "validation_steps = num_val_samples // batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1242/1242 [==============================] - 253s 192ms/step - loss: 0.0421 - mean_squared_error: 0.0375 - mean_absolute_error: 0.1471 - val_loss: 0.0272 - val_mean_squared_error: 0.0230 - val_mean_absolute_error: 0.1162\n",
      "Epoch 2/100\n",
      "1242/1242 [==============================] - 216s 173ms/step - loss: 0.0258 - mean_squared_error: 0.0218 - mean_absolute_error: 0.1113 - val_loss: 0.0165 - val_mean_squared_error: 0.0126 - val_mean_absolute_error: 0.0816\n",
      "Epoch 3/100\n",
      "1242/1242 [==============================] - 218s 176ms/step - loss: 0.0221 - mean_squared_error: 0.0183 - mean_absolute_error: 0.1008 - val_loss: 0.0138 - val_mean_squared_error: 0.0102 - val_mean_absolute_error: 0.0722\n",
      "Epoch 4/100\n",
      "1242/1242 [==============================] - 214s 172ms/step - loss: 0.0198 - mean_squared_error: 0.0162 - mean_absolute_error: 0.0939 - val_loss: 0.0130 - val_mean_squared_error: 0.0096 - val_mean_absolute_error: 0.0694\n",
      "Epoch 5/100\n",
      "1242/1242 [==============================] - 210s 169ms/step - loss: 0.0182 - mean_squared_error: 0.0148 - mean_absolute_error: 0.0888 - val_loss: 0.0114 - val_mean_squared_error: 0.0081 - val_mean_absolute_error: 0.0638\n",
      "Epoch 6/100\n",
      "1242/1242 [==============================] - 214s 172ms/step - loss: 0.0168 - mean_squared_error: 0.0136 - mean_absolute_error: 0.0847 - val_loss: 0.0104 - val_mean_squared_error: 0.0072 - val_mean_absolute_error: 0.0587\n",
      "Epoch 7/100\n",
      "1242/1242 [==============================] - 214s 172ms/step - loss: 0.0155 - mean_squared_error: 0.0125 - mean_absolute_error: 0.0813 - val_loss: 0.0101 - val_mean_squared_error: 0.0071 - val_mean_absolute_error: 0.0591\n",
      "Epoch 8/100\n",
      "1242/1242 [==============================] - 209s 168ms/step - loss: 0.0149 - mean_squared_error: 0.0120 - mean_absolute_error: 0.0789 - val_loss: 0.0096 - val_mean_squared_error: 0.0068 - val_mean_absolute_error: 0.0567\n",
      "Epoch 9/100\n",
      "1242/1242 [==============================] - 209s 168ms/step - loss: 0.0140 - mean_squared_error: 0.0113 - mean_absolute_error: 0.0771 - val_loss: 0.0093 - val_mean_squared_error: 0.0067 - val_mean_absolute_error: 0.0558\n",
      "Epoch 10/100\n",
      "1242/1242 [==============================] - 209s 168ms/step - loss: 0.0137 - mean_squared_error: 0.0111 - mean_absolute_error: 0.0763 - val_loss: 0.0089 - val_mean_squared_error: 0.0063 - val_mean_absolute_error: 0.0550\n",
      "Epoch 11/100\n",
      "1242/1242 [==============================] - 205s 165ms/step - loss: 0.0130 - mean_squared_error: 0.0106 - mean_absolute_error: 0.0744 - val_loss: 0.0084 - val_mean_squared_error: 0.0060 - val_mean_absolute_error: 0.0526\n",
      "Epoch 12/100\n",
      "1242/1242 [==============================] - 211s 170ms/step - loss: 0.0125 - mean_squared_error: 0.0101 - mean_absolute_error: 0.0731 - val_loss: 0.0081 - val_mean_squared_error: 0.0059 - val_mean_absolute_error: 0.0520\n",
      "Epoch 13/100\n",
      "1242/1242 [==============================] - 211s 170ms/step - loss: 0.0123 - mean_squared_error: 0.0101 - mean_absolute_error: 0.0729 - val_loss: 0.0089 - val_mean_squared_error: 0.0067 - val_mean_absolute_error: 0.0572\n",
      "Epoch 14/100\n",
      "1242/1242 [==============================] - 211s 170ms/step - loss: 0.0118 - mean_squared_error: 0.0098 - mean_absolute_error: 0.0717 - val_loss: 0.0082 - val_mean_squared_error: 0.0062 - val_mean_absolute_error: 0.0530\n",
      "Epoch 15/100\n",
      "1242/1242 [==============================] - 211s 170ms/step - loss: 0.0115 - mean_squared_error: 0.0096 - mean_absolute_error: 0.0709 - val_loss: 0.0077 - val_mean_squared_error: 0.0057 - val_mean_absolute_error: 0.0515\n",
      "Epoch 16/100\n",
      "1242/1242 [==============================] - 208s 167ms/step - loss: 0.0113 - mean_squared_error: 0.0094 - mean_absolute_error: 0.0699 - val_loss: 0.0074 - val_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0502\n",
      "Epoch 17/100\n",
      "1242/1242 [==============================] - 208s 167ms/step - loss: 0.0110 - mean_squared_error: 0.0092 - mean_absolute_error: 0.0696 - val_loss: 0.0071 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0493\n",
      "Epoch 18/100\n",
      "1242/1242 [==============================] - 210s 169ms/step - loss: 0.0108 - mean_squared_error: 0.0092 - mean_absolute_error: 0.0690 - val_loss: 0.0070 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0491\n",
      "Epoch 19/100\n",
      "1242/1242 [==============================] - 205s 165ms/step - loss: 0.0105 - mean_squared_error: 0.0089 - mean_absolute_error: 0.0681 - val_loss: 0.0072 - val_mean_squared_error: 0.0057 - val_mean_absolute_error: 0.0512\n",
      "Epoch 20/100\n",
      "1242/1242 [==============================] - 207s 167ms/step - loss: 0.0102 - mean_squared_error: 0.0087 - mean_absolute_error: 0.0673 - val_loss: 0.0068 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0490\n",
      "Epoch 21/100\n",
      "1242/1242 [==============================] - 209s 168ms/step - loss: 0.0101 - mean_squared_error: 0.0087 - mean_absolute_error: 0.0672 - val_loss: 0.0069 - val_mean_squared_error: 0.0056 - val_mean_absolute_error: 0.0506\n",
      "Epoch 22/100\n",
      "1242/1242 [==============================] - 207s 166ms/step - loss: 0.0098 - mean_squared_error: 0.0085 - mean_absolute_error: 0.0663 - val_loss: 0.0064 - val_mean_squared_error: 0.0052 - val_mean_absolute_error: 0.0479\n",
      "Epoch 23/100\n",
      "1242/1242 [==============================] - 207s 167ms/step - loss: 0.0097 - mean_squared_error: 0.0084 - mean_absolute_error: 0.0661 - val_loss: 0.0065 - val_mean_squared_error: 0.0053 - val_mean_absolute_error: 0.0483\n",
      "Epoch 24/100\n",
      "1242/1242 [==============================] - 208s 167ms/step - loss: 0.0094 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0653 - val_loss: 0.0066 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0491\n",
      "Epoch 25/100\n",
      "1242/1242 [==============================] - 208s 167ms/step - loss: 0.0092 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0650 - val_loss: 0.0064 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0485\n",
      "Epoch 26/100\n",
      "1242/1242 [==============================] - 207s 166ms/step - loss: 0.0092 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0648 - val_loss: 0.0065 - val_mean_squared_error: 0.0055 - val_mean_absolute_error: 0.0497\n",
      "Epoch 27/100\n",
      "1242/1242 [==============================] - 205s 165ms/step - loss: 0.0090 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0640 - val_loss: 0.0062 - val_mean_squared_error: 0.0053 - val_mean_absolute_error: 0.0484\n",
      "Epoch 28/100\n",
      "1242/1242 [==============================] - 207s 166ms/step - loss: 0.0089 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0639 - val_loss: 0.0060 - val_mean_squared_error: 0.0051 - val_mean_absolute_error: 0.0476\n",
      "Epoch 29/100\n",
      "1242/1242 [==============================] - 207s 166ms/step - loss: 0.0089 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0638 - val_loss: 0.0060 - val_mean_squared_error: 0.0052 - val_mean_absolute_error: 0.0481\n",
      "Epoch 30/100\n",
      "1242/1242 [==============================] - 203s 164ms/step - loss: 0.0087 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0632 - val_loss: 0.0059 - val_mean_squared_error: 0.0051 - val_mean_absolute_error: 0.0476\n",
      "Epoch 31/100\n",
      "1242/1242 [==============================] - 209s 168ms/step - loss: 0.0086 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0633 - val_loss: 0.0061 - val_mean_squared_error: 0.0053 - val_mean_absolute_error: 0.0495\n",
      "Epoch 32/100\n",
      "1242/1242 [==============================] - 205s 165ms/step - loss: 0.0085 - mean_squared_error: 0.0078 - mean_absolute_error: 0.0628 - val_loss: 0.0058 - val_mean_squared_error: 0.0051 - val_mean_absolute_error: 0.0474\n",
      "Epoch 33/100\n",
      "1242/1242 [==============================] - 206s 166ms/step - loss: 0.0084 - mean_squared_error: 0.0077 - mean_absolute_error: 0.0625 - val_loss: 0.0057 - val_mean_squared_error: 0.0051 - val_mean_absolute_error: 0.0471\n",
      "Epoch 34/100\n",
      "1242/1242 [==============================] - 207s 167ms/step - loss: 0.0079 - mean_squared_error: 0.0072 - mean_absolute_error: 0.0610 - val_loss: 0.0056 - val_mean_squared_error: 0.0050 - val_mean_absolute_error: 0.0472\n",
      "Epoch 35/100\n",
      "1242/1242 [==============================] - 206s 166ms/step - loss: 0.0078 - mean_squared_error: 0.0072 - mean_absolute_error: 0.0604 - val_loss: 0.0060 - val_mean_squared_error: 0.0054 - val_mean_absolute_error: 0.0487\n",
      "Epoch 36/100\n",
      "1242/1242 [==============================] - 206s 166ms/step - loss: 0.0077 - mean_squared_error: 0.0071 - mean_absolute_error: 0.0602 - val_loss: 0.0057 - val_mean_squared_error: 0.0052 - val_mean_absolute_error: 0.0480\n",
      "Epoch 37/100\n",
      "1242/1242 [==============================] - 206s 165ms/step - loss: 0.0076 - mean_squared_error: 0.0070 - mean_absolute_error: 0.0598 - val_loss: 0.0056 - val_mean_squared_error: 0.0050 - val_mean_absolute_error: 0.0469\n",
      "Epoch 38/100\n",
      "1242/1242 [==============================] - 206s 166ms/step - loss: 0.0075 - mean_squared_error: 0.0069 - mean_absolute_error: 0.0596 - val_loss: 0.0054 - val_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0460\n",
      "Epoch 39/100\n",
      "1242/1242 [==============================] - 206s 166ms/step - loss: 0.0073 - mean_squared_error: 0.0068 - mean_absolute_error: 0.0590 - val_loss: 0.0053 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0454\n",
      "Epoch 40/100\n",
      "1242/1242 [==============================] - 207s 166ms/step - loss: 0.0073 - mean_squared_error: 0.0068 - mean_absolute_error: 0.0590 - val_loss: 0.0055 - val_mean_squared_error: 0.0050 - val_mean_absolute_error: 0.0471\n",
      "Epoch 41/100\n",
      "1242/1242 [==============================] - 205s 165ms/step - loss: 0.0073 - mean_squared_error: 0.0069 - mean_absolute_error: 0.0591 - val_loss: 0.0053 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0459\n",
      "Epoch 42/100\n",
      "1242/1242 [==============================] - 206s 166ms/step - loss: 0.0073 - mean_squared_error: 0.0068 - mean_absolute_error: 0.0587 - val_loss: 0.0054 - val_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0466\n",
      "Epoch 43/100\n",
      "1242/1242 [==============================] - 203s 163ms/step - loss: 0.0072 - mean_squared_error: 0.0068 - mean_absolute_error: 0.0585 - val_loss: 0.0051 - val_mean_squared_error: 0.0047 - val_mean_absolute_error: 0.0449\n",
      "Epoch 44/100\n",
      "1242/1242 [==============================] - 207s 167ms/step - loss: 0.0071 - mean_squared_error: 0.0067 - mean_absolute_error: 0.0584 - val_loss: 0.0052 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0451\n",
      "Epoch 45/100\n",
      "1242/1242 [==============================] - 207s 167ms/step - loss: 0.0072 - mean_squared_error: 0.0068 - mean_absolute_error: 0.0585 - val_loss: 0.0053 - val_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0458\n",
      "Epoch 46/100\n",
      "1242/1242 [==============================] - 207s 167ms/step - loss: 0.0070 - mean_squared_error: 0.0067 - mean_absolute_error: 0.0580 - val_loss: 0.0056 - val_mean_squared_error: 0.0052 - val_mean_absolute_error: 0.0478\n",
      "Epoch 47/100\n",
      "1242/1242 [==============================] - 206s 166ms/step - loss: 0.0068 - mean_squared_error: 0.0065 - mean_absolute_error: 0.0572 - val_loss: 0.0050 - val_mean_squared_error: 0.0046 - val_mean_absolute_error: 0.0443\n",
      "Epoch 48/100\n",
      "1242/1242 [==============================] - 212s 171ms/step - loss: 0.0069 - mean_squared_error: 0.0065 - mean_absolute_error: 0.0575 - val_loss: 0.0053 - val_mean_squared_error: 0.0050 - val_mean_absolute_error: 0.0459\n",
      "Epoch 49/100\n",
      "1242/1242 [==============================] - 221s 178ms/step - loss: 0.0069 - mean_squared_error: 0.0065 - mean_absolute_error: 0.0575 - val_loss: 0.0050 - val_mean_squared_error: 0.0047 - val_mean_absolute_error: 0.0451\n",
      "Epoch 50/100\n",
      "1242/1242 [==============================] - 209s 168ms/step - loss: 0.0069 - mean_squared_error: 0.0066 - mean_absolute_error: 0.0573 - val_loss: 0.0051 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0450\n",
      "Epoch 51/100\n",
      "1242/1242 [==============================] - 207s 167ms/step - loss: 0.0068 - mean_squared_error: 0.0065 - mean_absolute_error: 0.0575 - val_loss: 0.0053 - val_mean_squared_error: 0.0050 - val_mean_absolute_error: 0.0462\n",
      "Epoch 52/100\n",
      "1242/1242 [==============================] - 207s 167ms/step - loss: 0.0068 - mean_squared_error: 0.0065 - mean_absolute_error: 0.0572 - val_loss: 0.0052 - val_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0458\n",
      "Epoch 53/100\n",
      "1242/1242 [==============================] - 205s 165ms/step - loss: 0.0067 - mean_squared_error: 0.0064 - mean_absolute_error: 0.0569 - val_loss: 0.0051 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0453\n",
      "Epoch 54/100\n",
      "1242/1242 [==============================] - 205s 165ms/step - loss: 0.0068 - mean_squared_error: 0.0065 - mean_absolute_error: 0.0571 - val_loss: 0.0051 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0448\n",
      "Epoch 55/100\n",
      "1242/1242 [==============================] - 205s 165ms/step - loss: 0.0067 - mean_squared_error: 0.0064 - mean_absolute_error: 0.0569 - val_loss: 0.0050 - val_mean_squared_error: 0.0047 - val_mean_absolute_error: 0.0449\n",
      "Epoch 56/100\n",
      "1242/1242 [==============================] - 206s 165ms/step - loss: 0.0067 - mean_squared_error: 0.0064 - mean_absolute_error: 0.0568 - val_loss: 0.0052 - val_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0465\n",
      "Epoch 57/100\n",
      "1242/1242 [==============================] - 207s 167ms/step - loss: 0.0067 - mean_squared_error: 0.0064 - mean_absolute_error: 0.0568 - val_loss: 0.0051 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0457\n",
      "Epoch 58/100\n",
      "1242/1242 [==============================] - 205s 165ms/step - loss: 0.0066 - mean_squared_error: 0.0063 - mean_absolute_error: 0.0566 - val_loss: 0.0052 - val_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0457\n",
      "Epoch 59/100\n",
      "1242/1242 [==============================] - 206s 166ms/step - loss: 0.0065 - mean_squared_error: 0.0063 - mean_absolute_error: 0.0562 - val_loss: 0.0052 - val_mean_squared_error: 0.0050 - val_mean_absolute_error: 0.0467\n",
      "Epoch 60/100\n",
      "1242/1242 [==============================] - 205s 165ms/step - loss: 0.0065 - mean_squared_error: 0.0063 - mean_absolute_error: 0.0561 - val_loss: 0.0052 - val_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0461\n",
      "Epoch 61/100\n",
      "1242/1242 [==============================] - 206s 166ms/step - loss: 0.0065 - mean_squared_error: 0.0063 - mean_absolute_error: 0.0560 - val_loss: 0.0051 - val_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0455\n",
      "Epoch 62/100\n",
      "1242/1242 [==============================] - 207s 166ms/step - loss: 0.0065 - mean_squared_error: 0.0063 - mean_absolute_error: 0.0561 - val_loss: 0.0054 - val_mean_squared_error: 0.0052 - val_mean_absolute_error: 0.0474\n",
      "Epoch 63/100\n",
      "1242/1242 [==============================] - 203s 163ms/step - loss: 0.0064 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0556 - val_loss: 0.0050 - val_mean_squared_error: 0.0047 - val_mean_absolute_error: 0.0453\n",
      "Epoch 64/100\n",
      "1242/1242 [==============================] - 204s 164ms/step - loss: 0.0065 - mean_squared_error: 0.0063 - mean_absolute_error: 0.0560 - val_loss: 0.0050 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0454\n",
      "Epoch 65/100\n",
      "1242/1242 [==============================] - 206s 166ms/step - loss: 0.0065 - mean_squared_error: 0.0063 - mean_absolute_error: 0.0560 - val_loss: 0.0050 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0455\n",
      "Epoch 66/100\n",
      "1242/1242 [==============================] - 205s 165ms/step - loss: 0.0063 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0555 - val_loss: 0.0052 - val_mean_squared_error: 0.0050 - val_mean_absolute_error: 0.0466\n",
      "Epoch 67/100\n",
      "1242/1242 [==============================] - 204s 164ms/step - loss: 0.0064 - mean_squared_error: 0.0062 - mean_absolute_error: 0.0557 - val_loss: 0.0050 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0456\n",
      "Epoch 68/100\n",
      "1242/1242 [==============================] - 206s 166ms/step - loss: 0.0063 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0554 - val_loss: 0.0050 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0451\n",
      "Epoch 69/100\n",
      "1242/1242 [==============================] - 203s 164ms/step - loss: 0.0063 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0555 - val_loss: 0.0053 - val_mean_squared_error: 0.0051 - val_mean_absolute_error: 0.0472\n",
      "Epoch 70/100\n",
      "1242/1242 [==============================] - 206s 166ms/step - loss: 0.0063 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0553 - val_loss: 0.0053 - val_mean_squared_error: 0.0051 - val_mean_absolute_error: 0.0474\n",
      "Epoch 71/100\n",
      "1242/1242 [==============================] - 206s 166ms/step - loss: 0.0063 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0553 - val_loss: 0.0049 - val_mean_squared_error: 0.0047 - val_mean_absolute_error: 0.0449\n",
      "Epoch 72/100\n",
      "1242/1242 [==============================] - 207s 167ms/step - loss: 0.0063 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0552 - val_loss: 0.0049 - val_mean_squared_error: 0.0047 - val_mean_absolute_error: 0.0450\n",
      "Epoch 73/100\n",
      "1242/1242 [==============================] - 205s 165ms/step - loss: 0.0062 - mean_squared_error: 0.0060 - mean_absolute_error: 0.0551 - val_loss: 0.0049 - val_mean_squared_error: 0.0047 - val_mean_absolute_error: 0.0446\n",
      "Epoch 74/100\n",
      "1242/1242 [==============================] - 205s 165ms/step - loss: 0.0063 - mean_squared_error: 0.0062 - mean_absolute_error: 0.0555 - val_loss: 0.0049 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0455\n",
      "Epoch 75/100\n",
      "1242/1242 [==============================] - 206s 166ms/step - loss: 0.0063 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0552 - val_loss: 0.0048 - val_mean_squared_error: 0.0047 - val_mean_absolute_error: 0.0443\n",
      "Epoch 76/100\n",
      "1242/1242 [==============================] - 203s 164ms/step - loss: 0.0063 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0552 - val_loss: 0.0049 - val_mean_squared_error: 0.0047 - val_mean_absolute_error: 0.0443\n",
      "Epoch 77/100\n",
      "1242/1242 [==============================] - 207s 167ms/step - loss: 0.0063 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0551 - val_loss: 0.0051 - val_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0459\n",
      "Epoch 78/100\n",
      "1242/1242 [==============================] - 207s 167ms/step - loss: 0.0062 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0549 - val_loss: 0.0051 - val_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0462\n",
      "Epoch 79/100\n",
      "1242/1242 [==============================] - 207s 166ms/step - loss: 0.0062 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0549 - val_loss: 0.0050 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0456\n",
      "Epoch 80/100\n",
      "1242/1242 [==============================] - 205s 165ms/step - loss: 0.0063 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0551 - val_loss: 0.0049 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0448\n",
      "Epoch 81/100\n",
      "1242/1242 [==============================] - 204s 165ms/step - loss: 0.0061 - mean_squared_error: 0.0060 - mean_absolute_error: 0.0547 - val_loss: 0.0050 - val_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0459\n",
      "Epoch 82/100\n",
      "1242/1242 [==============================] - 206s 166ms/step - loss: 0.0062 - mean_squared_error: 0.0060 - mean_absolute_error: 0.0549 - val_loss: 0.0050 - val_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0461\n",
      "Epoch 83/100\n",
      "1242/1242 [==============================] - 207s 167ms/step - loss: 0.0062 - mean_squared_error: 0.0060 - mean_absolute_error: 0.0549 - val_loss: 0.0050 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0453\n",
      "Epoch 84/100\n",
      "1242/1242 [==============================] - 204s 165ms/step - loss: 0.0062 - mean_squared_error: 0.0060 - mean_absolute_error: 0.0548 - val_loss: 0.0052 - val_mean_squared_error: 0.0050 - val_mean_absolute_error: 0.0467\n",
      "Epoch 85/100\n",
      "1242/1242 [==============================] - 203s 164ms/step - loss: 0.0061 - mean_squared_error: 0.0060 - mean_absolute_error: 0.0547 - val_loss: 0.0052 - val_mean_squared_error: 0.0051 - val_mean_absolute_error: 0.0472\n",
      "Epoch 86/100\n",
      "1242/1242 [==============================] - 207s 167ms/step - loss: 0.0063 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0548 - val_loss: 0.0050 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0453\n",
      "Epoch 87/100\n",
      "1242/1242 [==============================] - 204s 164ms/step - loss: 0.0062 - mean_squared_error: 0.0060 - mean_absolute_error: 0.0545 - val_loss: 0.0051 - val_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0459\n",
      "Epoch 88/100\n",
      "1242/1242 [==============================] - 204s 164ms/step - loss: 0.0062 - mean_squared_error: 0.0060 - mean_absolute_error: 0.0546 - val_loss: 0.0051 - val_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0466\n",
      "Epoch 89/100\n",
      "1242/1242 [==============================] - 207s 167ms/step - loss: 0.0061 - mean_squared_error: 0.0060 - mean_absolute_error: 0.0546 - val_loss: 0.0050 - val_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0456\n",
      "Epoch 90/100\n",
      "1242/1242 [==============================] - 203s 164ms/step - loss: 0.0062 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0546 - val_loss: 0.0049 - val_mean_squared_error: 0.0047 - val_mean_absolute_error: 0.0448\n",
      "Epoch 91/100\n",
      "1242/1242 [==============================] - 204s 164ms/step - loss: 0.0062 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0548 - val_loss: 0.0049 - val_mean_squared_error: 0.0047 - val_mean_absolute_error: 0.0449\n",
      "Epoch 92/100\n",
      "1242/1242 [==============================] - 207s 167ms/step - loss: 0.0061 - mean_squared_error: 0.0060 - mean_absolute_error: 0.0544 - val_loss: 0.0051 - val_mean_squared_error: 0.0050 - val_mean_absolute_error: 0.0458\n",
      "Epoch 93/100\n",
      "1242/1242 [==============================] - 202s 162ms/step - loss: 0.0061 - mean_squared_error: 0.0060 - mean_absolute_error: 0.0543 - val_loss: 0.0049 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0446\n",
      "Epoch 94/100\n",
      "1242/1242 [==============================] - 206s 166ms/step - loss: 0.0060 - mean_squared_error: 0.0059 - mean_absolute_error: 0.0542 - val_loss: 0.0050 - val_mean_squared_error: 0.0048 - val_mean_absolute_error: 0.0455\n",
      "Epoch 95/100\n",
      "1242/1242 [==============================] - 203s 164ms/step - loss: 0.0060 - mean_squared_error: 0.0059 - mean_absolute_error: 0.0541 - val_loss: 0.0050 - val_mean_squared_error: 0.0049 - val_mean_absolute_error: 0.0460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f0bd7c0340>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(\n",
    "    x=batch_generator(X_train, Y_train, batch_size=batch_size, shuffle=True),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=100,  # Number of epochs to train for\n",
    "    validation_data=batch_generator(X_val, Y_val, batch_size=batch_size, shuffle=False),\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#evaluate the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('./models/eye_gaze_v18.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[1;32m----> 5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m screen_width, screen_height \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2650\u001b[39m, \u001b[38;5;241m1440\u001b[39m\n\u001b[0;32m      7\u001b[0m canvas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((screen_height, screen_width, \u001b[38;5;241m3\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\wgoud\\.conda\\envs\\py3_9_tf_12\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "#plot predicted vs actual on test data on a canvas using opencv \n",
    "\n",
    "import cv2\n",
    "import numpy as np \n",
    "predictions = model.predict(X_test)\n",
    "screen_width, screen_height = 2650, 1440\n",
    "canvas = np.zeros((screen_height, screen_width, 3), dtype=np.uint8)\n",
    "cv2.namedWindow('Gaze Tracking on Canvas', cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('Gaze Tracking on Canvas', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "# plot the first 10 images one by one\n",
    "for i in range(0,25):\n",
    "    \n",
    "    # get the predicted x,y coordinates\n",
    "    x, y = predictions[i][0] * screen_width, predictions[i][1] * screen_height\n",
    "\n",
    "    # lock the preds \n",
    "    x = min(max(x, 0), screen_width)\n",
    "    y = min(max(y, 0), screen_height)\n",
    "\n",
    "    # get the actual x,y coordinates\n",
    "    x_actual, y_actual = Y_test[i][0] * screen_width, Y_test[i][1] * screen_height\n",
    "\n",
    "    # plot the predicted x,y coordinates\n",
    "    cv2.circle(canvas, (int(x), int(y)), 10, (0, 0, 255), -1)\n",
    "    # plot the actual x,y coordinates\n",
    "    cv2.circle(canvas, (int(x_actual), int(y_actual)), 10, (0, 255, 0), -1 )\n",
    "    # show the canvas\n",
    "    cv2.imshow('Gaze Tracking on Canvas', canvas)\n",
    "    cv2.waitKey(0)\n",
    "    # # show the image \n",
    "    # cv2.imshow('image', X_test[i])\n",
    "    # cv2.waitKey(0)\n",
    "    # # clear the canvas\n",
    "    \n",
    "    canvas = np.zeros((screen_height, screen_width, 3), dtype=np.uint8)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/eye_gaze_v21.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.10_eye_gaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
