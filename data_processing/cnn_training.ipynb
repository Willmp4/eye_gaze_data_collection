{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import dlib\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eye_region(frame, eye_coords, target_size=(40, 48)):\n",
    "    \"\"\"\n",
    "    Preprocesses the eye region for the CNN model.\n",
    "    Args:\n",
    "        frame: The input image frame (in BGR format).\n",
    "        eye_coords: Coordinates of the eye region.\n",
    "        target_size: The target size for each eye region.\n",
    "    Returns:\n",
    "        The preprocessed eye region.\n",
    "    \"\"\"\n",
    "    x_min = min(x for x, y in eye_coords)\n",
    "    x_max = max(x for x, y in eye_coords)\n",
    "    y_min = min(y for x, y in eye_coords)\n",
    "    y_max = max(y for x, y in eye_coords)\n",
    "\n",
    "    # Cropping the eye region based on the extremities of the landmarks\n",
    "    cropped_eye = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    # Resizing the cropped eye region to the target size\n",
    "    resized_eye = cv2.resize(cropped_eye, target_size)\n",
    "\n",
    "    return resized_eye.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_eyes(frame):\n",
    "    \"\"\"\n",
    "    Detects and combines the eye regions from the frame.\n",
    "    Args:\n",
    "        frame: The input image frame.\n",
    "    Returns:\n",
    "        The combined eye regions, or None if not detected.\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "\n",
    "        # Extract the coordinates for each eye\n",
    "        left_eye = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(36, 42)]\n",
    "        right_eye = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(42, 48)]\n",
    "\n",
    "        # Preprocess each eye region\n",
    "        left_eye_region = preprocess_eye_region(frame, left_eye)\n",
    "\n",
    "        right_eye_region = preprocess_eye_region(frame, right_eye)\n",
    "\n",
    "        # Combine the eyes side by side\n",
    "        combined_eyes = np.hstack([left_eye_region, right_eye_region])\n",
    "\n",
    "        # Ensure the combined eyes image has the correct shape\n",
    "        if combined_eyes.shape[1] != 80:\n",
    "            raise ValueError(\"Combined eyes region does not match the expected width.\")\n",
    "        return combined_eyes\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_head_pose(head_pose_data, rotation_scale=180, translation_max_displacement=None):\n",
    "    \"\"\"\n",
    "    Normalizes the head pose data.\n",
    "    Args:\n",
    "        head_pose_data: List containing the head pose data (rotation and translation vectors).\n",
    "        rotation_scale: Maximum value for the rotation vector components (180 for degrees, np.pi for radians).\n",
    "        translation_max_displacement: A tuple (max_x, max_y, max_z) representing the maximum displacement in each axis. If None, standard deviation normalization will be used.\n",
    "\n",
    "    Returns:\n",
    "        Normalized head pose data.\n",
    "    \"\"\"\n",
    "    # Normalize rotation vectors\n",
    "    normalized_rotation = np.array(head_pose_data[:3]) / rotation_scale\n",
    "\n",
    "    # Normalize translation vectors\n",
    "    if translation_max_displacement:\n",
    "        max_x, max_y, max_z = translation_max_displacement\n",
    "        normalized_translation = np.array(head_pose_data[3:]) / np.array([max_x, max_y, max_z])\n",
    "    else:\n",
    "        # Standard deviation normalization\n",
    "        translation_vector = np.array(head_pose_data[3:])\n",
    "        std_dev = np.std(translation_vector)\n",
    "        mean_val = np.mean(translation_vector)\n",
    "        normalized_translation = (translation_vector - mean_val) / std_dev\n",
    "\n",
    "    return np.concatenate([normalized_rotation, normalized_translation]).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "# Assuming normalize_head_pose and get_combined_eyes are defined as before\n",
    "def get_screen_size(metadata_file_path):\n",
    "    with open(metadata_file_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "        # Check if 'screenData' is a key in the metadata\n",
    "        if 'screenData' in metadata:\n",
    "            metadata = metadata['screenData']\n",
    "        # Otherwise, assume the metadata is already at the top level\n",
    "\n",
    "        screen_width = metadata.get('screenWidth')\n",
    "        screen_height = metadata.get('screenHeight')\n",
    "\n",
    "        if screen_width is None or screen_height is None:\n",
    "            raise ValueError(\"Screen size not found in metadata\")\n",
    "\n",
    "        return screen_width, screen_height\n",
    "\n",
    "def parse_head_pose_data(row):\n",
    "    # Split the strings and convert to float\n",
    "    rotation_str, translation_str = row['head_pose'], row['head_translation']\n",
    "    rotation = [float(x) for x in rotation_str.strip('\"').split(',')]\n",
    "    translation = [float(x) for x in translation_str.strip('\"').split(',')]\n",
    "    return rotation + translation  # Combine into a single list\n",
    "\n",
    "def prepare_dataset(base_dir):\n",
    "    X, Y = [], []\n",
    "    processed_files = set()\n",
    "    column_names = ['image_path', 'cursor_x', 'cursor_y', 'left_pup', 'eye_y1', 'eye_x2', 'eye_y2', 'eye_x3', 'eye_y3', 'eye_x4', 'eye_y4', 'eye_x5', 'eye_y5', 'eye_x6', 'eye_y6', 'head_pose', 'head_translation']\n",
    "\n",
    "    for subdir in glob(os.path.join(base_dir, '*/')):\n",
    "        print(f\"Processing directory: {subdir}\")\n",
    "        metadata_file_path = os.path.join(subdir, 'metadata.json')\n",
    "        screen_width, screen_height = get_screen_size(metadata_file_path)\n",
    "        print(f\"Screen size: {screen_width}x{screen_height}\")\n",
    "\n",
    "        # Find any CSV files in the directory\n",
    "        csv_files = glob(os.path.join(subdir, '*.csv'))\n",
    "        #skip calibration files\n",
    "        # csv_files = [f for f in csv_files if 'calibration' not in f]\n",
    "\n",
    "        for data_file_path in csv_files:\n",
    "            if data_file_path in processed_files:\n",
    "                # Skip this file since it has already been processed\n",
    "                continue\n",
    "            processed_files.add(data_file_path)  # Mark this file as processed\n",
    "\n",
    "            print(f\"Processing data CSV file: {data_file_path}\")\n",
    "            data = pd.read_csv(data_file_path, header=None, names=column_names)\n",
    "\n",
    "            if not csv_files:\n",
    "                print(f\"No data CSV file found in directory: {subdir}\")\n",
    "                continue\n",
    "            # Find any directory that contains image files (assuming JPEG for example)\n",
    "            img_folders = [d for d in os.listdir(subdir) if os.path.isdir(os.path.join(subdir, d)) and glob(os.path.join(subdir, d, '*.png'))]\n",
    "            if not img_folders:\n",
    "                print(f\"No image folder found that contains images in directory: {subdir}\")\n",
    "                continue\n",
    "            data = pd.read_csv(data_file_path, header=None, names=column_names)\n",
    "            # print how many columns \n",
    "            print(data.shape)\n",
    "\n",
    "            for index, row in data.iterrows():\n",
    "                # Directly use the image path from the dataframe\n",
    "                img_path = os.path.join(row['image_path'])\n",
    "                cursor_x, cursor_y = row['cursor_x'], row['cursor_y']\n",
    "                eye_box_pupil_data = row[3:15].tolist()\n",
    "                head_pose_data = parse_head_pose_data(row)\n",
    "\n",
    "                normalized_eye_box_pupil_data = [float(coord) / screen_width if i % 2 == 0 else float(coord) / screen_height for i, coord in enumerate(eye_box_pupil_data)]\n",
    "                normalized_head_pose_data = normalize_head_pose(head_pose_data)\n",
    "\n",
    "                # Load the image\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    print(f\"Image not found: {img_path}\")\n",
    "                    continue\n",
    "\n",
    "                combined_eyes = get_combined_eyes(img)\n",
    "\n",
    "                # Append to datasets\n",
    "                Y.append([cursor_x / screen_width, cursor_y / screen_height] + normalized_eye_box_pupil_data + normalized_head_pose_data)\n",
    "                X.append(combined_eyes)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing directory: ./data\\eloise\\\n",
      "Screen size: 1440x900\n",
      "Processing data CSV file: ./data\\eloise\\calibration_data.csv\n",
      "(49, 17)\n",
      "Processing directory: ./data\\Hossein\\\n",
      "Screen size: 1536x864\n",
      "Processing data CSV file: ./data\\Hossein\\calibration_data.csv\n",
      "(53, 17)\n",
      "Processing data CSV file: ./data\\Hossein\\data.csv\n",
      "(19, 17)\n",
      "Processing directory: ./data\\koala\\\n",
      "Screen size: 1536x864\n",
      "Processing data CSV file: ./data\\koala\\calibration_data.csv\n",
      "(9, 17)\n",
      "Processing data CSV file: ./data\\koala\\eye_gaze_data.csv\n",
      "(2, 17)\n",
      "Processing directory: ./data\\melissa\\\n",
      "Screen size: 1710x1112\n",
      "Processing data CSV file: ./data\\melissa\\calibration_data.csv\n",
      "(49, 17)\n",
      "Processing data CSV file: ./data\\melissa\\data.csv\n",
      "(74, 17)\n",
      "Processing directory: ./data\\muzzy\\\n",
      "Screen size: 1536x864\n",
      "Processing data CSV file: ./data\\muzzy\\calibration_data.csv\n",
      "(30, 17)\n",
      "Processing data CSV file: ./data\\muzzy\\eye_gaze_data.csv\n",
      "(149, 17)\n",
      "Processing directory: ./data\\Naia\\\n",
      "Screen size: 1440x900\n",
      "Processing data CSV file: ./data\\Naia\\calibration_data.csv\n",
      "(53, 17)\n",
      "Processing data CSV file: ./data\\Naia\\eye_gaze_data.csv\n",
      "(90, 17)\n",
      "Processing directory: ./data\\PerfectUser\\\n",
      "Screen size: 1536x864\n",
      "Processing data CSV file: ./data\\PerfectUser\\calibration_data.csv\n",
      "(53, 17)\n",
      "Processing data CSV file: ./data\\PerfectUser\\eye_gaze_data.csv\n",
      "(4, 17)\n",
      "Processing directory: ./data\\Shaq\\\n",
      "Screen size: 1280x720\n",
      "Processing data CSV file: ./data\\Shaq\\calibration_data.csv\n",
      "(53, 17)\n",
      "Processing data CSV file: ./data\\Shaq\\data.csv\n",
      "(29, 17)\n",
      "Processing directory: ./data\\Will\\\n",
      "Screen size: 1707x960\n",
      "Processing data CSV file: ./data\\Will\\calibration_data.csv\n",
      "(172, 17)\n",
      "Processing data CSV file: ./data\\Will\\eye_gaze_data.csv\n",
      "(358, 17)\n",
      "Processing directory: ./data\\William\\\n",
      "Screen size: 1707x960\n",
      "Processing data CSV file: ./data\\William\\calibration_data.csv\n",
      "(210, 17)\n",
      "Processing data CSV file: ./data\\William\\eye_gaze_data.csv\n",
      "(555, 17)\n",
      "Processing directory: ./data\\WilliamOld\\\n",
      "Screen size: 2560x1440\n",
      "Processing data CSV file: ./data\\WilliamOld\\data1.csv\n",
      "(1810, 17)\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "base_dir = './data'\n",
    "X, Y = prepare_dataset(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_filtered = [img for img in X if img is not None and isinstance(img, np.ndarray)]\n",
    "Y_filtered = [Y[i] for i in range(len(Y)) if X[i] is not None and isinstance(X[i], np.ndarray)]\n",
    "\n",
    "X_filtered = np.array(X_filtered)\n",
    "\n",
    "Y_filtered = np.array(Y_filtered)\n",
    "Y_filtered = Y_filtered[:, :14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3821, 3821)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_filtered), len(Y_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_filtered, Y_filtered, test_size=0.2, random_state=42)\n",
    "#Val data\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense, MaxPool2D\n",
    "from keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 80, 3)), \n",
    "    MaxPool2D(),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(14) \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[MeanSquaredError(), MeanAbsoluteError()])\n",
    "model.fit(X_train, Y_train, epochs=100, validation_split=0.1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "77/77 [==============================] - 8s 96ms/step - loss: 0.2284 - mean_squared_error: 0.1392 - mean_absolute_error: 0.2572 - val_loss: 0.1564 - val_mean_squared_error: 0.0689 - val_mean_absolute_error: 0.1702\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 0.1302 - mean_squared_error: 0.0443 - mean_absolute_error: 0.1506 - val_loss: 0.1500 - val_mean_squared_error: 0.0659 - val_mean_absolute_error: 0.1656\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 0.1199 - mean_squared_error: 0.0374 - mean_absolute_error: 0.1360 - val_loss: 0.1432 - val_mean_squared_error: 0.0624 - val_mean_absolute_error: 0.1607\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 9s 114ms/step - loss: 0.1134 - mean_squared_error: 0.0342 - mean_absolute_error: 0.1272 - val_loss: 0.1360 - val_mean_squared_error: 0.0583 - val_mean_absolute_error: 0.1556\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 9s 118ms/step - loss: 0.1095 - mean_squared_error: 0.0332 - mean_absolute_error: 0.1242 - val_loss: 0.1284 - val_mean_squared_error: 0.0537 - val_mean_absolute_error: 0.1495\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 8s 110ms/step - loss: 0.1042 - mean_squared_error: 0.0308 - mean_absolute_error: 0.1189 - val_loss: 0.1206 - val_mean_squared_error: 0.0486 - val_mean_absolute_error: 0.1430\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 9s 111ms/step - loss: 0.1000 - mean_squared_error: 0.0293 - mean_absolute_error: 0.1156 - val_loss: 0.1127 - val_mean_squared_error: 0.0432 - val_mean_absolute_error: 0.1349\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 9s 116ms/step - loss: 0.0965 - mean_squared_error: 0.0283 - mean_absolute_error: 0.1117 - val_loss: 0.1059 - val_mean_squared_error: 0.0389 - val_mean_absolute_error: 0.1292\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 9s 118ms/step - loss: 0.0930 - mean_squared_error: 0.0272 - mean_absolute_error: 0.1087 - val_loss: 0.1006 - val_mean_squared_error: 0.0358 - val_mean_absolute_error: 0.1258\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 9s 114ms/step - loss: 0.0898 - mean_squared_error: 0.0261 - mean_absolute_error: 0.1060 - val_loss: 0.0958 - val_mean_squared_error: 0.0332 - val_mean_absolute_error: 0.1221\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 9s 117ms/step - loss: 0.0874 - mean_squared_error: 0.0258 - mean_absolute_error: 0.1040 - val_loss: 0.0897 - val_mean_squared_error: 0.0291 - val_mean_absolute_error: 0.1134\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 11s 137ms/step - loss: 0.0840 - mean_squared_error: 0.0244 - mean_absolute_error: 0.1014 - val_loss: 0.0865 - val_mean_squared_error: 0.0278 - val_mean_absolute_error: 0.1102\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 10s 133ms/step - loss: 0.0818 - mean_squared_error: 0.0240 - mean_absolute_error: 0.1003 - val_loss: 0.0826 - val_mean_squared_error: 0.0256 - val_mean_absolute_error: 0.1041\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 10s 132ms/step - loss: 0.0790 - mean_squared_error: 0.0229 - mean_absolute_error: 0.0973 - val_loss: 0.0795 - val_mean_squared_error: 0.0243 - val_mean_absolute_error: 0.0996\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 0.0770 - mean_squared_error: 0.0226 - mean_absolute_error: 0.0963 - val_loss: 0.0764 - val_mean_squared_error: 0.0228 - val_mean_absolute_error: 0.0957\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 10s 130ms/step - loss: 0.0744 - mean_squared_error: 0.0216 - mean_absolute_error: 0.0942 - val_loss: 0.0737 - val_mean_squared_error: 0.0218 - val_mean_absolute_error: 0.0917\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 0.0723 - mean_squared_error: 0.0210 - mean_absolute_error: 0.0922 - val_loss: 0.0714 - val_mean_squared_error: 0.0209 - val_mean_absolute_error: 0.0885\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 0.0707 - mean_squared_error: 0.0209 - mean_absolute_error: 0.0918 - val_loss: 0.0688 - val_mean_squared_error: 0.0198 - val_mean_absolute_error: 0.0841\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 10s 129ms/step - loss: 0.0688 - mean_squared_error: 0.0205 - mean_absolute_error: 0.0904 - val_loss: 0.0673 - val_mean_squared_error: 0.0197 - val_mean_absolute_error: 0.0841\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 0.0666 - mean_squared_error: 0.0196 - mean_absolute_error: 0.0882 - val_loss: 0.0653 - val_mean_squared_error: 0.0191 - val_mean_absolute_error: 0.0812\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 10s 129ms/step - loss: 0.0649 - mean_squared_error: 0.0193 - mean_absolute_error: 0.0869 - val_loss: 0.0632 - val_mean_squared_error: 0.0183 - val_mean_absolute_error: 0.0792\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0636 - mean_squared_error: 0.0194 - mean_absolute_error: 0.0865 - val_loss: 0.0615 - val_mean_squared_error: 0.0178 - val_mean_absolute_error: 0.0774\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 10s 135ms/step - loss: 0.0615 - mean_squared_error: 0.0186 - mean_absolute_error: 0.0843 - val_loss: 0.0598 - val_mean_squared_error: 0.0174 - val_mean_absolute_error: 0.0742\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 0.0601 - mean_squared_error: 0.0184 - mean_absolute_error: 0.0838 - val_loss: 0.0586 - val_mean_squared_error: 0.0175 - val_mean_absolute_error: 0.0748\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 0.0586 - mean_squared_error: 0.0181 - mean_absolute_error: 0.0826 - val_loss: 0.0571 - val_mean_squared_error: 0.0172 - val_mean_absolute_error: 0.0748\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0570 - mean_squared_error: 0.0177 - mean_absolute_error: 0.0814 - val_loss: 0.0560 - val_mean_squared_error: 0.0173 - val_mean_absolute_error: 0.0749\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 10s 129ms/step - loss: 0.0555 - mean_squared_error: 0.0174 - mean_absolute_error: 0.0808 - val_loss: 0.0544 - val_mean_squared_error: 0.0168 - val_mean_absolute_error: 0.0732\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 10s 132ms/step - loss: 0.0541 - mean_squared_error: 0.0171 - mean_absolute_error: 0.0794 - val_loss: 0.0532 - val_mean_squared_error: 0.0167 - val_mean_absolute_error: 0.0725\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 10s 131ms/step - loss: 0.0529 - mean_squared_error: 0.0170 - mean_absolute_error: 0.0787 - val_loss: 0.0521 - val_mean_squared_error: 0.0168 - val_mean_absolute_error: 0.0734\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 0.0516 - mean_squared_error: 0.0168 - mean_absolute_error: 0.0787 - val_loss: 0.0508 - val_mean_squared_error: 0.0166 - val_mean_absolute_error: 0.0724\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 0.0504 - mean_squared_error: 0.0167 - mean_absolute_error: 0.0778 - val_loss: 0.0502 - val_mean_squared_error: 0.0170 - val_mean_absolute_error: 0.0753\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0491 - mean_squared_error: 0.0164 - mean_absolute_error: 0.0769 - val_loss: 0.0482 - val_mean_squared_error: 0.0161 - val_mean_absolute_error: 0.0698\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 10s 129ms/step - loss: 0.0478 - mean_squared_error: 0.0161 - mean_absolute_error: 0.0761 - val_loss: 0.0475 - val_mean_squared_error: 0.0163 - val_mean_absolute_error: 0.0721\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 10s 129ms/step - loss: 0.0466 - mean_squared_error: 0.0159 - mean_absolute_error: 0.0754 - val_loss: 0.0467 - val_mean_squared_error: 0.0165 - val_mean_absolute_error: 0.0740\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 10s 131ms/step - loss: 0.0453 - mean_squared_error: 0.0156 - mean_absolute_error: 0.0749 - val_loss: 0.0454 - val_mean_squared_error: 0.0162 - val_mean_absolute_error: 0.0714\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 10s 130ms/step - loss: 0.0445 - mean_squared_error: 0.0158 - mean_absolute_error: 0.0746 - val_loss: 0.0441 - val_mean_squared_error: 0.0158 - val_mean_absolute_error: 0.0699\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 0.0432 - mean_squared_error: 0.0154 - mean_absolute_error: 0.0735 - val_loss: 0.0429 - val_mean_squared_error: 0.0156 - val_mean_absolute_error: 0.0698\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 10s 132ms/step - loss: 0.0421 - mean_squared_error: 0.0153 - mean_absolute_error: 0.0730 - val_loss: 0.0417 - val_mean_squared_error: 0.0153 - val_mean_absolute_error: 0.0689\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 10s 134ms/step - loss: 0.0412 - mean_squared_error: 0.0152 - mean_absolute_error: 0.0730 - val_loss: 0.0411 - val_mean_squared_error: 0.0156 - val_mean_absolute_error: 0.0706\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 10s 128ms/step - loss: 0.0400 - mean_squared_error: 0.0149 - mean_absolute_error: 0.0717 - val_loss: 0.0396 - val_mean_squared_error: 0.0149 - val_mean_absolute_error: 0.0665\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0389 - mean_squared_error: 0.0146 - mean_absolute_error: 0.0708 - val_loss: 0.0394 - val_mean_squared_error: 0.0156 - val_mean_absolute_error: 0.0713\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 9s 118ms/step - loss: 0.0381 - mean_squared_error: 0.0146 - mean_absolute_error: 0.0705 - val_loss: 0.0385 - val_mean_squared_error: 0.0155 - val_mean_absolute_error: 0.0687\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 9s 119ms/step - loss: 0.0369 - mean_squared_error: 0.0142 - mean_absolute_error: 0.0694 - val_loss: 0.0381 - val_mean_squared_error: 0.0158 - val_mean_absolute_error: 0.0699\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 0.0361 - mean_squared_error: 0.0142 - mean_absolute_error: 0.0692 - val_loss: 0.0361 - val_mean_squared_error: 0.0146 - val_mean_absolute_error: 0.0666\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 9s 112ms/step - loss: 0.0351 - mean_squared_error: 0.0140 - mean_absolute_error: 0.0683 - val_loss: 0.0350 - val_mean_squared_error: 0.0143 - val_mean_absolute_error: 0.0649\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 9s 114ms/step - loss: 0.0342 - mean_squared_error: 0.0138 - mean_absolute_error: 0.0679 - val_loss: 0.0340 - val_mean_squared_error: 0.0139 - val_mean_absolute_error: 0.0625\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 9s 112ms/step - loss: 0.0332 - mean_squared_error: 0.0135 - mean_absolute_error: 0.0673 - val_loss: 0.0337 - val_mean_squared_error: 0.0144 - val_mean_absolute_error: 0.0657\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 9s 112ms/step - loss: 0.0325 - mean_squared_error: 0.0135 - mean_absolute_error: 0.0665 - val_loss: 0.0330 - val_mean_squared_error: 0.0144 - val_mean_absolute_error: 0.0662\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 8s 109ms/step - loss: 0.0317 - mean_squared_error: 0.0134 - mean_absolute_error: 0.0662 - val_loss: 0.0313 - val_mean_squared_error: 0.0134 - val_mean_absolute_error: 0.0617\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 9s 113ms/step - loss: 0.0308 - mean_squared_error: 0.0131 - mean_absolute_error: 0.0653 - val_loss: 0.0317 - val_mean_squared_error: 0.0144 - val_mean_absolute_error: 0.0664\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 9s 114ms/step - loss: 0.0300 - mean_squared_error: 0.0130 - mean_absolute_error: 0.0649 - val_loss: 0.0304 - val_mean_squared_error: 0.0137 - val_mean_absolute_error: 0.0618\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 9s 111ms/step - loss: 0.0292 - mean_squared_error: 0.0128 - mean_absolute_error: 0.0634 - val_loss: 0.0295 - val_mean_squared_error: 0.0135 - val_mean_absolute_error: 0.0603\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 0.0285 - mean_squared_error: 0.0127 - mean_absolute_error: 0.0634 - val_loss: 0.0292 - val_mean_squared_error: 0.0137 - val_mean_absolute_error: 0.0620\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 0.0278 - mean_squared_error: 0.0126 - mean_absolute_error: 0.0630 - val_loss: 0.0281 - val_mean_squared_error: 0.0131 - val_mean_absolute_error: 0.0608\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 8s 109ms/step - loss: 0.0271 - mean_squared_error: 0.0125 - mean_absolute_error: 0.0622 - val_loss: 0.0271 - val_mean_squared_error: 0.0127 - val_mean_absolute_error: 0.0567\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 8s 109ms/step - loss: 0.0265 - mean_squared_error: 0.0123 - mean_absolute_error: 0.0621 - val_loss: 0.0271 - val_mean_squared_error: 0.0132 - val_mean_absolute_error: 0.0604\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 8s 110ms/step - loss: 0.0257 - mean_squared_error: 0.0121 - mean_absolute_error: 0.0612 - val_loss: 0.0263 - val_mean_squared_error: 0.0130 - val_mean_absolute_error: 0.0576\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 8s 108ms/step - loss: 0.0250 - mean_squared_error: 0.0119 - mean_absolute_error: 0.0604 - val_loss: 0.0254 - val_mean_squared_error: 0.0125 - val_mean_absolute_error: 0.0556\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 9s 113ms/step - loss: 0.0246 - mean_squared_error: 0.0120 - mean_absolute_error: 0.0604 - val_loss: 0.0253 - val_mean_squared_error: 0.0129 - val_mean_absolute_error: 0.0567\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 9s 113ms/step - loss: 0.0243 - mean_squared_error: 0.0121 - mean_absolute_error: 0.0602 - val_loss: 0.0242 - val_mean_squared_error: 0.0123 - val_mean_absolute_error: 0.0537\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 8s 109ms/step - loss: 0.0235 - mean_squared_error: 0.0118 - mean_absolute_error: 0.0595 - val_loss: 0.0233 - val_mean_squared_error: 0.0118 - val_mean_absolute_error: 0.0529\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 8s 108ms/step - loss: 0.0230 - mean_squared_error: 0.0118 - mean_absolute_error: 0.0589 - val_loss: 0.0235 - val_mean_squared_error: 0.0125 - val_mean_absolute_error: 0.0565\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 0.0224 - mean_squared_error: 0.0115 - mean_absolute_error: 0.0586 - val_loss: 0.0224 - val_mean_squared_error: 0.0118 - val_mean_absolute_error: 0.0529\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 0.0220 - mean_squared_error: 0.0115 - mean_absolute_error: 0.0582 - val_loss: 0.0221 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0535\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 0.0216 - mean_squared_error: 0.0116 - mean_absolute_error: 0.0578 - val_loss: 0.0217 - val_mean_squared_error: 0.0118 - val_mean_absolute_error: 0.0526\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 0.0208 - mean_squared_error: 0.0111 - mean_absolute_error: 0.0568 - val_loss: 0.0211 - val_mean_squared_error: 0.0116 - val_mean_absolute_error: 0.0514\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 0.0206 - mean_squared_error: 0.0113 - mean_absolute_error: 0.0568 - val_loss: 0.0205 - val_mean_squared_error: 0.0114 - val_mean_absolute_error: 0.0505\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 0.0201 - mean_squared_error: 0.0111 - mean_absolute_error: 0.0563 - val_loss: 0.0202 - val_mean_squared_error: 0.0114 - val_mean_absolute_error: 0.0506\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 0.0196 - mean_squared_error: 0.0110 - mean_absolute_error: 0.0563 - val_loss: 0.0198 - val_mean_squared_error: 0.0113 - val_mean_absolute_error: 0.0496\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 0.0192 - mean_squared_error: 0.0109 - mean_absolute_error: 0.0555 - val_loss: 0.0195 - val_mean_squared_error: 0.0113 - val_mean_absolute_error: 0.0487\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 8s 108ms/step - loss: 0.0189 - mean_squared_error: 0.0109 - mean_absolute_error: 0.0553 - val_loss: 0.0191 - val_mean_squared_error: 0.0112 - val_mean_absolute_error: 0.0475\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 8s 110ms/step - loss: 0.0187 - mean_squared_error: 0.0109 - mean_absolute_error: 0.0547 - val_loss: 0.0194 - val_mean_squared_error: 0.0118 - val_mean_absolute_error: 0.0492\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 8s 109ms/step - loss: 0.0185 - mean_squared_error: 0.0110 - mean_absolute_error: 0.0549 - val_loss: 0.0184 - val_mean_squared_error: 0.0110 - val_mean_absolute_error: 0.0473\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 8s 109ms/step - loss: 0.0178 - mean_squared_error: 0.0106 - mean_absolute_error: 0.0539 - val_loss: 0.0184 - val_mean_squared_error: 0.0113 - val_mean_absolute_error: 0.0468\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 8s 104ms/step - loss: 0.0176 - mean_squared_error: 0.0106 - mean_absolute_error: 0.0536 - val_loss: 0.0172 - val_mean_squared_error: 0.0103 - val_mean_absolute_error: 0.0441\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 0.0174 - mean_squared_error: 0.0107 - mean_absolute_error: 0.0536 - val_loss: 0.0176 - val_mean_squared_error: 0.0110 - val_mean_absolute_error: 0.0471\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 0.0171 - mean_squared_error: 0.0106 - mean_absolute_error: 0.0533 - val_loss: 0.0172 - val_mean_squared_error: 0.0108 - val_mean_absolute_error: 0.0460\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 8s 109ms/step - loss: 0.0169 - mean_squared_error: 0.0106 - mean_absolute_error: 0.0532 - val_loss: 0.0168 - val_mean_squared_error: 0.0107 - val_mean_absolute_error: 0.0452\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 0.0163 - mean_squared_error: 0.0102 - mean_absolute_error: 0.0522 - val_loss: 0.0160 - val_mean_squared_error: 0.0100 - val_mean_absolute_error: 0.0426\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 9s 111ms/step - loss: 0.0163 - mean_squared_error: 0.0104 - mean_absolute_error: 0.0525 - val_loss: 0.0167 - val_mean_squared_error: 0.0109 - val_mean_absolute_error: 0.0462\n",
      "Epoch 81/100\n",
      "77/77 [==============================] - 8s 110ms/step - loss: 0.0161 - mean_squared_error: 0.0104 - mean_absolute_error: 0.0520 - val_loss: 0.0162 - val_mean_squared_error: 0.0106 - val_mean_absolute_error: 0.0447\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 8s 107ms/step - loss: 0.0157 - mean_squared_error: 0.0102 - mean_absolute_error: 0.0516 - val_loss: 0.0158 - val_mean_squared_error: 0.0103 - val_mean_absolute_error: 0.0439\n",
      "Epoch 83/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 0.0155 - mean_squared_error: 0.0101 - mean_absolute_error: 0.0507 - val_loss: 0.0152 - val_mean_squared_error: 0.0100 - val_mean_absolute_error: 0.0418\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 0.0153 - mean_squared_error: 0.0101 - mean_absolute_error: 0.0510 - val_loss: 0.0151 - val_mean_squared_error: 0.0100 - val_mean_absolute_error: 0.0419\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 0.0151 - mean_squared_error: 0.0101 - mean_absolute_error: 0.0511 - val_loss: 0.0157 - val_mean_squared_error: 0.0107 - val_mean_absolute_error: 0.0452\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 0.0149 - mean_squared_error: 0.0100 - mean_absolute_error: 0.0501 - val_loss: 0.0151 - val_mean_squared_error: 0.0102 - val_mean_absolute_error: 0.0425\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 8s 106ms/step - loss: 0.0147 - mean_squared_error: 0.0099 - mean_absolute_error: 0.0502 - val_loss: 0.0150 - val_mean_squared_error: 0.0103 - val_mean_absolute_error: 0.0431\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 0.0145 - mean_squared_error: 0.0098 - mean_absolute_error: 0.0496 - val_loss: 0.0149 - val_mean_squared_error: 0.0103 - val_mean_absolute_error: 0.0429\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 0.0145 - mean_squared_error: 0.0100 - mean_absolute_error: 0.0498 - val_loss: 0.0145 - val_mean_squared_error: 0.0100 - val_mean_absolute_error: 0.0412\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 0.0143 - mean_squared_error: 0.0098 - mean_absolute_error: 0.0493 - val_loss: 0.0148 - val_mean_squared_error: 0.0104 - val_mean_absolute_error: 0.0422\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 0.0140 - mean_squared_error: 0.0097 - mean_absolute_error: 0.0487 - val_loss: 0.0144 - val_mean_squared_error: 0.0101 - val_mean_absolute_error: 0.0411\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 0.0139 - mean_squared_error: 0.0097 - mean_absolute_error: 0.0484 - val_loss: 0.0146 - val_mean_squared_error: 0.0105 - val_mean_absolute_error: 0.0443\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 0.0139 - mean_squared_error: 0.0097 - mean_absolute_error: 0.0485 - val_loss: 0.0141 - val_mean_squared_error: 0.0101 - val_mean_absolute_error: 0.0419\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 8s 103ms/step - loss: 0.0137 - mean_squared_error: 0.0097 - mean_absolute_error: 0.0486 - val_loss: 0.0140 - val_mean_squared_error: 0.0101 - val_mean_absolute_error: 0.0412\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 8s 102ms/step - loss: 0.0136 - mean_squared_error: 0.0097 - mean_absolute_error: 0.0480 - val_loss: 0.0137 - val_mean_squared_error: 0.0098 - val_mean_absolute_error: 0.0403\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 0.0134 - mean_squared_error: 0.0095 - mean_absolute_error: 0.0475 - val_loss: 0.0140 - val_mean_squared_error: 0.0102 - val_mean_absolute_error: 0.0417\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 0.0132 - mean_squared_error: 0.0095 - mean_absolute_error: 0.0473 - val_loss: 0.0138 - val_mean_squared_error: 0.0101 - val_mean_absolute_error: 0.0408\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 8s 109ms/step - loss: 0.0131 - mean_squared_error: 0.0094 - mean_absolute_error: 0.0472 - val_loss: 0.0135 - val_mean_squared_error: 0.0098 - val_mean_absolute_error: 0.0396\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 8s 105ms/step - loss: 0.0130 - mean_squared_error: 0.0094 - mean_absolute_error: 0.0468 - val_loss: 0.0134 - val_mean_squared_error: 0.0098 - val_mean_absolute_error: 0.0401\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 8s 108ms/step - loss: 0.0127 - mean_squared_error: 0.0092 - mean_absolute_error: 0.0462 - val_loss: 0.0130 - val_mean_squared_error: 0.0095 - val_mean_absolute_error: 0.0384\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    # rotation_range=20,\n",
    "    # width_shift_range=0.1,\n",
    "    # height_shift_range=0.1,\n",
    "    # shear_range=0.2,\n",
    "    # zoom_range=[0.9, 1.1],\n",
    "    # horizontal_flip=True,\n",
    "    # fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Assuming you have your training data in train_data and train_labels\n",
    "train_generator = train_datagen.flow(X_train, Y_train, batch_size=32)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Adding L2 Regularization to Convolutional Layers\n",
    "l2_reg = 0.001\n",
    "\n",
    "# First Conv Block\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 80, 3), kernel_regularizer=l2(l2_reg)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Second Conv Block\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "# Third Conv Block\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# Fourth Conv Block\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# Flatten and Dense Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(14))  # Adjust the number of outputs as needed\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.00005), loss='mse', metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,  # Adjust number of epochs\n",
    "    validation_data=(X_val, Y_val),  # Assuming validation data is available\n",
    "    callbacks=[early_stopping],\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers with dropout\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 80, 3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.25))  # Dropout layer after pooling\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.25))  # Another dropout layer\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.4))  # Higher dropout rate for deeper layers\n",
    "\n",
    "# Flatten the output from convolutional layers before passing it to the dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add dense layers with dropout\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout layer before the output layer\n",
    "model.add(Dense(14, activation='sigmoid'))  # Adjust the number of outputs as needed\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "model.fit(X_train, Y_train, epochs=100, validation_split=0.1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 18ms/step - loss: 0.0133 - mean_squared_error: 0.0098 - mean_absolute_error: 0.0391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.013337544165551662, 0.009809695184230804, 0.03913525491952896]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate the model\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('./models/eye_gaze_v10_3800v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 16ms/step\n",
      "656.0080021619797 664.2289352416992\n",
      "1001.3181019332161 892.5\n",
      "1751.6347140073776 1350.9301471710205\n",
      "424.4140625 1348.0\n",
      "2665.245872735977 1235.9159088134766\n",
      "2409.84375 1306.0\n",
      "728.4108132123947 1332.5440120697021\n",
      "313.65234375 1417.0\n",
      "1335.2465242147446 715.5313110351562\n",
      "810.3690685413005 1221.0\n",
      "2365.419378876686 1067.3769664764404\n",
      "2265.95703125 691.0\n",
      "2325.101736187935 1040.5418300628662\n",
      "2505.078125 834.0000000000001\n",
      "1916.7950183153152 570.1615905761719\n",
      "1309.47265625 335.0\n",
      "749.0452289581299 1460.4592895507812\n",
      "819.84375 1412.0\n",
      "1108.8196784257889 1104.1140460968018\n",
      "338.42999414176916 1428.0\n",
      "1278.733952343464 325.323543548584\n",
      "1394.3554687499998 19.0\n",
      "1242.6920786499977 589.9280548095703\n",
      "1648.6818980667838 375.0\n",
      "1088.113710284233 736.0221862792969\n",
      "2334.85647334505 1314.0\n",
      "1284.9935233592987 722.7606582641602\n",
      "2329.1015625 206.66666666666666\n",
      "2339.668098092079 547.3868894577026\n",
      "2339.453125 166.0\n",
      "1315.3618291020393 417.12246894836426\n",
      "1648.6818980667838 547.5\n",
      "1175.4302993416786 658.0673217773438\n",
      "2240.877192982456 481.72661870503595\n",
      "1472.5727885961533 485.56034088134766\n",
      "2087.4561403508774 458.41726618705036\n",
      "1131.1334431171417 564.7453308105469\n",
      "1766.6666666666665 477.0\n",
      "401.916441321373 854.4343757629395\n",
      "160.44921875 1151.0\n",
      "1111.785864830017 804.6253681182861\n",
      "2618.9513766842415 1435.5\n",
      "1100.7406547665596 652.7230739593506\n",
      "409.1228070175439 540.0\n",
      "825.1052677631378 647.0816802978516\n",
      "0.0 0.0\n",
      "1431.1979711055756 629.1018676757812\n",
      "678.7719298245614 1240.5755395683452\n",
      "1787.6277804374695 976.422872543335\n",
      "773.1107205623902 450.0\n",
      "1136.9640946388245 709.2624092102051\n",
      "1364.6809895833335 1408.3333333333335\n",
      "1421.9890356063843 693.9705562591553\n",
      "678.4124194493263 1237.5\n",
      "1575.5338430404663 639.1402816772461\n",
      "1417.12890625 1091.0\n",
      "728.7778943777084 549.2334938049316\n",
      "2296.0456942003516 202.5\n",
      "996.2515696883202 297.0669221878052\n",
      "814.66796875 330.0\n",
      "960.9583899378777 750.0386810302734\n",
      "971.3216145833333 11.666666666666666\n",
      "876.7293736338615 195.10345458984375\n",
      "789.82421875 76.0\n",
      "2021.448689699173 1040.522174835205\n",
      "1970.2473958333335 1063.3333333333333\n",
      "948.1870770454407 743.877067565918\n",
      "353.9543057996485 1237.5\n",
      "1403.7186920642853 844.152717590332\n",
      "453.3099004100761 309.0\n",
      "2281.799268722534 800.616044998169\n",
      "2412.94921875 623.0\n",
      "617.109876871109 525.6522846221924\n",
      "125.7469244288225 663.0\n",
      "715.7587543129921 855.2907943725586\n",
      "225.10251903925015 792.0000000000001\n",
      "854.1621744632721 1086.8994140625\n",
      "381.89806678383127 508.50000000000006\n",
      "1772.7450400590897 833.8400745391846\n",
      "2632.9232571763328 1383.0\n",
      "361.62545308470726 1264.701976776123\n",
      "726.6796875 913.0\n",
      "2733.328056335449 470.12858390808105\n",
      "2524.74609375 156.0\n",
      "1254.7130391001701 708.2014560699463\n",
      "124.21875 166.66666666666666\n",
      "1097.1726700663567 616.981029510498\n",
      "1328.6805555555554 548.8000000000001\n",
      "1017.4324214458466 717.9779148101807\n",
      "353.9543057996485 720.0\n",
      "1614.108008146286 124.87290143966675\n",
      "1590.0 0.0\n",
      "1955.9861451387405 926.3680458068848\n",
      "1696.8072642062098 1152.0\n",
      "1094.9325904250145 679.4265460968018\n",
      "0.0 0.0\n",
      "841.9880792498589 1050.417766571045\n",
      "1164.55078125 830.9999999999999\n"
     ]
    }
   ],
   "source": [
    "#plot predicted vs actual on test data on a canvas using opencv \n",
    "\n",
    "import cv2\n",
    "import numpy as np \n",
    "predictions = model.predict(X_test)\n",
    "screen_width, screen_height = 2650, 1440\n",
    "canvas = np.zeros((screen_height, screen_width, 3), dtype=np.uint8)\n",
    "cv2.namedWindow('Gaze Tracking on Canvas', cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('Gaze Tracking on Canvas', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "# plot the first 10 images one by one\n",
    "for i in range(1,50):\n",
    "    # get the predicted x,y coordinates\n",
    "    x, y = predictions[i][0] * screen_width, predictions[i][1] * screen_height\n",
    "    print(x,y)\n",
    "    # get the actual x,y coordinates\n",
    "    x_actual, y_actual = Y_test[i][0] * screen_width, Y_test[i][1] * screen_height\n",
    "    print(x_actual, y_actual)\n",
    "    # plot the predicted x,y coordinates\n",
    "    cv2.circle(canvas, (int(x), int(y)), 10, (0, 0, 255), -1)\n",
    "    # plot the actual x,y coordinates\n",
    "    cv2.circle(canvas, (int(x_actual), int(y_actual)), 10, (0, 255, 0), -1)\n",
    "    # show the canvas\n",
    "    cv2.imshow('Gaze Tracking on Canvas', canvas)\n",
    "    cv2.waitKey(0)\n",
    "    # clear the canvas\n",
    "    canvas = np.zeros((screen_height, screen_width, 3), dtype=np.uint8)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/eye_gaze_v12_3600v2.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.10_eye_gaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
