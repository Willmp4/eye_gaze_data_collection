{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_processed_data(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        X, Y = pickle.load(file)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_processed_data('./pickel_files/calibration_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_filtered = [img for img in X if img is not None and isinstance(img, np.ndarray)]\n",
    "Y_filtered = [Y[i] for i in range(len(Y)) if X[i] is not None and isinstance(X[i], np.ndarray)]\n",
    "\n",
    "X_filtered = np.array(X_filtered)\n",
    "\n",
    "Y_filtered = np.array(Y_filtered)\n",
    "Y_filtered = Y_filtered[:, :2]\n",
    "\n",
    "#convert to float\n",
    "Y_filtered = Y_filtered.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3978, 3978)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_filtered), len(Y_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_filtered, Y_filtered, test_size=0.2, random_state=42)\n",
    "#Val data\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/80 [===>..........................] - ETA: 10:11 - loss: 3.9217 - mean_squared_error: 0.3556 - mean_absolute_error: 0.4993"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    # rotation_range=5,\n",
    "    # width_shift_range=0.02,\n",
    "    # height_shift_range=0.02,\n",
    "    # zoom_range=[0.95, 1.05],\n",
    "    # brightness_range=[0.8, 1.2],\n",
    "    # shear_range=0.1,\n",
    "    # fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "# Assuming you have your training data in train_data and train_labels\n",
    "train_generator = train_datagen.flow(X_train, Y_train, batch_size=32)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Adding L2 Regularization to Convolutional Layers\n",
    "l2_reg = 0.001\n",
    "\n",
    "# First Conv Block\n",
    "model.add(Conv2D(32, (7, 7), activation='relu', input_shape=(48, 80, 3), kernel_regularizer=l2(l2_reg)))\n",
    "\n",
    "# Second Conv Block\n",
    "model.add(Conv2D(64, (7, 7), activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Conv2D(128, (5, 5), activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "# Third Conv Block\n",
    "model.add(Conv2D(256, (5, 5), activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Fourth Conv Block\n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Fifth Conv Block\n",
    "model.add(Conv2D(1028, (3, 3), activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Sixth Conv Block\n",
    "model.add(Conv2D(2056, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Seventh Conv Block\n",
    "model.add(Conv2D(4112, (1, 1), activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Flatten and Dense Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.00005), loss='mse', metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,  # Adjust number of epochs\n",
    "    validation_data=(X_val, Y_val),  # Assuming validation data is available\n",
    "      callbacks=[early_stopping],\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 3s 113ms/step - loss: 0.0204 - mean_squared_error: 0.0170 - mean_absolute_error: 0.0852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.020439883694052696, 0.01704290322959423, 0.08516847342252731]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate the model\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('./models/eye_gaze_v18.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 29ms/step\n"
     ]
    }
   ],
   "source": [
    "#plot predicted vs actual on test data on a canvas using opencv \n",
    "\n",
    "import cv2\n",
    "import numpy as np \n",
    "predictions = model.predict(X_test)\n",
    "screen_width, screen_height = 2650, 1440\n",
    "canvas = np.zeros((screen_height, screen_width, 3), dtype=np.uint8)\n",
    "cv2.namedWindow('Gaze Tracking on Canvas', cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('Gaze Tracking on Canvas', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "# plot the first 10 images one by one\n",
    "for i in range(0,25):\n",
    "    \n",
    "    # get the predicted x,y coordinates\n",
    "    x, y = predictions[i][0] * screen_width, predictions[i][1] * screen_height\n",
    "\n",
    "    # lock the preds \n",
    "    x = min(max(x, 0), screen_width)\n",
    "    y = min(max(y, 0), screen_height)\n",
    "\n",
    "    # get the actual x,y coordinates\n",
    "    x_actual, y_actual = Y_test[i][0] * screen_width, Y_test[i][1] * screen_height\n",
    "\n",
    "    # plot the predicted x,y coordinates\n",
    "    cv2.circle(canvas, (int(x), int(y)), 10, (0, 0, 255), -1)\n",
    "    # plot the actual x,y coordinates\n",
    "    cv2.circle(canvas, (int(x_actual), int(y_actual)), 10, (0, 255, 0), -1 )\n",
    "    # show the canvas\n",
    "    cv2.imshow('Gaze Tracking on Canvas', canvas)\n",
    "    cv2.waitKey(0)\n",
    "    # # show the image \n",
    "    # cv2.imshow('image', X_test[i])\n",
    "    # cv2.waitKey(0)\n",
    "    # # clear the canvas\n",
    "    \n",
    "    canvas = np.zeros((screen_height, screen_width, 3), dtype=np.uint8)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/eye_gaze_v19.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.10_eye_gaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
