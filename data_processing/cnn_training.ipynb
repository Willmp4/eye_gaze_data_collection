{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import dlib\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eye_region(frame, eye_coords, target_size=(40, 48)):\n",
    "    \"\"\"\n",
    "    Preprocesses the eye region for the CNN model.\n",
    "    Args:\n",
    "        frame: The input image frame (in BGR format).\n",
    "        eye_coords: Coordinates of the eye region.\n",
    "        target_size: The target size for each eye region.\n",
    "    Returns:\n",
    "        The preprocessed eye region.\n",
    "    \"\"\"\n",
    "    x_min = min(x for x, y in eye_coords)\n",
    "    x_max = max(x for x, y in eye_coords)\n",
    "    y_min = min(y for x, y in eye_coords)\n",
    "    y_max = max(y for x, y in eye_coords)\n",
    "\n",
    "    # Cropping the eye region based on the extremities of the landmarks\n",
    "    cropped_eye = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    # Resizing the cropped eye region to the target size\n",
    "    resized_eye = cv2.resize(cropped_eye, target_size)\n",
    "\n",
    "    return resized_eye.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_eyes(frame):\n",
    "    \"\"\"\n",
    "    Detects and combines the eye regions from the frame.\n",
    "    Args:\n",
    "        frame: The input image frame.\n",
    "    Returns:\n",
    "        The combined eye regions, or None if not detected.\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "\n",
    "        # Extract the coordinates for each eye\n",
    "        left_eye = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(36, 42)]\n",
    "        right_eye = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(42, 48)]\n",
    "\n",
    "        # Preprocess each eye region\n",
    "        left_eye_region = preprocess_eye_region(frame, left_eye)\n",
    "\n",
    "        right_eye_region = preprocess_eye_region(frame, right_eye)\n",
    "\n",
    "        # Combine the eyes side by side\n",
    "        combined_eyes = np.hstack([left_eye_region, right_eye_region])\n",
    "\n",
    "        # Ensure the combined eyes image has the correct shape\n",
    "        if combined_eyes.shape[1] != 80:\n",
    "            raise ValueError(\"Combined eyes region does not match the expected width.\")\n",
    "        return combined_eyes\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_head_pose(head_pose_data, rotation_scale=180, translation_max_displacement=None):\n",
    "    \"\"\"\n",
    "    Normalizes the head pose data.\n",
    "    Args:\n",
    "        head_pose_data: List containing the head pose data (rotation and translation vectors).\n",
    "        rotation_scale: Maximum value for the rotation vector components (180 for degrees, np.pi for radians).\n",
    "        translation_max_displacement: A tuple (max_x, max_y, max_z) representing the maximum displacement in each axis. If None, standard deviation normalization will be used.\n",
    "\n",
    "    Returns:\n",
    "        Normalized head pose data.\n",
    "    \"\"\"\n",
    "    # Normalize rotation vectors\n",
    "    normalized_rotation = np.array(head_pose_data[:3]) / rotation_scale\n",
    "\n",
    "    # Normalize translation vectors\n",
    "    if translation_max_displacement:\n",
    "        max_x, max_y, max_z = translation_max_displacement\n",
    "        normalized_translation = np.array(head_pose_data[3:]) / np.array([max_x, max_y, max_z])\n",
    "    else:\n",
    "        # Standard deviation normalization\n",
    "        translation_vector = np.array(head_pose_data[3:])\n",
    "        std_dev = np.std(translation_vector)\n",
    "        mean_val = np.mean(translation_vector)\n",
    "        normalized_translation = (translation_vector - mean_val) / std_dev\n",
    "\n",
    "    return np.concatenate([normalized_rotation, normalized_translation]).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "# Assuming normalize_head_pose and get_combined_eyes are defined as before\n",
    "def get_screen_size(metadata_file_path):\n",
    "    with open(metadata_file_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "        # Check if 'screenData' is a key in the metadata\n",
    "        if 'screenData' in metadata:\n",
    "            metadata = metadata['screenData']\n",
    "        # Otherwise, assume the metadata is already at the top level\n",
    "\n",
    "        screen_width = metadata.get('screenWidth')\n",
    "        screen_height = metadata.get('screenHeight')\n",
    "\n",
    "        if screen_width is None or screen_height is None:\n",
    "            raise ValueError(\"Screen size not found in metadata\")\n",
    "\n",
    "        return screen_width, screen_height\n",
    "\n",
    "def parse_head_pose_data(row):\n",
    "    # Split the strings and convert to float\n",
    "    rotation_str, translation_str = row['head_pose'], row['head_translation']\n",
    "    rotation = [float(x) for x in rotation_str.strip('\"').split(',')]\n",
    "    translation = [float(x) for x in translation_str.strip('\"').split(',')]\n",
    "    return rotation + translation  # Combine into a single list\n",
    "\n",
    "def prepare_dataset(base_dir):\n",
    "    X, Y = [], []\n",
    "    processed_files = set()\n",
    "    column_names = ['image_path', 'cursor_x', 'cursor_y', 'left_pup', 'eye_y1', 'eye_x2', 'eye_y2', 'eye_x3', 'eye_y3', 'eye_x4', 'eye_y4', 'eye_x5', 'eye_y5', 'eye_x6', 'eye_y6', 'head_pose', 'head_translation']\n",
    "\n",
    "    for subdir in glob(os.path.join(base_dir, '*/')):\n",
    "        print(f\"Processing directory: {subdir}\")\n",
    "        metadata_file_path = os.path.join(subdir, 'metadata.json')\n",
    "        screen_width, screen_height = get_screen_size(metadata_file_path)\n",
    "        print(f\"Screen size: {screen_width}x{screen_height}\")\n",
    "\n",
    "        # Find any CSV files in the directory\n",
    "        csv_files = glob(os.path.join(subdir, '*.csv'))\n",
    "        #skip calibration files\n",
    "        # csv_files = [f for f in csv_files if 'calibration' not in f]\n",
    "\n",
    "        for data_file_path in csv_files:\n",
    "            if data_file_path in processed_files:\n",
    "                # Skip this file since it has already been processed\n",
    "                continue\n",
    "            processed_files.add(data_file_path)  # Mark this file as processed\n",
    "\n",
    "            print(f\"Processing data CSV file: {data_file_path}\")\n",
    "            data = pd.read_csv(data_file_path, header=None, names=column_names)\n",
    "\n",
    "            if not csv_files:\n",
    "                print(f\"No data CSV file found in directory: {subdir}\")\n",
    "                continue\n",
    "            # Find any directory that contains image files (assuming JPEG for example)\n",
    "            img_folders = [d for d in os.listdir(subdir) if os.path.isdir(os.path.join(subdir, d)) and glob(os.path.join(subdir, d, '*.png'))]\n",
    "            if not img_folders:\n",
    "                print(f\"No image folder found that contains images in directory: {subdir}\")\n",
    "                continue\n",
    "            data = pd.read_csv(data_file_path, header=None, names=column_names)\n",
    "            # print how many columns \n",
    "            print(data.shape)\n",
    "\n",
    "            for index, row in data.iterrows():\n",
    "                # Directly use the image path from the dataframe\n",
    "                img_path = os.path.join(row['image_path'])\n",
    "                cursor_x, cursor_y = row['cursor_x'], row['cursor_y']\n",
    "                eye_box_pupil_data = row[3:15].tolist()\n",
    "                head_pose_data = parse_head_pose_data(row)\n",
    "\n",
    "                normalized_eye_box_pupil_data = [float(coord) / screen_width if i % 2 == 0 else float(coord) / screen_height for i, coord in enumerate(eye_box_pupil_data)]\n",
    "                normalized_head_pose_data = normalize_head_pose(head_pose_data)\n",
    "\n",
    "                # Load the image\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    print(f\"Image not found: {img_path}\")\n",
    "                    continue\n",
    "\n",
    "                combined_eyes = get_combined_eyes(img)\n",
    "\n",
    "                # Append to datasets\n",
    "                Y.append([cursor_x / screen_width, cursor_y / screen_height] + normalized_eye_box_pupil_data + normalized_head_pose_data)\n",
    "                X.append(combined_eyes)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "base_dir = './data'\n",
    "X, Y = prepare_dataset(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_filtered = [img for img in X if img is not None and isinstance(img, np.ndarray)]\n",
    "Y_filtered = [Y[i] for i in range(len(Y)) if X[i] is not None and isinstance(X[i], np.ndarray)]\n",
    "\n",
    "X_filtered = np.array(X_filtered)\n",
    "\n",
    "Y_filtered = np.array(Y_filtered)\n",
    "Y_filtered = Y_filtered[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_filtered), len(Y_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_filtered, Y_filtered, test_size=0.2, random_state=42)\n",
    "#Val data\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense, MaxPool2D\n",
    "from keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 80, 3)), \n",
    "    MaxPool2D(),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(14) \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[MeanSquaredError(), MeanAbsoluteError()])\n",
    "model.fit(X_train, Y_train, epochs=100, validation_split=0.1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    # rotation_range=20,\n",
    "    # width_shift_range=0.1,\n",
    "    # height_shift_range=0.1,\n",
    "    # shear_range=0.2,\n",
    "    # zoom_range=[0.9, 1.1],\n",
    "    # horizontal_flip=True,\n",
    "    # fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Assuming you have your training data in train_data and train_labels\n",
    "train_generator = train_datagen.flow(X_train, Y_train, batch_size=32)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Adding L2 Regularization to Convolutional Layers\n",
    "l2_reg = 0.001\n",
    "\n",
    "# First Conv Block\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 80, 3), kernel_regularizer=l2(l2_reg)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Second Conv Block\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "# Third Conv Block\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# Fourth Conv Block\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# Flatten and Dense Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2))  # Adjust the number of outputs as needed\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.00005), loss='mse', metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,  # Adjust number of epochs\n",
    "    validation_data=(X_val, Y_val),  # Assuming validation data is available\n",
    "    callbacks=[early_stopping],\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers with dropout\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 80, 3)))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.25))  # Dropout layer after pooling\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.25))  # Another dropout layer\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.4))  # Higher dropout rate for deeper layers\n",
    "\n",
    "# Flatten the output from convolutional layers before passing it to the dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add dense layers with dropout\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout layer before the output layer\n",
    "model.add(Dense(14, activation='sigmoid'))  # Adjust the number of outputs as needed\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "model.fit(X_train, Y_train, epochs=100, validation_split=0.1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('./models/eye_gaze_v13.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 28ms/step\n",
      "2419.257739186287 1341.7916679382324\n",
      "2026.8359375000002 1315.0\n",
      "657.1261465549469 947.7400588989258\n",
      "504.12109375000006 857.0\n",
      "2747.9534924030304 702.7704763412476\n",
      "2468.84765625 844.0\n",
      "2262.391984462738 1020.4450035095215\n",
      "2112.75390625 968.0000000000001\n",
      "1167.4029260873795 1139.7003936767578\n",
      "1281.5234375 1132.0\n",
      "818.1490480899811 603.8757562637329\n",
      "1004.1015625 380.0\n",
      "1989.0138149261475 991.2393951416016\n",
      "1859.8125366139427 1270.5\n",
      "1265.8489927649498 1077.641887664795\n",
      "1443.0078125 561.0\n",
      "2576.560863852501 933.3009338378906\n",
      "2087.91015625 911.0\n",
      "2059.6619337797165 487.7213430404663\n",
      "1984.0070298769772 153.0\n",
      "1527.9271751642227 414.2601442337036\n",
      "1516.50390625 180.0\n",
      "334.1575860977173 500.01577377319336\n",
      "91.09375000000001 68.0\n",
      "1586.6878032684326 934.3475532531738\n",
      "1602.1089630931458 1201.5\n",
      "1342.8165465593338 780.8297538757324\n",
      "1325.776215582894 547.5\n",
      "152.4806333705783 1120.3733825683594\n",
      "40.36321031048623 1410.0\n",
      "1991.881439089775 1106.953411102295\n",
      "1772.1874999999998 1078.0\n",
      "2166.5651619434357 901.842098236084\n",
      "2441.974223784417 150.0\n",
      "3012.1429443359375 43.06840717792511\n",
      "2613.194444444445 32.0\n",
      "621.6424763202667 955.5073928833008\n",
      "353.9543057996485 1237.5\n",
      "898.981063067913 435.22017002105713\n",
      "993.75 640.0\n",
      "1693.9081996679306 324.747576713562\n",
      "1462.6757812500002 407.0\n",
      "2196.92659676075 475.18182277679443\n",
      "2285.625 655.0\n",
      "2125.292855501175 216.4591383934021\n",
      "2176.93359375 288.0\n",
      "2365.1548087596893 777.4456214904785\n",
      "2121.03515625 1385.0\n",
      "1520.1094835996628 1359.6523475646973\n",
      "1347.7734374999998 1439.0\n"
     ]
    }
   ],
   "source": [
    "#plot predicted vs actual on test data on a canvas using opencv \n",
    "\n",
    "import cv2\n",
    "import numpy as np \n",
    "predictions = model.predict(X_test)\n",
    "screen_width, screen_height = 2650, 1440\n",
    "canvas = np.zeros((screen_height, screen_width, 3), dtype=np.uint8)\n",
    "cv2.namedWindow('Gaze Tracking on Canvas', cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('Gaze Tracking on Canvas', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "# plot the first 10 images one by one\n",
    "for i in range(50,75):\n",
    "    # get the predicted x,y coordinates\n",
    "    x, y = predictions[i][0] * screen_width, predictions[i][1] * screen_height\n",
    "    print(x,y)\n",
    "    # get the actual x,y coordinates\n",
    "    x_actual, y_actual = Y_test[i][0] * screen_width, Y_test[i][1] * screen_height\n",
    "    print(x_actual, y_actual)\n",
    "    # plot the predicted x,y coordinates\n",
    "    cv2.circle(canvas, (int(x), int(y)), 10, (0, 0, 255), -1)\n",
    "    # plot the actual x,y coordinates\n",
    "    cv2.circle(canvas, (int(x_actual), int(y_actual)), 10, (0, 255, 0), -1)\n",
    "    # show the canvas\n",
    "    cv2.imshow('Gaze Tracking on Canvas', canvas)\n",
    "    cv2.waitKey(0)\n",
    "    # clear the canvas\n",
    "    canvas = np.zeros((screen_height, screen_width, 3), dtype=np.uint8)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/eye_gaze_v13.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.10_eye_gaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
