{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from image_processing import detect_pupil, convert_eye_to_binary, extract_eye_region\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    dlib_faces = detector(gray)\n",
    "\n",
    "\n",
    "    processed_data = []\n",
    "    \n",
    "    left_eye_info = None\n",
    "    right_eye_info = None\n",
    "    left_eye_bbox = None\n",
    "    right_eye_bbox = None\n",
    "\n",
    "    for dlib_face in dlib_faces:\n",
    "        shape = predictor(gray, dlib_face)\n",
    "\n",
    "        for (i, (start, end)) in enumerate([(36,42), (42,48)]):\n",
    "            eye_image, (eye_min_x, eye_min_y, eye_max_x, eye_max_y) = extract_eye_region(gray, shape, range(start, end))\n",
    "            eye_image_b = convert_eye_to_binary(eye_image)\n",
    "            pupil_center, _ = detect_pupil(eye_image_b)\n",
    "\n",
    "            if pupil_center:\n",
    "                pupil_center_global = (pupil_center[0] + eye_min_x, pupil_center[1] + eye_min_y)\n",
    "                pupil_center_global = tuple(pc.item() if isinstance(pc, np.generic) else pc for pc in pupil_center_global)\n",
    "                bounding_box = (eye_min_x, eye_min_y, eye_max_x - eye_min_x, eye_max_y - eye_min_y)\n",
    "                bounding_box = tuple(bb.item() if isinstance(bb, np.generic) else bb for bb in bounding_box)\n",
    "                eye_data = {\n",
    "                    'eye_position': 'left' if i == 0 else 'right',\n",
    "                    'pupil_center': pupil_center_global,\n",
    "                    'bounding_box': bounding_box\n",
    "                }\n",
    "                processed_data.append(eye_data)\n",
    "\n",
    "                for eye_data in processed_data:\n",
    "                    if eye_data['eye_position'] == 'left':\n",
    "                        left_eye_info = eye_data['pupil_center']\n",
    "                        left_eye_bbox = eye_data['bounding_box']\n",
    "                    else:\n",
    "                        right_eye_info = eye_data['pupil_center']\n",
    "                        right_eye_bbox = eye_data['bounding_box']\n",
    "        break\n",
    "    return processed_data, left_eye_info, right_eye_info, left_eye_bbox, right_eye_bbox, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "Processed image saved to ./processed_William_053ae9fa-f0c7-475a-8ae2-f044a2fa8e3a.png\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "Processed image saved to ./processed_William_fa51752a-bcdc-4963-96e2-fe87b26192af.png\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "Processed image saved to ./processed_William_bf6481e1-0c75-4b6b-8f77-cb02648ba8ad.png\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "Processed image saved to ./processed_William_761f8493-a31a-4b9c-a9db-f52e84a12f22.png\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "Processed image saved to ./processed_William_931e3919-8183-4bca-9af0-ea539d813090.png\n",
      "grayscale\n",
      "grayscale\n",
      "Processed image saved to ./processed_William_58476db1-1979-44df-928c-f6e4ce8b6d32.png\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "Processed image saved to ./processed_William_94ad7e00-acf6-403d-80b5-b8ac03fe333b.png\n",
      "grayscale\n",
      "grayscale\n",
      "Processed image saved to ./processed_William_87dbec07-42e4-407e-9761-9e19789cb34d.png\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "Processed image saved to ./processed_William_f32b74fe-fceb-4f59-ae21-86f28485d6c5.png\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "Processed image saved to ./processed_William_4432cdb0-d338-4b72-a588-5e2b83307ea6.png\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "Processed image saved to ./processed_William_d259cfee-bd12-4b6f-9494-ff9778350b29.png\n",
      "grayscale\n",
      "grayscale\n",
      "Processed image saved to ./processed_William_a90e8903-aa60-4717-8b4e-c0fdf674df9b.png\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "Processed image saved to ./processed_William_d05a96d4-800b-47bb-8d44-36af67a226a6.png\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "Processed image saved to ./processed_William_d011d199-2c85-4563-8353-a02c2e1d45bb.png\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "Processed image saved to ./processed_William_2786a2f4-e633-40fa-b866-340d477a1ac9.png\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "Processed image saved to ./processed_William_ceb68628-0d43-44ff-9422-e0f228a3475d.png\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n",
      "grayscale\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_on_image(image, left_eye_box, right_eye_box, left_pupil, right_pupil, output_path):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for display\n",
    "\n",
    "    # Draw the eye boxes and pupils\n",
    "    ax.add_patch(plt.Rectangle((left_eye_box[0], left_eye_box[1]), left_eye_box[2], left_eye_box[3], fill=False, edgecolor='green', linewidth=2))\n",
    "    ax.add_patch(plt.Rectangle((right_eye_box[0], right_eye_box[1]), right_eye_box[2], right_eye_box[3], fill=False, edgecolor='green', linewidth=2))\n",
    "    ax.plot(left_pupil[0], left_pupil[1], 'ro', markersize=1)\n",
    "    ax.plot(right_pupil[0], right_pupil[1], 'ro', markersize=1)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.savefig(output_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Processed image saved to {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def test_eye_gaze_detection(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    processed_data, _, _, _, _, _ = pre_process_image(image)\n",
    "    # Process the data\n",
    "    left_eye_box, right_eye_box, left_pupil, right_pupil = None, None, None, None \n",
    "    for data in processed_data:\n",
    "        if data['eye_position'] == 'left':\n",
    "            left_eye_box = data['bounding_box']\n",
    "            left_pupil = data['pupil_center']\n",
    "        elif data['eye_position'] == 'right':\n",
    "            right_eye_box = data['bounding_box']\n",
    "            right_pupil = data['pupil_center']\n",
    "\n",
    "    # Ensure that data for both eyes is available before plotting\n",
    "    if left_eye_box is not None and right_eye_box is not None:\n",
    "        output_path = f\"./processed_{os.path.basename(image_path)}\"\n",
    "        plot_data_on_image(image, left_eye_box, right_eye_box, left_pupil, right_pupil, output_path)\n",
    "\n",
    "\n",
    "# Specify the subdirectory containing the test images\n",
    "subdirectory = './data/William/calibration_images'\n",
    "\n",
    "# List all images in the subdirectory and process each image\n",
    "test_image_paths = [os.path.join(subdirectory, f) for f in os.listdir(subdirectory) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "for image_path in test_image_paths:\n",
    "    test_eye_gaze_detection(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data_processing)",
   "language": "python",
   "name": "data_processing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
