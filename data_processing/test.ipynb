{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from image_processing import *\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_eye_region(image, landmarks, eye_points, buffer= 4):\n",
    "    # Extract the coordinates of the eye points\n",
    "    region = np.array([(landmarks.part(point).x, landmarks.part(point).y) for point in eye_points])\n",
    "    # Create a mask with zeros\n",
    "    height, width = image.shape[:2]\n",
    "    mask = np.zeros((height, width), np.uint8)\n",
    "    # Fill the mask with the polygon defined by the eye points\n",
    "    cv2.fillPoly(mask, [region], 255)\n",
    "    # Bitwise AND operation to isolate the eye region\n",
    "    eye = cv2.bitwise_and(image, image, mask=mask)\n",
    "    # Cropping the eye region\n",
    "    (min_x, min_y) = np.min(region, axis=0)\n",
    "    (max_x, max_y) = np.max(region, axis=0)\n",
    "    min_x = max(min_x - buffer, 0)\n",
    "    min_y = max(min_y - buffer, 0)\n",
    "    max_x = min(max_x + buffer, width)\n",
    "    max_y = min(max_y + buffer, height)\n",
    "    cropped_eye = eye[min_y:max_y, min_x:max_x]\n",
    "    return cropped_eye, (min_x, min_y, max_x, max_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def enhance_image_resolution(image):\n",
    "    # Load the super-resolution model\n",
    "    sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "    path = \"EDSR_x4.pb\"  # Change to the path of the model\n",
    "    sr.readModel(path)\n",
    "    sr.setModel(\"edsr\", 4)  # You can change the model and scale as needed\n",
    "\n",
    "    # Enhance the resolution of the image\n",
    "    enhanced_image = sr.upsample(image)\n",
    "    return enhanced_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pupil_candidate(contour, gray_eye_image, eye_center, threshold=0.8):\n",
    "    # Calculate area and perimeter of the contour\n",
    "    area = cv2.contourArea(contour)\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "\n",
    "    # Check for circularity\n",
    "    circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
    "    if circularity < threshold:\n",
    "        return False\n",
    "\n",
    "    # Check aspect ratio of bounding rectangle\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    aspect_ratio = float(w) / h\n",
    "    if aspect_ratio < 0.8 or aspect_ratio > 1.2:\n",
    "        return False\n",
    "\n",
    "    # Check solidity\n",
    "    hull = cv2.convexHull(contour)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    solidity = float(area) / hull_area\n",
    "    if solidity < threshold:\n",
    "        return False\n",
    "\n",
    "    # Check relative location to the center of the eye\n",
    "    M = cv2.moments(contour)\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    distance_to_center = np.sqrt((cX - eye_center[0])**2 + (cY - eye_center[1])**2)\n",
    "    if distance_to_center > (w / 2):\n",
    "        return False\n",
    "\n",
    "    # Check intensity\n",
    "    mask = np.zeros(gray_eye_image.shape, np.uint8)\n",
    "    cv2.drawContours(mask, [contour], -1, 255, -1)\n",
    "    mean_val = cv2.mean(gray_eye_image, mask=mask)[0]\n",
    "    if mean_val > 50:  # This threshold can be adjusted based on your images\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pupil(eye_image, eye_center):\n",
    "    # Enhance resolution\n",
    "    eye_image = enhance_image_resolution(eye_image)\n",
    "\n",
    "    # Preprocessing\n",
    "    gray = cv2.cvtColor(eye_image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)  # Histogram Equalization\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)  # Gaussian Blur\n",
    "\n",
    "    # Edge detection\n",
    "    edged = cv2.Canny(blurred, 50, 100)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort contours by area and filter\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    # Assuming the eye center is passed as a parameter, you can use it directly.\n",
    "    # If you need to calculate it, you can use eye landmarks like this:\n",
    "    # eye_center = np.mean(eye_landmarks, axis=0) where eye_landmarks is an array of (x, y) tuples\n",
    "\n",
    "    for contour in contours:\n",
    "        if is_pupil_candidate(contour, gray, eye_center):\n",
    "            # Found a good pupil candidate\n",
    "            M = cv2.moments(contour)\n",
    "            if M[\"m00\"] != 0:\n",
    "                cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                cv2.circle(eye_image, (cX, cY), 7, (255, 255, 255), -1)\n",
    "                cv2.imshow(\"Pupil\", eye_image)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "                return (cX, cY), contour\n",
    "\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(image):        \n",
    "    # Initialize variables\n",
    "    left_eye_info = right_eye_info = left_eye_bbox = right_eye_bbox = None\n",
    "\n",
    "    dlib_faces = detector(image)\n",
    "    processed_data = []\n",
    "    for dlib_face in dlib_faces:\n",
    "        shape = predictor(image, dlib_face)\n",
    "\n",
    "        for (i, (start, end)) in enumerate([(36,42), (42,48)]):\n",
    "            eye_landmarks = [(shape.part(point).x, shape.part(point).y) for point in range(start, end)]\n",
    "            eye_center = np.mean(eye_landmarks, axis=0).astype(int)  # Ensure you have integers for the center\n",
    "            eye_image, (eye_min_x, eye_min_y, eye_max_x, eye_max_y) = extract_eye_region(image, shape, range(start, end))\n",
    "            print(eye_max_x, eye_max_y)\n",
    "            print(eye_min_x, eye_min_y)\n",
    "# Now call the detect_pupil function with the eye image and the calculated eye center\n",
    "            pupil_center, pupil_contour = detect_pupil(eye_image, eye_center)\n",
    "            # After detecting the pupil in the cropped eye image:\n",
    "            if pupil_center:\n",
    "                # Scale the pupil center coordinates down to the original image size\n",
    "                pupil_center_original = (pupil_center[0] / 4, pupil_center[1] / 4)\n",
    "                # Transform these coordinates to the global space of the original image\n",
    "                pupil_center_global = (int(pupil_center_original[0]) + eye_min_x, int(pupil_center_original[1]) + eye_min_y)\n",
    "    \n",
    "                pupil_center_global = tuple(pc.item() if isinstance(pc, np.generic) else pc for pc in pupil_center_global)\n",
    "\n",
    "                #draw contours\n",
    "                cv2.drawContours(image, [pupil_contour], -1, (0, 255, 0), 2)\n",
    "                cv2.circle(image, pupil_center_global, 1, (255, 255, 255), -1)\n",
    "                cv2.imshow(\"Eye\", image)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "                bounding_box = (eye_min_x, eye_min_y, eye_max_x - eye_min_x, eye_max_y - eye_min_y)\n",
    "                bounding_box = tuple(bb.item() if isinstance(bb, np.generic) else bb for bb in bounding_box)\n",
    "\n",
    "                eye_data = {\n",
    "                    'eye_position': 'left' if i == 0 else 'right',\n",
    "                    'pupil_center': pupil_center_global,\n",
    "                    'bounding_box': bounding_box\n",
    "                }\n",
    "                processed_data.append(eye_data)\n",
    "\n",
    "        # Processed data for each eye\n",
    "    for eye_data in processed_data:\n",
    "        if eye_data['eye_position'] == 'left':\n",
    "            left_eye_info = eye_data['pupil_center']\n",
    "            left_eye_bbox = eye_data['bounding_box']\n",
    "        else:\n",
    "            right_eye_info = eye_data['pupil_center']\n",
    "            right_eye_bbox = eye_data['bounding_box']\n",
    "    \n",
    "    # Check if any eye information was detected\n",
    "    if left_eye_info is None and right_eye_info is None:\n",
    "        print(\"No eye information detected\")\n",
    "        return None\n",
    "\n",
    "    return processed_data, left_eye_info, right_eye_info, left_eye_bbox, right_eye_bbox, shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333 175\n",
      "289 157\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/Naia/calibration_images/Naia_07779f08-1c1f-490f-9d26-7786c43aca1d.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mpre_process_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# # Load your image here\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# image = cv2.imread(image)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# eye_image = extract_eye_region(image)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m, in \u001b[0;36mpre_process_image\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[38;5;28mprint\u001b[39m(eye_min_x, eye_min_y)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Now call the detect_pupil function with the eye image and the calculated eye center\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m             pupil_center, pupil_contour \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_pupil\u001b[49m\u001b[43m(\u001b[49m\u001b[43meye_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meye_center\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m             \u001b[38;5;66;03m# After detecting the pupil in the cropped eye image:\u001b[39;00m\n\u001b[0;32m     19\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m pupil_center:\n\u001b[0;32m     20\u001b[0m                 \u001b[38;5;66;03m# Scale the pupil center coordinates down to the original image size\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m, in \u001b[0;36mdetect_pupil\u001b[1;34m(eye_image, eye_center)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Assuming the eye center is passed as a parameter, you can use it directly.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# If you need to calculate it, you can use eye landmarks like this:\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# eye_center = np.mean(eye_landmarks, axis=0) where eye_landmarks is an array of (x, y) tuples\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m contour \u001b[38;5;129;01min\u001b[39;00m contours:\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_pupil_candidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontour\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meye_center\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;66;03m# Found a good pupil candidate\u001b[39;00m\n\u001b[0;32m     26\u001b[0m         M \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mmoments(contour)\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m M[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm00\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m, in \u001b[0;36mis_pupil_candidate\u001b[1;34m(contour, gray_eye_image, eye_center, threshold)\u001b[0m\n\u001b[0;32m      4\u001b[0m perimeter \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39marcLength(contour, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Check for circularity\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m circularity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m*\u001b[39m (\u001b[43marea\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mperimeter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mperimeter\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m circularity \u001b[38;5;241m<\u001b[39m threshold:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "image = 'data/Naia/calibration_images/Naia_07779f08-1c1f-490f-9d26-7786c43aca1d.png'\n",
    "pre_process_image(cv2.imread(image))\n",
    "# # Load your image here\n",
    "# image = cv2.imread(image)\n",
    "# eye_image = extract_eye_region(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308 272\n",
      "269 252\n",
      "4364.0\n",
      "383 271\n",
      "346 252\n",
      "81.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'eye_position': 'left',\n",
       "   'pupil_center': (289, 262),\n",
       "   'bounding_box': (269, 252, 39, 20)},\n",
       "  {'eye_position': 'right',\n",
       "   'pupil_center': (365, 261),\n",
       "   'bounding_box': (346, 252, 37, 19)}],\n",
       " (289, 262),\n",
       " (365, 261),\n",
       " (269, 252, 39, 20),\n",
       " (346, 252, 37, 19),\n",
       " <_dlib_pybind11.full_object_detection at 0x2b20dc2f4b0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1 = 'data/Will/eye_gaze_images/Will_01bdf4b4-38da-4bd3-a9b4-0ff7b57bd23a.png'\n",
    "pre_process_image(cv2.imread(image1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(data_processing)",
   "language": "python",
   "name": "data_processing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
