{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from image_processing import *\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_eye_region(image, landmarks, eye_points, buffer= 1):\n",
    "    # Extract the coordinates of the eye points\n",
    "    region = np.array([(landmarks.part(point).x, landmarks.part(point).y) for point in eye_points])\n",
    "    # Create a mask with zeros\n",
    "    height, width = image.shape[:2]\n",
    "    mask = np.zeros((height, width), np.uint8)\n",
    "    # Fill the mask with the polygon defined by the eye points\n",
    "    cv2.fillPoly(mask, [region], 255)\n",
    "    # Bitwise AND operation to isolate the eye region\n",
    "    eye = cv2.bitwise_and(image, image, mask=mask)\n",
    "    # Cropping the eye region\n",
    "    (min_x, min_y) = np.min(region, axis=0)\n",
    "    (max_x, max_y) = np.max(region, axis=0)\n",
    "    min_x = max(min_x - buffer, 0)\n",
    "    min_y = max(min_y - buffer, 0)\n",
    "    max_x = min(max_x + buffer, width)\n",
    "    max_y = min(max_y + buffer, height)\n",
    "    cropped_eye = eye[min_y:max_y, min_x:max_x]\n",
    "    return cropped_eye, (min_x, min_y, max_x, max_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def enhance_image_resolution(image):\n",
    "    # Load the super-resolution model\n",
    "    sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "    path = \"EDSR_x4.pb\"  # Change to the path of the model\n",
    "    sr.readModel(path)\n",
    "    sr.setModel(\"edsr\", 4)  # You can change the model and scale as needed\n",
    "\n",
    "    # Enhance the resolution of the image\n",
    "    enhanced_image = sr.upsample(image)\n",
    "    return enhanced_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(title, image):\n",
    "    cv2.imshow(title, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pupil_candidate(contour, gray_eye_image, eye_center, threshold=0.7):\n",
    "    #show gray_eye_image\n",
    "\n",
    "    # Calculate area and perimeter of the contour\n",
    "    area = cv2.contourArea(contour)\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    print(\"area: \", area)\n",
    "    print(\"perimeter: \", perimeter)\n",
    "\n",
    "    # Check if perimeter is zero to avoid division by zero\n",
    "    if perimeter == 0:\n",
    "        print(\"Perimeter is zero\")\n",
    "        return False\n",
    "\n",
    "    # Check for circularity\n",
    "    circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
    "    print(\"circularity: \", circularity)\n",
    "    if circularity < threshold:\n",
    "        return False\n",
    "\n",
    "    # Check aspect ratio of bounding rectangle\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    aspect_ratio = float(w) / h\n",
    "    print(\"aspect_ratio: \", aspect_ratio)\n",
    "    if aspect_ratio < 0.8 or aspect_ratio > 1.2:\n",
    "        return False\n",
    "\n",
    "    # Check solidity\n",
    "    hull = cv2.convexHull(contour)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    solidity = float(area) / hull_area\n",
    "    print(\"solidity: \", solidity)\n",
    "    if solidity < threshold:\n",
    "        return False\n",
    "\n",
    "    # Check relative location to the center of the eye\n",
    "    M = cv2.moments(contour)\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    distance_to_center = np.sqrt((cX - eye_center[0])**2 + (cY - eye_center[1])**2)\n",
    "    # if distance_to_center > (w ):\n",
    "    #     print(\"distance_to_center: \", distance_to_center)\n",
    "    #     return False\n",
    "\n",
    "    # Check intensity\n",
    "    mask = np.zeros(gray_eye_image.shape, np.uint8)\n",
    "    cv2.drawContours(mask, [contour], -1, 255, -1)\n",
    "    mean_val = cv2.mean(gray_eye_image, mask=mask)[0]\n",
    "    if mean_val > 50:  # This threshold can be adjusted based on your images\n",
    "        print(\"mean_val: \", mean_val)\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pupil(eye_image, eye_center):\n",
    "    # Enhance resolution\n",
    "    eye_image = enhance_image_resolution(eye_image)\n",
    "\n",
    "    gray = cv2.cvtColor(eye_image, cv2.COLOR_BGR2GRAY)\n",
    "    visualize_image(\"Grayscale Eye\", gray)  # Visualize grayscale eye\n",
    "\n",
    "    gray = cv2.equalizeHist(gray)  # Histogram Equalization\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)  # Gaussian Blur\n",
    "    visualize_image(\"Blurred Eye\", blurred)  # Visualize blurred eye\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(blurred, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "    # Sort contours by area and filter\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    # Visualize contours\n",
    "    contour_image = eye_image.copy()\n",
    "    cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)\n",
    "    visualize_image(\"Contours\", contour_image)\n",
    "\n",
    "    for contour in contours:\n",
    "\n",
    "        # if is_pupil_candidate(contour, gray, eye_center):\n",
    "            # Found a good pupil candidate\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            cv2.circle(eye_image, (cX, cY), 7, (255, 255, 255), -1)\n",
    "            visualize_image(\"Pupil\", eye_image)\n",
    "            return (cX, cY), contour\n",
    "\n",
    "    print(\"No suitable pupil found\")\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(image):        \n",
    "    # Initialize variables\n",
    "    left_eye_info = right_eye_info = left_eye_bbox = right_eye_bbox = None\n",
    "\n",
    "    dlib_faces = detector(image)\n",
    "    processed_data = []\n",
    "    for dlib_face in dlib_faces:\n",
    "        shape = predictor(image, dlib_face)\n",
    "\n",
    "        for (i, (start, end)) in enumerate([(36,42), (42,48)]):\n",
    "            eye_landmarks = [(shape.part(point).x, shape.part(point).y) for point in range(start, end)]\n",
    "            eye_center = np.mean(eye_landmarks, axis=0).astype(int)  # Ensure you have integers for the center\n",
    "            eye_image, (eye_min_x, eye_min_y, eye_max_x, eye_max_y) = extract_eye_region(image, shape, range(start, end))\n",
    "  \n",
    "            pupil_center, pupil_contour = detect_pupil(eye_image, eye_center)\n",
    "            print(pupil_center)\n",
    "            # After detecting the pupil in the cropped eye image:\n",
    "            if pupil_center:\n",
    "                # Scale the pupil center coordinates down to the original image size\n",
    "                pupil_center_original = (pupil_center[0] / 4, pupil_center[1] / 4)\n",
    "                # Transform these coordinates to the global space of the original image\n",
    "                pupil_center_global = (int(pupil_center_original[0]) + eye_min_x, int(pupil_center_original[1]) + eye_min_y)\n",
    "    \n",
    "                pupil_center_global = tuple(pc.item() if isinstance(pc, np.generic) else pc for pc in pupil_center_global)\n",
    "\n",
    "                #draw contours\n",
    "                cv2.drawContours(image, [pupil_contour], -1, (0, 255, 0), 2)\n",
    "                cv2.circle(image, pupil_center_global, 1, (255, 255, 255), -1)\n",
    "                cv2.imshow(\"Eye\", image)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "                bounding_box = (eye_min_x, eye_min_y, eye_max_x - eye_min_x, eye_max_y - eye_min_y)\n",
    "                bounding_box = tuple(bb.item() if isinstance(bb, np.generic) else bb for bb in bounding_box)\n",
    "\n",
    "                eye_data = {\n",
    "                    'eye_position': 'left' if i == 0 else 'right',\n",
    "                    'pupil_center': pupil_center_global,\n",
    "                    'bounding_box': bounding_box\n",
    "                }\n",
    "                processed_data.append(eye_data)\n",
    "\n",
    "        # Processed data for each eye\n",
    "    for eye_data in processed_data:\n",
    "        if eye_data['eye_position'] == 'left':\n",
    "            left_eye_info = eye_data['pupil_center']\n",
    "            left_eye_bbox = eye_data['bounding_box']\n",
    "        else:\n",
    "            right_eye_info = eye_data['pupil_center']\n",
    "            right_eye_bbox = eye_data['bounding_box']\n",
    "    \n",
    "    # Check if any eye information was detected\n",
    "    if left_eye_info is None and right_eye_info is None:\n",
    "        print(\"No eye information detected\")\n",
    "        return None\n",
    "\n",
    "    return processed_data, left_eye_info, right_eye_info, left_eye_bbox, right_eye_bbox, shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73, 25)\n",
      "(68, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'eye_position': 'left',\n",
       "   'pupil_center': (310, 166),\n",
       "   'bounding_box': (292, 160, 38, 12)},\n",
       "  {'eye_position': 'right',\n",
       "   'pupil_center': (394, 170),\n",
       "   'bounding_box': (377, 164, 35, 12)}],\n",
       " (310, 166),\n",
       " (394, 170),\n",
       " (292, 160, 38, 12),\n",
       " (377, 164, 35, 12),\n",
       " <_dlib_pybind11.full_object_detection at 0x157fffaa9b0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = 'data/Naia/calibration_images/Naia_07779f08-1c1f-490f-9d26-7786c43aca1d.png'\n",
    "pre_process_image(cv2.imread(image))\n",
    "# # Load your image here\n",
    "# image = cv2.imread(image)\n",
    "# eye_image = extract_eye_region(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 27)\n",
      "(59, 25)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'eye_position': 'left',\n",
       "   'pupil_center': (288, 233),\n",
       "   'bounding_box': (272, 227, 33, 13)},\n",
       "  {'eye_position': 'right',\n",
       "   'pupil_center': (364, 237),\n",
       "   'bounding_box': (350, 231, 30, 12)}],\n",
       " (288, 233),\n",
       " (364, 237),\n",
       " (272, 227, 33, 13),\n",
       " (350, 231, 30, 12),\n",
       " <_dlib_pybind11.full_object_detection at 0x25a8f2395b0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1 = 'data/Will/eye_gaze_images/Will_0c426e4f-72ac-479c-a1e6-3d9df004aebb.png'\n",
    "pre_process_image(cv2.imread(image1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 30)\n",
      "(83, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'eye_position': 'left',\n",
       "   'pupil_center': (294, 225),\n",
       "   'bounding_box': (274, 218, 43, 14)},\n",
       "  {'eye_position': 'right',\n",
       "   'pupil_center': (394, 227),\n",
       "   'bounding_box': (374, 220, 43, 14)}],\n",
       " (294, 225),\n",
       " (394, 227),\n",
       " (274, 218, 43, 14),\n",
       " (374, 220, 43, 14),\n",
       " <_dlib_pybind11.full_object_detection at 0x25a8f2e34f0>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image2 = 'data/muzzy/calibration_images/muzzy_0194b294-0505-498e-afe8-837a4e1b5cf6.png'\n",
    "pre_process_image(cv2.imread(image2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(data_processing)",
   "language": "python",
   "name": "data_processing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
