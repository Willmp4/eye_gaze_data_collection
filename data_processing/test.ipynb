{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from image_processing import *\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_eye_region(image, landmarks, eye_points, buffer= 0):\n",
    "    # Extract the coordinates of the eye points\n",
    "    region = np.array([(landmarks.part(point).x, landmarks.part(point).y) for point in eye_points])\n",
    "    # Create a mask with zeros\n",
    "    height, width = image.shape[:2]\n",
    "    mask = np.zeros((height, width), np.uint8)\n",
    "    # Fill the mask with the polygon defined by the eye points\n",
    "    cv2.fillPoly(mask, [region], 255)\n",
    "    # Bitwise AND operation to isolate the eye region\n",
    "    eye = cv2.bitwise_and(image, image, mask=mask)\n",
    "    # Cropping the eye region\n",
    "    (min_x, min_y) = np.min(region, axis=0)\n",
    "    (max_x, max_y) = np.max(region, axis=0)\n",
    "    min_x = max(min_x - buffer, 0)\n",
    "    min_y = max(min_y - buffer, 0)\n",
    "    max_x = min(max_x + buffer, width)\n",
    "    max_y = min(max_y + buffer, height)\n",
    "    cropped_eye = eye[min_y:max_y, min_x:max_x]\n",
    "    return cropped_eye, (min_x, min_y, max_x, max_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def enhance_image_resolution(image):\n",
    "    # Load the super-resolution model\n",
    "    sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "    path = \"EDSR_x4.pb\"  # Change to the path of the model\n",
    "    sr.readModel(path)\n",
    "    sr.setModel(\"edsr\", 4)  # You can change the model and scale as needed\n",
    "\n",
    "    # Enhance the resolution of the image\n",
    "    enhanced_image = sr.upsample(image)\n",
    "    return enhanced_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(title, image):\n",
    "    cv2.imshow(title, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pupil(eye_image):\n",
    "    # Enhance resolution\n",
    "    eye_image = enhance_image_resolution(eye_image)\n",
    "\n",
    "    gray = cv2.cvtColor(eye_image, cv2.COLOR_BGR2GRAY)\n",
    "    visualize_image(\"Grayscale Eye\", gray)  # Visualize grayscale eye\n",
    "\n",
    "    gray = cv2.equalizeHist(gray)  # Histogram Equalization\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)  # Gaussian Blur\n",
    "    visualize_image(\"Blurred Eye\", blurred)  # Visualize blurred eye\n",
    "\n",
    "    # Thresholding\n",
    "    _, thresholded = cv2.threshold(blurred, 40, 255, cv2.THRESH_BINARY_INV)\n",
    "    visualize_image(\"Thresholded Eye\", thresholded)  # Visualize thresholded eye\n",
    "\n",
    "    # Morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    opened = cv2.morphologyEx(thresholded, cv2.MORPH_OPEN, kernel)\n",
    "    visualize_image(\"Opened Eye\", opened)  # Visualize opened eye\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(opened, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort contours by area and filter\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    # Filter out edge contours\n",
    "    filtered_contours = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if x > 0 and y > 0 and x + w < eye_image.shape[1] and y + h < eye_image.shape[0]:\n",
    "            filtered_contours.append(contour)\n",
    "\n",
    "    # Visualize contours\n",
    "    contour_image = eye_image.copy()\n",
    "    cv2.drawContours(contour_image, filtered_contours, -1, (0, 255, 0), 2)\n",
    "    visualize_image(\"Contours\", contour_image)\n",
    "\n",
    "    for contour in filtered_contours:\n",
    "        # Rest of the code...\n",
    "\n",
    "        area = cv2.contourArea(contour)\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "\n",
    "        # Check if perimeter is zero to avoid division by zero\n",
    "        if perimeter == 0:\n",
    "            print(\"Perimeter is zero\")\n",
    "            continue\n",
    "\n",
    "        # Check for circularity\n",
    "        circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
    "        print(f'Circularity: {circularity}')\n",
    "        if circularity < 0.5:\n",
    "            continue\n",
    "\n",
    "        # Found a good pupil candidate\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            cv2.circle(eye_image, (cX, cY), 7, (255, 255, 255), -1)\n",
    "            visualize_image(\"Pupil\", eye_image)\n",
    "            return (cX, cY), contour\n",
    "\n",
    "    print(\"No suitable pupil found\")\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pupil(eye_image):\n",
    "    # Enhance resolution\n",
    "    eye_image = enhance_image_resolution(eye_image)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(eye_image, cv2.COLOR_BGR2GRAY)\n",
    "    visualize_image(\"gray\", gray)\n",
    "\n",
    "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    clahe_equalized = clahe.apply(gray)\n",
    "    visualize_image(\"clahe_equalized\", clahe_equalized)\n",
    "\n",
    "    # Apply Gaussian Blur\n",
    "    blurred = cv2.GaussianBlur(clahe_equalized, (7, 7), 0)\n",
    "\n",
    "    # Apply Adaptive Thresholding\n",
    "    adaptive_thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                            cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # Perform Edge Detection using Canny\n",
    "    edges = cv2.Canny(adaptive_thresh, 50, 150)#\n",
    "    visualize_image(\"edges\", edges)\n",
    "\n",
    "    # Use Hough Circle Transform to find circles\n",
    "    circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, dp=1, minDist=30,\n",
    "                               param1=30, param2=20, minRadius=12, maxRadius=30)\n",
    "    print(circles)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        for (x, y, r) in circles:\n",
    "            cv2.circle(eye_image, (x, y), r, (0, 255, 0), 4)\n",
    "            cv2.rectangle(eye_image, (x - 5, y - 5), (x + 5, y + 5), (0, 128, 255), -1)\n",
    "        return eye_image, circles\n",
    "\n",
    "    print(\"No suitable pupil found\")\n",
    "    return eye_image, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(image):\n",
    "    # Initialize variables\n",
    "    left_eye_info = right_eye_info = left_eye_bbox = right_eye_bbox = None\n",
    "\n",
    "    dlib_faces = detector(image)\n",
    "    processed_data = []\n",
    "    for dlib_face in dlib_faces:\n",
    "        shape = predictor(image, dlib_face)\n",
    "\n",
    "        for (i, (start, end)) in enumerate([(36,42), (42,48)]):\n",
    "            eye_landmarks = [(shape.part(point).x, shape.part(point).y) for point in range(start, end)]\n",
    "            eye_image, (eye_min_x, eye_min_y, eye_max_x, eye_max_y) = extract_eye_region(image, shape, range(start, end))\n",
    "  \n",
    "            # Call the new detect_pupil function\n",
    "            result_eye_image, circles = detect_pupil(eye_image)\n",
    "            \n",
    "            # After detecting the pupil in the cropped eye image:\n",
    "            if circles is not None:\n",
    "                # Select the largest circle as the pupil\n",
    "                largest_circle = max(circles, key=lambda c: c[2])\n",
    "                x, y, r = largest_circle\n",
    "                pupil_center = (int(x/4), int(y/4))\n",
    "\n",
    "\n",
    "                # Create a contour from the circle for compatibility\n",
    "                pupil_contour = cv2.ellipse2Poly((x, y), (r, r), 0, 0, 360, 1)\n",
    "\n",
    "                # Transform the pupil center coordinates to the global space of the original image\n",
    "                pupil_center_global = (pupil_center[0] + eye_min_x, pupil_center[1] + eye_min_y)\n",
    "\n",
    "                # Draw contours and center on the original image\n",
    "                # Draw the pupils \n",
    "                cv2.circle(image, pupil_center_global, 1, (0, 255, 0), 2)\n",
    "                # Draw the contour\n",
    "                \n",
    "\n",
    "                cv2.imshow(\"image\", image)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "                bounding_box = (eye_min_x, eye_min_y, eye_max_x - eye_min_x, eye_max_y - eye_min_y)\n",
    "                eye_data = {\n",
    "                    'eye_position': 'left' if i == 0 else 'right',\n",
    "                    'pupil_center': pupil_center_global,\n",
    "                    'bounding_box': bounding_box,\n",
    "                }\n",
    "                processed_data.append(eye_data)\n",
    "\n",
    "    # Processed data for each eye\n",
    "    for eye_data in processed_data:\n",
    "        if eye_data['eye_position'] == 'left':\n",
    "            left_eye_info = eye_data['pupil_center']\n",
    "            left_eye_bbox = eye_data['bounding_box']\n",
    "        else:\n",
    "            right_eye_info = eye_data['pupil_center']\n",
    "            right_eye_bbox = eye_data['bounding_box']\n",
    "\n",
    "    # Check if any eye information was detected\n",
    "    if left_eye_info is None and right_eye_info is None:\n",
    "        print(\"No eye information detected\")\n",
    "        return None\n",
    "\n",
    "    # Returning the processed data along with the dlib shape for further processing if needed\n",
    "    return processed_data, left_eye_info, right_eye_info, left_eye_bbox, right_eye_bbox, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[74.5 17.5 20.5]]]\n",
      "[[[67.5 18.5 15.8]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'eye_position': 'left',\n",
       "   'pupil_center': (311, 165),\n",
       "   'bounding_box': (293, 161, 36, 10)},\n",
       "  {'eye_position': 'right',\n",
       "   'pupil_center': (395, 169),\n",
       "   'bounding_box': (378, 165, 33, 10)}],\n",
       " (311, 165),\n",
       " (395, 169),\n",
       " (293, 161, 36, 10),\n",
       " (378, 165, 33, 10),\n",
       " <_dlib_pybind11.full_object_detection at 0x234eef0ee30>)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = 'data/Naia/calibration_images/Naia_07779f08-1c1f-490f-9d26-7786c43aca1d.png'\n",
    "pre_process_image(cv2.imread(image))\n",
    "# # Load your image here\n",
    "# image = cv2.imread(image)\n",
    "# eye_image = extract_eye_region(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[82.5 21.5 19.4]]]\n",
      "[[[49.5 15.5 21.7]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'eye_position': 'left',\n",
       "   'pupil_center': (293, 233),\n",
       "   'bounding_box': (273, 228, 31, 11)},\n",
       "  {'eye_position': 'right',\n",
       "   'pupil_center': (363, 236),\n",
       "   'bounding_box': (351, 232, 28, 10)}],\n",
       " (293, 233),\n",
       " (363, 236),\n",
       " (273, 228, 31, 11),\n",
       " (351, 232, 28, 10),\n",
       " <_dlib_pybind11.full_object_detection at 0x234ee6e6070>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1 = 'data/Will/eye_gaze_images/Will_0c426e4f-72ac-479c-a1e6-3d9df004aebb.png'\n",
    "pre_process_image(cv2.imread(image1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[84.5 17.5 13.6]]]\n",
      "[[[50.5 24.5 20.5]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'eye_position': 'left',\n",
       "   'pupil_center': (296, 223),\n",
       "   'bounding_box': (275, 219, 41, 12)},\n",
       "  {'eye_position': 'right',\n",
       "   'pupil_center': (387, 227),\n",
       "   'bounding_box': (375, 221, 41, 12)}],\n",
       " (296, 223),\n",
       " (387, 227),\n",
       " (275, 219, 41, 12),\n",
       " (375, 221, 41, 12),\n",
       " <_dlib_pybind11.full_object_detection at 0x2348634f8f0>)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image2 = 'data/muzzy/calibration_images/muzzy_0194b294-0505-498e-afe8-837a4e1b5cf6.png'\n",
    "pre_process_image(cv2.imread(image2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(data_processing)",
   "language": "python",
   "name": "data_processing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
